2019-02-28 14:44:40	DEBUG	Punctuation handler ==>> text to process:can you recharge
2019-02-28 15:11:18	DEBUG	Punctuation handler ==>> text to process:can you recharge
2019-02-28 15:11:18	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge'] and tokenize_without_stop_words:[]
2019-02-28 15:11:18	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg'] and stem_without_stop_words:[]
2019-02-28 15:11:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:11:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:11:18	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['you recharg'] == trigram:['can you recharg']
2019-02-28 15:11:18	DEBUG	Punctuation handler ==>> text to process:recharge mobile number
2019-02-28 15:11:18	DEBUG	Tokenization handler ==>> takens:['recharge', 'mobile', 'number'] and tokenize_without_stop_words:[]
2019-02-28 15:11:18	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'mobil', 'number'] and stem_without_stop_words:[]
2019-02-28 15:11:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:11:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:11:18	DEBUG	Ngram handler ==>> unigram:['recharg', 'mobil'] == bigram:['recharg mobil', 'mobil number'] == trigram:['recharg mobil number']
2019-02-28 15:11:18	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-02-28 15:11:18	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-02-28 15:11:18	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-02-28 15:11:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:11:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:11:18	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-02-28 15:11:18	DEBUG	Punctuation handler ==>> text to process:enter your mobile number
2019-02-28 15:11:18	DEBUG	Tokenization handler ==>> takens:['enter', 'your', 'mobile', 'number'] and tokenize_without_stop_words:[]
2019-02-28 15:11:18	DEBUG	Stemmer handler ==>> stem_tokens:['enter', 'your', 'mobil', 'number'] and stem_without_stop_words:[]
2019-02-28 15:11:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:11:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:11:18	DEBUG	Ngram handler ==>> unigram:['enter', 'mobil'] == bigram:['enter your', 'your mobil', 'mobil number'] == trigram:['enter your mobil', 'your mobil number']
2019-02-28 15:11:18	DEBUG	Punctuation handler ==>> text to process:recharge amount
2019-02-28 15:11:18	DEBUG	Tokenization handler ==>> takens:['recharge', 'amount'] and tokenize_without_stop_words:[]
2019-02-28 15:11:18	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'amount'] and stem_without_stop_words:[]
2019-02-28 15:11:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:11:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:11:18	DEBUG	Ngram handler ==>> unigram:['recharg', 'amount'] == bigram:['recharg amount'] == trigram:[]
2019-02-28 15:11:18	DEBUG	Punctuation handler ==>> text to process:amount data
2019-02-28 15:11:18	DEBUG	Tokenization handler ==>> takens:['amount', 'data'] and tokenize_without_stop_words:[]
2019-02-28 15:11:18	DEBUG	Stemmer handler ==>> stem_tokens:['amount', 'data'] and stem_without_stop_words:[]
2019-02-28 15:11:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:11:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:11:18	DEBUG	Ngram handler ==>> unigram:['amount', 'data'] == bigram:['amount data'] == trigram:[]
2019-02-28 15:11:18	DEBUG	Punctuation handler ==>> text to process:recharge amount
2019-02-28 15:11:18	DEBUG	Tokenization handler ==>> takens:['recharge', 'amount'] and tokenize_without_stop_words:[]
2019-02-28 15:11:18	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'amount'] and stem_without_stop_words:[]
2019-02-28 15:11:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:11:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:11:18	DEBUG	Ngram handler ==>> unigram:['recharg', 'amount'] == bigram:['recharg amount'] == trigram:[]
2019-02-28 15:11:31	DEBUG	Punctuation handler ==>> text to process:recharge mobile number
2019-02-28 15:11:31	DEBUG	Tokenization handler ==>> takens:['recharge', 'mobile', 'number'] and tokenize_without_stop_words:[]
2019-02-28 15:11:31	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'mobil', 'number'] and stem_without_stop_words:[]
2019-02-28 15:11:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:11:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:11:31	DEBUG	Ngram handler ==>> unigram:['recharg', 'mobil'] == bigram:['recharg mobil', 'mobil number'] == trigram:['recharg mobil number']
2019-02-28 15:11:31	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-02-28 15:11:31	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-02-28 15:11:31	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-02-28 15:11:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:11:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:11:31	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-02-28 15:11:31	DEBUG	Punctuation handler ==>> text to process:can you recharge
2019-02-28 15:11:31	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge'] and tokenize_without_stop_words:[]
2019-02-28 15:11:31	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg'] and stem_without_stop_words:[]
2019-02-28 15:11:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:11:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:11:31	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['you recharg'] == trigram:['can you recharg']
2019-02-28 15:11:31	DEBUG	Punctuation handler ==>> text to process:enter your mobile number
2019-02-28 15:11:31	DEBUG	Tokenization handler ==>> takens:['enter', 'your', 'mobile', 'number'] and tokenize_without_stop_words:[]
2019-02-28 15:11:31	DEBUG	Stemmer handler ==>> stem_tokens:['enter', 'your', 'mobil', 'number'] and stem_without_stop_words:[]
2019-02-28 15:11:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:11:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:11:31	DEBUG	Ngram handler ==>> unigram:['enter', 'mobil'] == bigram:['enter your', 'your mobil', 'mobil number'] == trigram:['enter your mobil', 'your mobil number']
2019-02-28 15:11:31	DEBUG	Punctuation handler ==>> text to process:recharge amount
2019-02-28 15:11:31	DEBUG	Tokenization handler ==>> takens:['recharge', 'amount'] and tokenize_without_stop_words:[]
2019-02-28 15:11:31	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'amount'] and stem_without_stop_words:[]
2019-02-28 15:11:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:11:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:11:31	DEBUG	Ngram handler ==>> unigram:['recharg', 'amount'] == bigram:['recharg amount'] == trigram:[]
2019-02-28 15:11:31	DEBUG	Punctuation handler ==>> text to process:amount data
2019-02-28 15:11:31	DEBUG	Tokenization handler ==>> takens:['amount', 'data'] and tokenize_without_stop_words:[]
2019-02-28 15:11:31	DEBUG	Stemmer handler ==>> stem_tokens:['amount', 'data'] and stem_without_stop_words:[]
2019-02-28 15:11:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:11:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:11:31	DEBUG	Ngram handler ==>> unigram:['amount', 'data'] == bigram:['amount data'] == trigram:[]
2019-02-28 15:11:31	DEBUG	Punctuation handler ==>> text to process:recharge amount
2019-02-28 15:11:31	DEBUG	Tokenization handler ==>> takens:['recharge', 'amount'] and tokenize_without_stop_words:[]
2019-02-28 15:11:31	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'amount'] and stem_without_stop_words:[]
2019-02-28 15:11:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:11:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:11:31	DEBUG	Ngram handler ==>> unigram:['recharg', 'amount'] == bigram:['recharg amount'] == trigram:[]
2019-02-28 15:26:33	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-02-28 15:26:33	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-02-28 15:26:33	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-02-28 15:26:33	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:26:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:26:33	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-02-28 15:26:33	DEBUG	Punctuation handler ==>> text to process:can you recharge
2019-02-28 15:26:33	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge'] and tokenize_without_stop_words:[]
2019-02-28 15:26:33	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg'] and stem_without_stop_words:[]
2019-02-28 15:26:33	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:26:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:26:33	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['you recharg'] == trigram:['can you recharg']
2019-02-28 15:26:33	DEBUG	Punctuation handler ==>> text to process:recharge mobile number
2019-02-28 15:26:33	DEBUG	Tokenization handler ==>> takens:['recharge', 'mobile', 'number'] and tokenize_without_stop_words:[]
2019-02-28 15:26:33	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'mobil', 'number'] and stem_without_stop_words:[]
2019-02-28 15:26:33	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:26:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:26:33	DEBUG	Ngram handler ==>> unigram:['recharg', 'mobil'] == bigram:['recharg mobil', 'mobil number'] == trigram:['recharg mobil number']
2019-02-28 15:26:33	DEBUG	Punctuation handler ==>> text to process:enter your mobile number
2019-02-28 15:26:33	DEBUG	Tokenization handler ==>> takens:['enter', 'your', 'mobile', 'number'] and tokenize_without_stop_words:[]
2019-02-28 15:26:33	DEBUG	Stemmer handler ==>> stem_tokens:['enter', 'your', 'mobil', 'number'] and stem_without_stop_words:[]
2019-02-28 15:26:33	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:26:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:26:33	DEBUG	Ngram handler ==>> unigram:['enter', 'mobil'] == bigram:['enter your', 'your mobil', 'mobil number'] == trigram:['enter your mobil', 'your mobil number']
2019-02-28 15:26:33	DEBUG	Punctuation handler ==>> text to process:recharge amount
2019-02-28 15:26:33	DEBUG	Tokenization handler ==>> takens:['recharge', 'amount'] and tokenize_without_stop_words:[]
2019-02-28 15:26:33	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'amount'] and stem_without_stop_words:[]
2019-02-28 15:26:33	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:26:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:26:33	DEBUG	Ngram handler ==>> unigram:['recharg', 'amount'] == bigram:['recharg amount'] == trigram:[]
2019-02-28 15:26:33	DEBUG	Punctuation handler ==>> text to process:amount data
2019-02-28 15:26:33	DEBUG	Tokenization handler ==>> takens:['amount', 'data'] and tokenize_without_stop_words:[]
2019-02-28 15:26:33	DEBUG	Stemmer handler ==>> stem_tokens:['amount', 'data'] and stem_without_stop_words:[]
2019-02-28 15:26:33	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:26:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:26:33	DEBUG	Ngram handler ==>> unigram:['amount', 'data'] == bigram:['amount data'] == trigram:[]
2019-02-28 15:26:33	DEBUG	Punctuation handler ==>> text to process:recharge amount
2019-02-28 15:26:33	DEBUG	Tokenization handler ==>> takens:['recharge', 'amount'] and tokenize_without_stop_words:[]
2019-02-28 15:26:33	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'amount'] and stem_without_stop_words:[]
2019-02-28 15:26:33	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:26:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:26:33	DEBUG	Ngram handler ==>> unigram:['recharg', 'amount'] == bigram:['recharg amount'] == trigram:[]
2019-02-28 15:26:44	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-02-28 15:26:44	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-02-28 15:26:44	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-02-28 15:26:44	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:26:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:26:44	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-02-28 15:26:44	DEBUG	Punctuation handler ==>> text to process:can you recharge
2019-02-28 15:26:44	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge'] and tokenize_without_stop_words:[]
2019-02-28 15:26:44	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg'] and stem_without_stop_words:[]
2019-02-28 15:26:44	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:26:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:26:44	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['you recharg'] == trigram:['can you recharg']
2019-02-28 15:26:44	DEBUG	Punctuation handler ==>> text to process:recharge mobile number
2019-02-28 15:26:44	DEBUG	Tokenization handler ==>> takens:['recharge', 'mobile', 'number'] and tokenize_without_stop_words:[]
2019-02-28 15:26:44	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'mobil', 'number'] and stem_without_stop_words:[]
2019-02-28 15:26:44	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:26:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:26:44	DEBUG	Ngram handler ==>> unigram:['recharg', 'mobil'] == bigram:['recharg mobil', 'mobil number'] == trigram:['recharg mobil number']
2019-02-28 15:26:44	DEBUG	Punctuation handler ==>> text to process:enter your mobile number
2019-02-28 15:26:44	DEBUG	Tokenization handler ==>> takens:['enter', 'your', 'mobile', 'number'] and tokenize_without_stop_words:[]
2019-02-28 15:26:44	DEBUG	Stemmer handler ==>> stem_tokens:['enter', 'your', 'mobil', 'number'] and stem_without_stop_words:[]
2019-02-28 15:26:44	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:26:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:26:44	DEBUG	Ngram handler ==>> unigram:['enter', 'mobil'] == bigram:['enter your', 'your mobil', 'mobil number'] == trigram:['enter your mobil', 'your mobil number']
2019-02-28 15:26:44	DEBUG	Punctuation handler ==>> text to process:amount data
2019-02-28 15:26:44	DEBUG	Tokenization handler ==>> takens:['amount', 'data'] and tokenize_without_stop_words:[]
2019-02-28 15:26:44	DEBUG	Stemmer handler ==>> stem_tokens:['amount', 'data'] and stem_without_stop_words:[]
2019-02-28 15:26:44	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:26:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:26:44	DEBUG	Ngram handler ==>> unigram:['amount', 'data'] == bigram:['amount data'] == trigram:[]
2019-02-28 15:26:44	DEBUG	Punctuation handler ==>> text to process:recharge amount
2019-02-28 15:26:44	DEBUG	Tokenization handler ==>> takens:['recharge', 'amount'] and tokenize_without_stop_words:[]
2019-02-28 15:26:44	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'amount'] and stem_without_stop_words:[]
2019-02-28 15:26:44	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:26:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:26:44	DEBUG	Ngram handler ==>> unigram:['recharg', 'amount'] == bigram:['recharg amount'] == trigram:[]
2019-02-28 15:26:44	DEBUG	Punctuation handler ==>> text to process:recharge amount
2019-02-28 15:26:44	DEBUG	Tokenization handler ==>> takens:['recharge', 'amount'] and tokenize_without_stop_words:[]
2019-02-28 15:26:44	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'amount'] and stem_without_stop_words:[]
2019-02-28 15:26:44	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:26:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:26:44	DEBUG	Ngram handler ==>> unigram:['recharg', 'amount'] == bigram:['recharg amount'] == trigram:[]
2019-02-28 15:28:43	DEBUG	Punctuation handler ==>> text to process:travel from one city to other city
2019-02-28 15:28:43	DEBUG	Tokenization handler ==>> takens:['travel', 'from', 'one', 'city', 'to', 'other', 'city'] and tokenize_without_stop_words:[]
2019-02-28 15:28:43	DEBUG	Stemmer handler ==>> stem_tokens:['travel', 'from', 'one', 'citi', 'to', 'other', 'citi'] and stem_without_stop_words:[]
2019-02-28 15:28:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:28:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:28:43	DEBUG	Ngram handler ==>> unigram:['travel', 'one', 'citi', 'citi'] == bigram:['travel from', 'from one', 'one citi', 'citi to', 'other citi'] == trigram:['travel from one', 'from one citi', 'one citi to', 'citi to other', 'to other citi']
2019-02-28 15:28:43	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-02-28 15:28:43	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-02-28 15:28:43	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-02-28 15:28:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:28:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:28:43	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-02-28 15:28:43	DEBUG	Punctuation handler ==>> text to process:i want to book travel
2019-02-28 15:28:43	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'book', 'travel'] and tokenize_without_stop_words:[]
2019-02-28 15:28:43	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'book', 'travel'] and stem_without_stop_words:[]
2019-02-28 15:28:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:28:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:28:43	DEBUG	Ngram handler ==>> unigram:['book', 'travel'] == bigram:['to book', 'book travel'] == trigram:['want to book', 'to book travel']
2019-02-28 15:28:43	DEBUG	Punctuation handler ==>> text to process:travel
2019-02-28 15:28:43	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-02-28 15:28:43	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-02-28 15:28:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:28:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:28:43	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-02-28 15:28:43	DEBUG	Punctuation handler ==>> text to process:i want to travel
2019-02-28 15:28:43	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'travel'] and tokenize_without_stop_words:[]
2019-02-28 15:28:43	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'travel'] and stem_without_stop_words:[]
2019-02-28 15:28:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:28:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:28:43	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:['to travel'] == trigram:['want to travel']
2019-02-28 15:28:43	DEBUG	Punctuation handler ==>> text to process:ask to city
2019-02-28 15:28:43	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'city'] and tokenize_without_stop_words:[]
2019-02-28 15:28:43	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'citi'] and stem_without_stop_words:[]
2019-02-28 15:28:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:28:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:28:43	DEBUG	Ngram handler ==>> unigram:['citi'] == bigram:['to citi'] == trigram:['ask to citi']
2019-02-28 15:28:55	DEBUG	Punctuation handler ==>> text to process:book
2019-02-28 15:28:55	DEBUG	Tokenization handler ==>> takens:['book'] and tokenize_without_stop_words:[]
2019-02-28 15:28:55	DEBUG	Stemmer handler ==>> stem_tokens:['book'] and stem_without_stop_words:[]
2019-02-28 15:28:55	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:28:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:28:55	DEBUG	Ngram handler ==>> unigram:['book'] == bigram:[] == trigram:[]
2019-02-28 15:28:56	DEBUG	Punctuation handler ==>> text to process:book
2019-02-28 15:28:56	DEBUG	Tokenization handler ==>> takens:['book'] and tokenize_without_stop_words:[]
2019-02-28 15:28:56	DEBUG	Stemmer handler ==>> stem_tokens:['book'] and stem_without_stop_words:[]
2019-02-28 15:28:58	DEBUG	lemmatization handler ==>> lemma_tokens:['book'] and lemma_without_stop_words:[]
2019-02-28 15:28:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:28:58	DEBUG	Ngram handler ==>> unigram:['book'] == bigram:[] == trigram:[]
2019-02-28 15:30:23	DEBUG	Punctuation handler ==>> text to process:book
2019-02-28 15:30:23	DEBUG	Tokenization handler ==>> takens:['book'] and tokenize_without_stop_words:[]
2019-02-28 15:30:23	DEBUG	Stemmer handler ==>> stem_tokens:['book'] and stem_without_stop_words:[]
2019-02-28 15:30:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:30:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:30:23	DEBUG	Ngram handler ==>> unigram:['book'] == bigram:[] == trigram:[]
2019-02-28 15:30:24	DEBUG	Punctuation handler ==>> text to process:book
2019-02-28 15:30:24	DEBUG	Tokenization handler ==>> takens:['book'] and tokenize_without_stop_words:[]
2019-02-28 15:30:24	DEBUG	Stemmer handler ==>> stem_tokens:['book'] and stem_without_stop_words:[]
2019-02-28 15:30:24	DEBUG	lemmatization handler ==>> lemma_tokens:['book'] and lemma_without_stop_words:[]
2019-02-28 15:30:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:30:24	DEBUG	Ngram handler ==>> unigram:['book'] == bigram:[] == trigram:[]
2019-02-28 15:30:45	DEBUG	Punctuation handler ==>> text to process:book
2019-02-28 15:30:45	DEBUG	Tokenization handler ==>> takens:['book'] and tokenize_without_stop_words:[]
2019-02-28 15:30:45	DEBUG	Stemmer handler ==>> stem_tokens:['book'] and stem_without_stop_words:[]
2019-02-28 15:30:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:30:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:30:45	DEBUG	Ngram handler ==>> unigram:['book'] == bigram:[] == trigram:[]
2019-02-28 15:30:45	DEBUG	Punctuation handler ==>> text to process:book
2019-02-28 15:30:45	DEBUG	Tokenization handler ==>> takens:['book'] and tokenize_without_stop_words:[]
2019-02-28 15:30:45	DEBUG	Stemmer handler ==>> stem_tokens:['book'] and stem_without_stop_words:[]
2019-02-28 15:30:45	DEBUG	lemmatization handler ==>> lemma_tokens:['book'] and lemma_without_stop_words:[]
2019-02-28 15:30:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:30:45	DEBUG	Ngram handler ==>> unigram:['book'] == bigram:[] == trigram:[]
2019-02-28 15:31:51	DEBUG	Punctuation handler ==>> text to process:recharge
2019-02-28 15:31:51	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-02-28 15:31:51	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-02-28 15:31:51	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:31:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:31:51	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-02-28 15:31:51	DEBUG	Punctuation handler ==>> text to process:recharge
2019-02-28 15:31:51	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-02-28 15:31:51	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-02-28 15:31:51	DEBUG	lemmatization handler ==>> lemma_tokens:['recharge'] and lemma_without_stop_words:[]
2019-02-28 15:31:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:31:51	DEBUG	Ngram handler ==>> unigram:['recharge'] == bigram:[] == trigram:[]
2019-02-28 15:32:19	DEBUG	Punctuation handler ==>> text to process:recharage
2019-02-28 15:32:19	DEBUG	Tokenization handler ==>> takens:['recharage'] and tokenize_without_stop_words:[]
2019-02-28 15:32:19	DEBUG	Stemmer handler ==>> stem_tokens:['recharag'] and stem_without_stop_words:[]
2019-02-28 15:32:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:32:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:32:19	DEBUG	Ngram handler ==>> unigram:['recharag'] == bigram:[] == trigram:[]
2019-02-28 15:32:19	DEBUG	Punctuation handler ==>> text to process:recharage
2019-02-28 15:32:19	DEBUG	Tokenization handler ==>> takens:['recharage'] and tokenize_without_stop_words:[]
2019-02-28 15:32:19	DEBUG	Stemmer handler ==>> stem_tokens:['recharag'] and stem_without_stop_words:[]
2019-02-28 15:32:19	DEBUG	lemmatization handler ==>> lemma_tokens:['recharage'] and lemma_without_stop_words:[]
2019-02-28 15:32:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:32:19	DEBUG	Ngram handler ==>> unigram:['recharage'] == bigram:[] == trigram:[]
2019-02-28 15:33:37	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-02-28 15:33:37	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-02-28 15:33:37	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-02-28 15:33:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:33:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:33:37	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:[] == trigram:[]
2019-02-28 15:33:37	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-02-28 15:33:37	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-02-28 15:33:37	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-02-28 15:33:37	DEBUG	lemmatization handler ==>> lemma_tokens:['rechrage'] and lemma_without_stop_words:[]
2019-02-28 15:33:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:33:37	DEBUG	Ngram handler ==>> unigram:['rechrage'] == bigram:[] == trigram:[]
2019-02-28 15:48:34	DEBUG	Punctuation handler ==>> text to process:book
2019-02-28 15:48:34	DEBUG	Tokenization handler ==>> takens:['book'] and tokenize_without_stop_words:[]
2019-02-28 15:48:34	DEBUG	Stemmer handler ==>> stem_tokens:['book'] and stem_without_stop_words:[]
2019-02-28 15:48:34	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:48:34	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:48:34	DEBUG	Ngram handler ==>> unigram:['book'] == bigram:[] == trigram:[]
2019-02-28 15:48:34	DEBUG	Punctuation handler ==>> text to process:book
2019-02-28 15:48:34	DEBUG	Tokenization handler ==>> takens:['book'] and tokenize_without_stop_words:[]
2019-02-28 15:48:34	DEBUG	Stemmer handler ==>> stem_tokens:['book'] and stem_without_stop_words:[]
2019-02-28 15:48:34	DEBUG	lemmatization handler ==>> lemma_tokens:['book'] and lemma_without_stop_words:[]
2019-02-28 15:48:34	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:48:34	DEBUG	Ngram handler ==>> unigram:['book'] == bigram:[] == trigram:[]
2019-02-28 15:49:28	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-02-28 15:49:28	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-02-28 15:49:28	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-02-28 15:49:28	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:49:28	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:49:28	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:[] == trigram:[]
2019-02-28 15:49:28	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-02-28 15:49:28	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-02-28 15:49:28	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-02-28 15:49:28	DEBUG	lemmatization handler ==>> lemma_tokens:['rechrage'] and lemma_without_stop_words:[]
2019-02-28 15:49:28	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:49:28	DEBUG	Ngram handler ==>> unigram:['rechrage'] == bigram:[] == trigram:[]
2019-02-28 15:50:12	DEBUG	Punctuation handler ==>> text to process:book
2019-02-28 15:50:12	DEBUG	Tokenization handler ==>> takens:['book'] and tokenize_without_stop_words:[]
2019-02-28 15:50:12	DEBUG	Stemmer handler ==>> stem_tokens:['book'] and stem_without_stop_words:[]
2019-02-28 15:50:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 15:50:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:50:12	DEBUG	Ngram handler ==>> unigram:['book'] == bigram:[] == trigram:[]
2019-02-28 15:50:12	DEBUG	Punctuation handler ==>> text to process:book
2019-02-28 15:50:12	DEBUG	Tokenization handler ==>> takens:['book'] and tokenize_without_stop_words:[]
2019-02-28 15:50:12	DEBUG	Stemmer handler ==>> stem_tokens:['book'] and stem_without_stop_words:[]
2019-02-28 15:50:12	DEBUG	lemmatization handler ==>> lemma_tokens:['book'] and lemma_without_stop_words:[]
2019-02-28 15:50:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 15:50:12	DEBUG	Ngram handler ==>> unigram:['book'] == bigram:[] == trigram:[]
2019-02-28 16:01:39	DEBUG	Punctuation handler ==>> text to process:book
2019-02-28 16:01:39	DEBUG	Tokenization handler ==>> takens:['book'] and tokenize_without_stop_words:[]
2019-02-28 16:01:39	DEBUG	Stemmer handler ==>> stem_tokens:['book'] and stem_without_stop_words:[]
2019-02-28 16:01:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 16:01:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 16:01:39	DEBUG	Ngram handler ==>> unigram:['book'] == bigram:[] == trigram:[]
2019-02-28 16:01:39	DEBUG	Punctuation handler ==>> text to process:book
2019-02-28 16:01:39	DEBUG	Tokenization handler ==>> takens:['book'] and tokenize_without_stop_words:[]
2019-02-28 16:01:39	DEBUG	Stemmer handler ==>> stem_tokens:['book'] and stem_without_stop_words:[]
2019-02-28 16:01:39	DEBUG	lemmatization handler ==>> lemma_tokens:['book'] and lemma_without_stop_words:[]
2019-02-28 16:01:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 16:01:39	DEBUG	Ngram handler ==>> unigram:['book'] == bigram:[] == trigram:[]
2019-02-28 16:01:46	DEBUG	Punctuation handler ==>> text to process:recharage
2019-02-28 16:01:46	DEBUG	Tokenization handler ==>> takens:['recharage'] and tokenize_without_stop_words:[]
2019-02-28 16:01:46	DEBUG	Stemmer handler ==>> stem_tokens:['recharag'] and stem_without_stop_words:[]
2019-02-28 16:01:46	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-02-28 16:01:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 16:01:46	DEBUG	Ngram handler ==>> unigram:['recharag'] == bigram:[] == trigram:[]
2019-02-28 16:01:46	DEBUG	Punctuation handler ==>> text to process:recharage
2019-02-28 16:01:46	DEBUG	Tokenization handler ==>> takens:['recharage'] and tokenize_without_stop_words:[]
2019-02-28 16:01:46	DEBUG	Stemmer handler ==>> stem_tokens:['recharag'] and stem_without_stop_words:[]
2019-02-28 16:01:46	DEBUG	lemmatization handler ==>> lemma_tokens:['recharage'] and lemma_without_stop_words:[]
2019-02-28 16:01:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-02-28 16:01:46	DEBUG	Ngram handler ==>> unigram:['recharage'] == bigram:[] == trigram:[]
2019-03-01 12:05:20	DEBUG	Punctuation handler ==>> text to process:book
2019-03-01 12:05:20	DEBUG	Tokenization handler ==>> takens:['book'] and tokenize_without_stop_words:[]
2019-03-01 12:05:20	DEBUG	Stemmer handler ==>> stem_tokens:['book'] and stem_without_stop_words:[]
2019-03-01 12:05:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:05:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:05:20	DEBUG	Ngram handler ==>> unigram:['book'] == bigram:[] == trigram:[]
2019-03-01 12:05:21	DEBUG	Punctuation handler ==>> text to process:book
2019-03-01 12:05:21	DEBUG	Tokenization handler ==>> takens:['book'] and tokenize_without_stop_words:[]
2019-03-01 12:05:21	DEBUG	Stemmer handler ==>> stem_tokens:['book'] and stem_without_stop_words:[]
2019-03-01 12:05:24	DEBUG	lemmatization handler ==>> lemma_tokens:['book'] and lemma_without_stop_words:[]
2019-03-01 12:05:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:05:24	DEBUG	Ngram handler ==>> unigram:['book'] == bigram:[] == trigram:[]
2019-03-01 12:07:20	DEBUG	Punctuation handler ==>> text to process:book
2019-03-01 12:07:20	DEBUG	Tokenization handler ==>> takens:['book'] and tokenize_without_stop_words:[]
2019-03-01 12:07:20	DEBUG	Stemmer handler ==>> stem_tokens:['book'] and stem_without_stop_words:[]
2019-03-01 12:07:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:07:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:07:20	DEBUG	Ngram handler ==>> unigram:['book'] == bigram:[] == trigram:[]
2019-03-01 12:07:20	DEBUG	Punctuation handler ==>> text to process:book
2019-03-01 12:07:20	DEBUG	Tokenization handler ==>> takens:['book'] and tokenize_without_stop_words:[]
2019-03-01 12:07:20	DEBUG	Stemmer handler ==>> stem_tokens:['book'] and stem_without_stop_words:[]
2019-03-01 12:07:20	DEBUG	lemmatization handler ==>> lemma_tokens:['book'] and lemma_without_stop_words:[]
2019-03-01 12:07:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:07:20	DEBUG	Ngram handler ==>> unigram:['book'] == bigram:[] == trigram:[]
2019-03-01 12:07:21	DEBUG	Punctuation handler ==>> text to process:book
2019-03-01 12:07:21	DEBUG	Tokenization handler ==>> takens:['book'] and tokenize_without_stop_words:[]
2019-03-01 12:07:21	DEBUG	Stemmer handler ==>> stem_tokens:['book'] and stem_without_stop_words:[]
2019-03-01 12:07:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:07:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:07:21	DEBUG	Ngram handler ==>> unigram:['book'] == bigram:[] == trigram:[]
2019-03-01 12:08:04	DEBUG	Punctuation handler ==>> text to process:book
2019-03-01 12:08:04	DEBUG	Tokenization handler ==>> takens:['book'] and tokenize_without_stop_words:[]
2019-03-01 12:08:04	DEBUG	Stemmer handler ==>> stem_tokens:['book'] and stem_without_stop_words:[]
2019-03-01 12:08:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:08:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:08:04	DEBUG	Ngram handler ==>> unigram:['book'] == bigram:[] == trigram:[]
2019-03-01 12:09:59	DEBUG	Punctuation handler ==>> text to process:book
2019-03-01 12:09:59	DEBUG	Tokenization handler ==>> takens:['book'] and tokenize_without_stop_words:[]
2019-03-01 12:09:59	DEBUG	Stemmer handler ==>> stem_tokens:['book'] and stem_without_stop_words:[]
2019-03-01 12:09:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:09:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:09:59	DEBUG	Ngram handler ==>> unigram:['book'] == bigram:[] == trigram:[]
2019-03-01 12:10:21	DEBUG	Punctuation handler ==>> text to process:book
2019-03-01 12:10:21	DEBUG	Tokenization handler ==>> takens:['book'] and tokenize_without_stop_words:[]
2019-03-01 12:10:21	DEBUG	Stemmer handler ==>> stem_tokens:['book'] and stem_without_stop_words:[]
2019-03-01 12:10:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:10:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:10:21	DEBUG	Ngram handler ==>> unigram:['book'] == bigram:[] == trigram:[]
2019-03-01 12:11:00	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-03-01 12:11:00	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-03-01 12:11:00	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-03-01 12:11:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:11:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:11:00	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:[] == trigram:[]
2019-03-01 12:14:13	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-03-01 12:14:13	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-03-01 12:14:13	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-03-01 12:14:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:14:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:14:13	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:[] == trigram:[]
2019-03-01 12:18:02	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 12:18:02	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 12:18:02	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 12:18:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:18:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:18:02	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 12:18:02	DEBUG	Punctuation handler ==>> text to process:can you recharge
2019-03-01 12:18:02	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 12:18:02	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg'] and stem_without_stop_words:[]
2019-03-01 12:18:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:18:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:18:02	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['you recharg'] == trigram:['can you recharg']
2019-03-01 12:18:02	DEBUG	Punctuation handler ==>> text to process:recharge mobile number
2019-03-01 12:18:02	DEBUG	Tokenization handler ==>> takens:['recharge', 'mobile', 'number'] and tokenize_without_stop_words:[]
2019-03-01 12:18:02	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'mobil', 'number'] and stem_without_stop_words:[]
2019-03-01 12:18:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:18:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:18:02	DEBUG	Ngram handler ==>> unigram:['recharg', 'mobil'] == bigram:['recharg mobil', 'mobil number'] == trigram:['recharg mobil number']
2019-03-01 12:18:02	DEBUG	Punctuation handler ==>> text to process:enter your mobile number
2019-03-01 12:18:02	DEBUG	Tokenization handler ==>> takens:['enter', 'your', 'mobile', 'number'] and tokenize_without_stop_words:[]
2019-03-01 12:18:02	DEBUG	Stemmer handler ==>> stem_tokens:['enter', 'your', 'mobil', 'number'] and stem_without_stop_words:[]
2019-03-01 12:18:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:18:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:18:02	DEBUG	Ngram handler ==>> unigram:['enter', 'mobil'] == bigram:['enter your', 'your mobil', 'mobil number'] == trigram:['enter your mobil', 'your mobil number']
2019-03-01 12:18:02	DEBUG	Punctuation handler ==>> text to process:amount data
2019-03-01 12:18:02	DEBUG	Tokenization handler ==>> takens:['amount', 'data'] and tokenize_without_stop_words:[]
2019-03-01 12:18:02	DEBUG	Stemmer handler ==>> stem_tokens:['amount', 'data'] and stem_without_stop_words:[]
2019-03-01 12:18:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:18:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:18:02	DEBUG	Ngram handler ==>> unigram:['amount', 'data'] == bigram:['amount data'] == trigram:[]
2019-03-01 12:18:02	DEBUG	Punctuation handler ==>> text to process:recharge amount
2019-03-01 12:18:02	DEBUG	Tokenization handler ==>> takens:['recharge', 'amount'] and tokenize_without_stop_words:[]
2019-03-01 12:18:02	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'amount'] and stem_without_stop_words:[]
2019-03-01 12:18:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:18:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:18:02	DEBUG	Ngram handler ==>> unigram:['recharg', 'amount'] == bigram:['recharg amount'] == trigram:[]
2019-03-01 12:18:02	DEBUG	Punctuation handler ==>> text to process:recharage data
2019-03-01 12:18:02	DEBUG	Tokenization handler ==>> takens:['recharage', 'data'] and tokenize_without_stop_words:[]
2019-03-01 12:18:02	DEBUG	Stemmer handler ==>> stem_tokens:['recharag', 'data'] and stem_without_stop_words:[]
2019-03-01 12:18:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:18:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:18:02	DEBUG	Ngram handler ==>> unigram:['recharag', 'data'] == bigram:['recharag data'] == trigram:[]
2019-03-01 12:18:02	DEBUG	Punctuation handler ==>> text to process:recharge amount
2019-03-01 12:18:02	DEBUG	Tokenization handler ==>> takens:['recharge', 'amount'] and tokenize_without_stop_words:[]
2019-03-01 12:18:02	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'amount'] and stem_without_stop_words:[]
2019-03-01 12:18:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:18:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:18:02	DEBUG	Ngram handler ==>> unigram:['recharg', 'amount'] == bigram:['recharg amount'] == trigram:[]
2019-03-01 12:18:30	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-03-01 12:18:30	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-03-01 12:18:30	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-03-01 12:18:30	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:18:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:18:30	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:[] == trigram:[]
2019-03-01 12:19:23	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-03-01 12:19:23	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-03-01 12:19:23	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-03-01 12:19:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:19:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:19:23	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:[] == trigram:[]
2019-03-01 12:20:35	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-03-01 12:20:35	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-03-01 12:20:35	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-03-01 12:20:35	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:20:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:20:35	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:[] == trigram:[]
2019-03-01 12:21:13	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-03-01 12:21:13	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-03-01 12:21:13	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-03-01 12:21:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:21:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:21:13	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:[] == trigram:[]
2019-03-01 12:21:26	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-03-01 12:21:26	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-03-01 12:21:26	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-03-01 12:21:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:21:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:21:26	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:[] == trigram:[]
2019-03-01 12:22:13	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-03-01 12:22:13	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-03-01 12:22:13	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-03-01 12:22:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:22:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:22:13	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:[] == trigram:[]
2019-03-01 12:23:04	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-03-01 12:23:04	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-03-01 12:23:04	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-03-01 12:23:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:23:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:23:04	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:[] == trigram:[]
2019-03-01 12:23:28	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-03-01 12:23:28	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-03-01 12:23:28	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-03-01 12:23:28	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:23:28	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:23:28	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:[] == trigram:[]
2019-03-01 12:24:15	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 12:24:15	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 12:24:15	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 12:24:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:24:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:24:15	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 12:24:15	DEBUG	Punctuation handler ==>> text to process:can you recharge
2019-03-01 12:24:15	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 12:24:15	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg'] and stem_without_stop_words:[]
2019-03-01 12:24:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:24:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:24:15	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['you recharg'] == trigram:['can you recharg']
2019-03-01 12:24:15	DEBUG	Punctuation handler ==>> text to process:recharge mobile number
2019-03-01 12:24:15	DEBUG	Tokenization handler ==>> takens:['recharge', 'mobile', 'number'] and tokenize_without_stop_words:[]
2019-03-01 12:24:15	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'mobil', 'number'] and stem_without_stop_words:[]
2019-03-01 12:24:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:24:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:24:15	DEBUG	Ngram handler ==>> unigram:['recharg', 'mobil'] == bigram:['recharg mobil', 'mobil number'] == trigram:['recharg mobil number']
2019-03-01 12:24:15	DEBUG	Punctuation handler ==>> text to process:enter your mobile number
2019-03-01 12:24:15	DEBUG	Tokenization handler ==>> takens:['enter', 'your', 'mobile', 'number'] and tokenize_without_stop_words:[]
2019-03-01 12:24:15	DEBUG	Stemmer handler ==>> stem_tokens:['enter', 'your', 'mobil', 'number'] and stem_without_stop_words:[]
2019-03-01 12:24:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:24:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:24:15	DEBUG	Ngram handler ==>> unigram:['enter', 'mobil'] == bigram:['enter your', 'your mobil', 'mobil number'] == trigram:['enter your mobil', 'your mobil number']
2019-03-01 12:24:15	DEBUG	Punctuation handler ==>> text to process:data here
2019-03-01 12:24:15	DEBUG	Tokenization handler ==>> takens:['data', 'here'] and tokenize_without_stop_words:[]
2019-03-01 12:24:15	DEBUG	Stemmer handler ==>> stem_tokens:['data', 'here'] and stem_without_stop_words:[]
2019-03-01 12:24:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:24:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:24:15	DEBUG	Ngram handler ==>> unigram:['data'] == bigram:['data here'] == trigram:[]
2019-03-01 12:24:15	DEBUG	Punctuation handler ==>> text to process:amount data
2019-03-01 12:24:15	DEBUG	Tokenization handler ==>> takens:['amount', 'data'] and tokenize_without_stop_words:[]
2019-03-01 12:24:15	DEBUG	Stemmer handler ==>> stem_tokens:['amount', 'data'] and stem_without_stop_words:[]
2019-03-01 12:24:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:24:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:24:15	DEBUG	Ngram handler ==>> unigram:['amount', 'data'] == bigram:['amount data'] == trigram:[]
2019-03-01 12:24:15	DEBUG	Punctuation handler ==>> text to process:recharge amount
2019-03-01 12:24:15	DEBUG	Tokenization handler ==>> takens:['recharge', 'amount'] and tokenize_without_stop_words:[]
2019-03-01 12:24:15	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'amount'] and stem_without_stop_words:[]
2019-03-01 12:24:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:24:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:24:15	DEBUG	Ngram handler ==>> unigram:['recharg', 'amount'] == bigram:['recharg amount'] == trigram:[]
2019-03-01 12:24:15	DEBUG	Punctuation handler ==>> text to process:recharage data
2019-03-01 12:24:15	DEBUG	Tokenization handler ==>> takens:['recharage', 'data'] and tokenize_without_stop_words:[]
2019-03-01 12:24:15	DEBUG	Stemmer handler ==>> stem_tokens:['recharag', 'data'] and stem_without_stop_words:[]
2019-03-01 12:24:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:24:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:24:15	DEBUG	Ngram handler ==>> unigram:['recharag', 'data'] == bigram:['recharag data'] == trigram:[]
2019-03-01 12:24:15	DEBUG	Punctuation handler ==>> text to process:recharge amount
2019-03-01 12:24:15	DEBUG	Tokenization handler ==>> takens:['recharge', 'amount'] and tokenize_without_stop_words:[]
2019-03-01 12:24:15	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'amount'] and stem_without_stop_words:[]
2019-03-01 12:24:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:24:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:24:15	DEBUG	Ngram handler ==>> unigram:['recharg', 'amount'] == bigram:['recharg amount'] == trigram:[]
2019-03-01 12:24:22	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-03-01 12:24:22	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-03-01 12:24:22	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-03-01 12:24:22	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:24:22	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:24:22	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:[] == trigram:[]
2019-03-01 12:24:42	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-03-01 12:24:42	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-03-01 12:24:42	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-03-01 12:24:42	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:24:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:24:42	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:[] == trigram:[]
2019-03-01 12:25:33	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 12:25:33	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 12:25:33	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 12:25:33	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:25:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:25:33	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 12:25:33	DEBUG	Punctuation handler ==>> text to process:can you recharge
2019-03-01 12:25:33	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 12:25:33	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg'] and stem_without_stop_words:[]
2019-03-01 12:25:33	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:25:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:25:33	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['you recharg'] == trigram:['can you recharg']
2019-03-01 12:25:33	DEBUG	Punctuation handler ==>> text to process:recharge mobile number
2019-03-01 12:25:33	DEBUG	Tokenization handler ==>> takens:['recharge', 'mobile', 'number'] and tokenize_without_stop_words:[]
2019-03-01 12:25:33	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'mobil', 'number'] and stem_without_stop_words:[]
2019-03-01 12:25:33	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:25:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:25:33	DEBUG	Ngram handler ==>> unigram:['recharg', 'mobil'] == bigram:['recharg mobil', 'mobil number'] == trigram:['recharg mobil number']
2019-03-01 12:25:33	DEBUG	Punctuation handler ==>> text to process:enter your mobile number
2019-03-01 12:25:33	DEBUG	Tokenization handler ==>> takens:['enter', 'your', 'mobile', 'number'] and tokenize_without_stop_words:[]
2019-03-01 12:25:33	DEBUG	Stemmer handler ==>> stem_tokens:['enter', 'your', 'mobil', 'number'] and stem_without_stop_words:[]
2019-03-01 12:25:33	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:25:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:25:33	DEBUG	Ngram handler ==>> unigram:['enter', 'mobil'] == bigram:['enter your', 'your mobil', 'mobil number'] == trigram:['enter your mobil', 'your mobil number']
2019-03-01 12:25:33	DEBUG	Punctuation handler ==>> text to process:data here
2019-03-01 12:25:33	DEBUG	Tokenization handler ==>> takens:['data', 'here'] and tokenize_without_stop_words:[]
2019-03-01 12:25:33	DEBUG	Stemmer handler ==>> stem_tokens:['data', 'here'] and stem_without_stop_words:[]
2019-03-01 12:25:33	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:25:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:25:33	DEBUG	Ngram handler ==>> unigram:['data'] == bigram:['data here'] == trigram:[]
2019-03-01 12:25:33	DEBUG	Punctuation handler ==>> text to process:amount data
2019-03-01 12:25:33	DEBUG	Tokenization handler ==>> takens:['amount', 'data'] and tokenize_without_stop_words:[]
2019-03-01 12:25:33	DEBUG	Stemmer handler ==>> stem_tokens:['amount', 'data'] and stem_without_stop_words:[]
2019-03-01 12:25:33	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:25:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:25:33	DEBUG	Ngram handler ==>> unigram:['amount', 'data'] == bigram:['amount data'] == trigram:[]
2019-03-01 12:25:33	DEBUG	Punctuation handler ==>> text to process:data
2019-03-01 12:25:33	DEBUG	Tokenization handler ==>> takens:['data'] and tokenize_without_stop_words:[]
2019-03-01 12:25:33	DEBUG	Stemmer handler ==>> stem_tokens:['data'] and stem_without_stop_words:[]
2019-03-01 12:25:33	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:25:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:25:33	DEBUG	Ngram handler ==>> unigram:['data'] == bigram:[] == trigram:[]
2019-03-01 12:25:33	DEBUG	Punctuation handler ==>> text to process:recharge amount
2019-03-01 12:25:33	DEBUG	Tokenization handler ==>> takens:['recharge', 'amount'] and tokenize_without_stop_words:[]
2019-03-01 12:25:33	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'amount'] and stem_without_stop_words:[]
2019-03-01 12:25:33	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:25:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:25:33	DEBUG	Ngram handler ==>> unigram:['recharg', 'amount'] == bigram:['recharg amount'] == trigram:[]
2019-03-01 12:25:33	DEBUG	Punctuation handler ==>> text to process:recharage data
2019-03-01 12:25:33	DEBUG	Tokenization handler ==>> takens:['recharage', 'data'] and tokenize_without_stop_words:[]
2019-03-01 12:25:33	DEBUG	Stemmer handler ==>> stem_tokens:['recharag', 'data'] and stem_without_stop_words:[]
2019-03-01 12:25:33	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:25:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:25:33	DEBUG	Ngram handler ==>> unigram:['recharag', 'data'] == bigram:['recharag data'] == trigram:[]
2019-03-01 12:25:33	DEBUG	Punctuation handler ==>> text to process:recharge amount
2019-03-01 12:25:33	DEBUG	Tokenization handler ==>> takens:['recharge', 'amount'] and tokenize_without_stop_words:[]
2019-03-01 12:25:33	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'amount'] and stem_without_stop_words:[]
2019-03-01 12:25:33	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:25:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:25:33	DEBUG	Ngram handler ==>> unigram:['recharg', 'amount'] == bigram:['recharg amount'] == trigram:[]
2019-03-01 12:26:16	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-03-01 12:26:16	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-03-01 12:26:16	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-03-01 12:26:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:26:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:26:16	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:[] == trigram:[]
2019-03-01 12:27:40	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-03-01 12:27:40	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-03-01 12:27:40	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-03-01 12:27:40	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:27:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:27:40	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:[] == trigram:[]
2019-03-01 12:28:56	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-03-01 12:28:56	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-03-01 12:28:56	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-03-01 12:28:56	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:28:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:28:56	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:[] == trigram:[]
2019-03-01 12:31:46	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 12:31:46	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 12:31:46	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 12:31:46	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:31:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:31:46	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 12:36:11	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 12:36:11	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 12:36:11	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 12:36:11	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:36:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:36:11	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 12:36:47	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 12:36:47	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 12:36:47	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 12:36:47	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:36:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:36:47	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 12:36:54	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 12:36:54	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 12:36:54	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 12:36:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:36:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:36:54	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 12:37:21	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 12:37:21	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 12:37:21	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 12:37:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:37:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:37:21	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 12:40:29	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 12:40:29	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:40:29	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 12:40:29	DEBUG	Punctuation handler ==>> text to process:can you recharge
2019-03-01 12:40:29	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg'] and stem_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:40:29	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['you recharg'] == trigram:['can you recharg']
2019-03-01 12:40:29	DEBUG	Punctuation handler ==>> text to process:recharge mobile number
2019-03-01 12:40:29	DEBUG	Tokenization handler ==>> takens:['recharge', 'mobile', 'number'] and tokenize_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'mobil', 'number'] and stem_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:40:29	DEBUG	Ngram handler ==>> unigram:['recharg', 'mobil'] == bigram:['recharg mobil', 'mobil number'] == trigram:['recharg mobil number']
2019-03-01 12:40:29	DEBUG	Punctuation handler ==>> text to process:enter your mobile number
2019-03-01 12:40:29	DEBUG	Tokenization handler ==>> takens:['enter', 'your', 'mobile', 'number'] and tokenize_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	Stemmer handler ==>> stem_tokens:['enter', 'your', 'mobil', 'number'] and stem_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:40:29	DEBUG	Ngram handler ==>> unigram:['enter', 'mobil'] == bigram:['enter your', 'your mobil', 'mobil number'] == trigram:['enter your mobil', 'your mobil number']
2019-03-01 12:40:29	DEBUG	Punctuation handler ==>> text to process:recharge amount
2019-03-01 12:40:29	DEBUG	Tokenization handler ==>> takens:['recharge', 'amount'] and tokenize_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'amount'] and stem_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:40:29	DEBUG	Ngram handler ==>> unigram:['recharg', 'amount'] == bigram:['recharg amount'] == trigram:[]
2019-03-01 12:40:29	DEBUG	Punctuation handler ==>> text to process:data here
2019-03-01 12:40:29	DEBUG	Tokenization handler ==>> takens:['data', 'here'] and tokenize_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	Stemmer handler ==>> stem_tokens:['data', 'here'] and stem_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:40:29	DEBUG	Ngram handler ==>> unigram:['data'] == bigram:['data here'] == trigram:[]
2019-03-01 12:40:29	DEBUG	Punctuation handler ==>> text to process:recharge on my phone
2019-03-01 12:40:29	DEBUG	Tokenization handler ==>> takens:['recharge', 'on', 'my', 'phone'] and tokenize_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'on', 'my', 'phone'] and stem_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:40:29	DEBUG	Ngram handler ==>> unigram:['recharg', 'phone'] == bigram:['recharg on', 'my phone'] == trigram:['recharg on my', 'on my phone']
2019-03-01 12:40:29	DEBUG	Punctuation handler ==>> text to process:recharage data
2019-03-01 12:40:29	DEBUG	Tokenization handler ==>> takens:['recharage', 'data'] and tokenize_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	Stemmer handler ==>> stem_tokens:['recharag', 'data'] and stem_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:40:29	DEBUG	Ngram handler ==>> unigram:['recharag', 'data'] == bigram:['recharag data'] == trigram:[]
2019-03-01 12:40:29	DEBUG	Punctuation handler ==>> text to process:data
2019-03-01 12:40:29	DEBUG	Tokenization handler ==>> takens:['data'] and tokenize_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	Stemmer handler ==>> stem_tokens:['data'] and stem_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:40:29	DEBUG	Ngram handler ==>> unigram:['data'] == bigram:[] == trigram:[]
2019-03-01 12:40:29	DEBUG	Punctuation handler ==>> text to process:amount data
2019-03-01 12:40:29	DEBUG	Tokenization handler ==>> takens:['amount', 'data'] and tokenize_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	Stemmer handler ==>> stem_tokens:['amount', 'data'] and stem_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:40:29	DEBUG	Ngram handler ==>> unigram:['amount', 'data'] == bigram:['amount data'] == trigram:[]
2019-03-01 12:40:29	DEBUG	Punctuation handler ==>> text to process:recharge amount
2019-03-01 12:40:29	DEBUG	Tokenization handler ==>> takens:['recharge', 'amount'] and tokenize_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'amount'] and stem_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:40:29	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:40:29	DEBUG	Ngram handler ==>> unigram:['recharg', 'amount'] == bigram:['recharg amount'] == trigram:[]
2019-03-01 12:45:21	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 12:45:21	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 12:45:21	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 12:45:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:45:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:45:21	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 12:48:06	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 12:48:06	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 12:48:06	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 12:48:06	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 12:48:06	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 12:48:06	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 14:06:01	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 14:06:01	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 14:06:01	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 14:06:01	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 14:06:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 14:06:01	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 14:07:01	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 14:07:01	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 14:07:01	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 14:07:01	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 14:07:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 14:07:01	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 14:26:24	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 14:26:24	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 14:26:24	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 14:26:24	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 14:26:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 14:26:24	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 14:27:11	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 14:27:11	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 14:27:11	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 14:27:11	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 14:27:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 14:27:11	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 14:28:57	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 14:28:57	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 14:28:57	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 14:28:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 14:28:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 14:28:57	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 14:46:20	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 14:46:20	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 14:46:20	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 14:46:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 14:46:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 14:46:20	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 14:47:12	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 14:47:12	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 14:47:12	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 14:47:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 14:47:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 14:47:12	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 14:48:51	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 14:48:51	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 14:48:51	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 14:48:51	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 14:48:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 14:48:51	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 14:49:14	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 14:49:14	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 14:49:14	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 14:49:14	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 14:49:14	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 14:49:14	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 14:50:55	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 14:50:55	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 14:50:55	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 14:50:55	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 14:50:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 14:50:55	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 14:51:18	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 14:51:18	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 14:51:18	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 14:51:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 14:51:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 14:51:18	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 14:51:57	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 14:51:57	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 14:51:57	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 14:51:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 14:51:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 14:51:57	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 14:52:20	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 14:52:20	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 14:52:20	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 14:52:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 14:52:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 14:52:20	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 14:52:34	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 14:52:34	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 14:52:34	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 14:52:34	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 14:52:34	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 14:52:34	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 14:54:50	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 14:54:50	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 14:54:50	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 14:54:50	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 14:54:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 14:54:50	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 15:02:45	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 15:02:45	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 15:02:45	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 15:02:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 15:02:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 15:02:45	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 15:28:46	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 15:28:46	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 15:28:46	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 15:28:46	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 15:28:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 15:28:46	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 15:30:27	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 15:30:27	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 15:30:27	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 15:30:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 15:30:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 15:30:27	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 15:30:56	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 15:30:56	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 15:30:56	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 15:30:56	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 15:30:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 15:30:56	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 15:32:12	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 15:32:12	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 15:32:12	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 15:32:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 15:32:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 15:32:12	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 15:32:42	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 15:32:42	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 15:32:42	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 15:32:42	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 15:32:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 15:32:42	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 15:33:12	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 15:33:12	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 15:33:12	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 15:33:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 15:33:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 15:33:12	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 15:33:36	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 15:33:36	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 15:33:36	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 15:33:36	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 15:33:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 15:33:36	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 15:33:53	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 15:33:53	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 15:33:53	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 15:33:53	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 15:33:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 15:33:53	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 15:34:21	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 15:34:21	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 15:34:21	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 15:34:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 15:34:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 15:34:21	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 15:35:04	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 15:35:04	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 15:35:04	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 15:35:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 15:35:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 15:35:04	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 15:39:21	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 15:39:21	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 15:39:21	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 15:39:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 15:39:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 15:39:21	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 15:40:31	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 15:40:31	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 15:40:31	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 15:40:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 15:40:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 15:40:31	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 15:41:48	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 15:41:48	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 15:41:48	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 15:41:48	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 15:41:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 15:41:48	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 17:35:17	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 17:35:17	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 17:35:17	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 17:35:17	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 17:35:17	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 17:35:17	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 17:36:05	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 17:36:05	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 17:36:05	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 17:36:05	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 17:36:05	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 17:36:05	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 17:42:59	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 17:42:59	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 17:42:59	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 17:42:59	DEBUG	Punctuation handler ==>> text to process:can you recharge
2019-03-01 17:42:59	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg'] and stem_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 17:42:59	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['you recharg'] == trigram:['can you recharg']
2019-03-01 17:42:59	DEBUG	Punctuation handler ==>> text to process:recharge mobile number
2019-03-01 17:42:59	DEBUG	Tokenization handler ==>> takens:['recharge', 'mobile', 'number'] and tokenize_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'mobil', 'number'] and stem_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 17:42:59	DEBUG	Ngram handler ==>> unigram:['recharg', 'mobil'] == bigram:['recharg mobil', 'mobil number'] == trigram:['recharg mobil number']
2019-03-01 17:42:59	DEBUG	Punctuation handler ==>> text to process:enter your mobile number
2019-03-01 17:42:59	DEBUG	Tokenization handler ==>> takens:['enter', 'your', 'mobile', 'number'] and tokenize_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	Stemmer handler ==>> stem_tokens:['enter', 'your', 'mobil', 'number'] and stem_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 17:42:59	DEBUG	Ngram handler ==>> unigram:['enter', 'mobil'] == bigram:['enter your', 'your mobil', 'mobil number'] == trigram:['enter your mobil', 'your mobil number']
2019-03-01 17:42:59	DEBUG	Punctuation handler ==>> text to process:recharge amount
2019-03-01 17:42:59	DEBUG	Tokenization handler ==>> takens:['recharge', 'amount'] and tokenize_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'amount'] and stem_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 17:42:59	DEBUG	Ngram handler ==>> unigram:['recharg', 'amount'] == bigram:['recharg amount'] == trigram:[]
2019-03-01 17:42:59	DEBUG	Punctuation handler ==>> text to process:recharge on my phone
2019-03-01 17:42:59	DEBUG	Tokenization handler ==>> takens:['recharge', 'on', 'my', 'phone'] and tokenize_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'on', 'my', 'phone'] and stem_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 17:42:59	DEBUG	Ngram handler ==>> unigram:['recharg', 'phone'] == bigram:['recharg on', 'my phone'] == trigram:['recharg on my', 'on my phone']
2019-03-01 17:42:59	DEBUG	Punctuation handler ==>> text to process:amount data
2019-03-01 17:42:59	DEBUG	Tokenization handler ==>> takens:['amount', 'data'] and tokenize_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	Stemmer handler ==>> stem_tokens:['amount', 'data'] and stem_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 17:42:59	DEBUG	Ngram handler ==>> unigram:['amount', 'data'] == bigram:['amount data'] == trigram:[]
2019-03-01 17:42:59	DEBUG	Punctuation handler ==>> text to process:data
2019-03-01 17:42:59	DEBUG	Tokenization handler ==>> takens:['data'] and tokenize_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	Stemmer handler ==>> stem_tokens:['data'] and stem_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 17:42:59	DEBUG	Ngram handler ==>> unigram:['data'] == bigram:[] == trigram:[]
2019-03-01 17:42:59	DEBUG	Punctuation handler ==>> text to process:data here
2019-03-01 17:42:59	DEBUG	Tokenization handler ==>> takens:['data', 'here'] and tokenize_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	Stemmer handler ==>> stem_tokens:['data', 'here'] and stem_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 17:42:59	DEBUG	Ngram handler ==>> unigram:['data'] == bigram:['data here'] == trigram:[]
2019-03-01 17:42:59	DEBUG	Punctuation handler ==>> text to process:recharage data
2019-03-01 17:42:59	DEBUG	Tokenization handler ==>> takens:['recharage', 'data'] and tokenize_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	Stemmer handler ==>> stem_tokens:['recharag', 'data'] and stem_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 17:42:59	DEBUG	Ngram handler ==>> unigram:['recharag', 'data'] == bigram:['recharag data'] == trigram:[]
2019-03-01 17:42:59	DEBUG	Punctuation handler ==>> text to process:account data info
2019-03-01 17:42:59	DEBUG	Tokenization handler ==>> takens:['account', 'data', 'info'] and tokenize_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	Stemmer handler ==>> stem_tokens:['account', 'data', 'info'] and stem_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 17:42:59	DEBUG	Ngram handler ==>> unigram:['account', 'data', 'info'] == bigram:['account data', 'data info'] == trigram:['account data info']
2019-03-01 17:42:59	DEBUG	Punctuation handler ==>> text to process:recharge amount
2019-03-01 17:42:59	DEBUG	Tokenization handler ==>> takens:['recharge', 'amount'] and tokenize_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'amount'] and stem_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 17:42:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 17:42:59	DEBUG	Ngram handler ==>> unigram:['recharg', 'amount'] == bigram:['recharg amount'] == trigram:[]
2019-03-01 18:04:48	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 18:04:48	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 18:04:48	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 18:04:48	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 18:04:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 18:04:48	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 18:07:10	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 18:07:10	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 18:07:10	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 18:07:10	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 18:07:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 18:07:10	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 18:07:45	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 18:07:45	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 18:07:45	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 18:07:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 18:07:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 18:07:45	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 18:08:13	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 18:08:13	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 18:08:13	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 18:08:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 18:08:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 18:08:13	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 18:08:55	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 18:08:55	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 18:08:55	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 18:08:55	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 18:08:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 18:08:55	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 18:09:40	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 18:09:40	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 18:09:40	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 18:09:40	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 18:09:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 18:09:40	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 18:10:15	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 18:10:15	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 18:10:15	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 18:10:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 18:10:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 18:10:15	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 18:11:11	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 18:11:11	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 18:11:11	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 18:11:11	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 18:11:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 18:11:11	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 18:43:24	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 18:43:24	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 18:43:24	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 18:43:24	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 18:43:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 18:43:24	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 18:43:46	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 18:43:46	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 18:43:46	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 18:43:46	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 18:43:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 18:43:46	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 18:55:55	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-03-01 18:55:55	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-03-01 18:55:55	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-03-01 18:55:55	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 18:55:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 18:55:55	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:[] == trigram:[]
2019-03-01 18:57:13	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-03-01 18:57:13	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-03-01 18:57:13	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-03-01 18:57:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 18:57:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 18:57:13	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:[] == trigram:[]
2019-03-01 18:57:31	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-01 18:57:31	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 18:57:31	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-01 18:57:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 18:57:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 18:57:31	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-01 18:57:53	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-01 18:57:53	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-01 18:57:53	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-01 18:57:53	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 18:57:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 18:57:53	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-01 18:59:57	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-01 18:59:57	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-01 18:59:57	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-01 18:59:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 18:59:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 18:59:57	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-01 19:00:25	DEBUG	Punctuation handler ==>> text to process:sdfsdfsfsdf
2019-03-01 19:00:25	DEBUG	Tokenization handler ==>> takens:['sdfsdfsfsdf'] and tokenize_without_stop_words:[]
2019-03-01 19:00:25	DEBUG	Stemmer handler ==>> stem_tokens:['sdfsdfsfsdf'] and stem_without_stop_words:[]
2019-03-01 19:00:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 19:00:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 19:00:25	DEBUG	Ngram handler ==>> unigram:['sdfsdfsfsdf'] == bigram:[] == trigram:[]
2019-03-01 19:00:54	DEBUG	Punctuation handler ==>> text to process:sdfsdfsfsdf
2019-03-01 19:00:54	DEBUG	Tokenization handler ==>> takens:['sdfsdfsfsdf'] and tokenize_without_stop_words:[]
2019-03-01 19:00:54	DEBUG	Stemmer handler ==>> stem_tokens:['sdfsdfsfsdf'] and stem_without_stop_words:[]
2019-03-01 19:00:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 19:00:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 19:00:54	DEBUG	Ngram handler ==>> unigram:['sdfsdfsfsdf'] == bigram:[] == trigram:[]
2019-03-01 19:04:10	DEBUG	Punctuation handler ==>> text to process:sdfsdfsfsdf data recharge
2019-03-01 19:04:10	DEBUG	Tokenization handler ==>> takens:['sdfsdfsfsdf', 'data', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 19:04:10	DEBUG	Stemmer handler ==>> stem_tokens:['sdfsdfsfsdf', 'data', 'recharg'] and stem_without_stop_words:[]
2019-03-01 19:04:10	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 19:04:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 19:04:10	DEBUG	Ngram handler ==>> unigram:['sdfsdfsfsdf', 'data', 'recharg'] == bigram:['sdfsdfsfsdf data', 'data recharg'] == trigram:['sdfsdfsfsdf data recharg']
2019-03-01 19:04:27	DEBUG	Punctuation handler ==>> text to process:sdfsdfsfsdf asdf sdfsadas
2019-03-01 19:04:27	DEBUG	Tokenization handler ==>> takens:['sdfsdfsfsdf', 'asdf', 'sdfsadas'] and tokenize_without_stop_words:[]
2019-03-01 19:04:27	DEBUG	Stemmer handler ==>> stem_tokens:['sdfsdfsfsdf', 'asdf', 'sdfsada'] and stem_without_stop_words:[]
2019-03-01 19:04:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 19:04:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 19:04:27	DEBUG	Ngram handler ==>> unigram:['sdfsdfsfsdf', 'asdf', 'sdfsada'] == bigram:['sdfsdfsfsdf asdf', 'asdf sdfsada'] == trigram:['sdfsdfsfsdf asdf sdfsada']
2019-03-01 19:08:39	DEBUG	Punctuation handler ==>> text to process:sdfsdfsfsdf asdf sdfsadas
2019-03-01 19:08:39	DEBUG	Tokenization handler ==>> takens:['sdfsdfsfsdf', 'asdf', 'sdfsadas'] and tokenize_without_stop_words:[]
2019-03-01 19:08:39	DEBUG	Stemmer handler ==>> stem_tokens:['sdfsdfsfsdf', 'asdf', 'sdfsada'] and stem_without_stop_words:[]
2019-03-01 19:08:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 19:08:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 19:08:39	DEBUG	Ngram handler ==>> unigram:['sdfsdfsfsdf', 'asdf', 'sdfsada'] == bigram:['sdfsdfsfsdf asdf', 'asdf sdfsada'] == trigram:['sdfsdfsfsdf asdf sdfsada']
2019-03-01 19:09:26	DEBUG	Punctuation handler ==>> text to process:sdfsdfsfsdf asdf sdfsadas
2019-03-01 19:09:26	DEBUG	Tokenization handler ==>> takens:['sdfsdfsfsdf', 'asdf', 'sdfsadas'] and tokenize_without_stop_words:[]
2019-03-01 19:09:26	DEBUG	Stemmer handler ==>> stem_tokens:['sdfsdfsfsdf', 'asdf', 'sdfsada'] and stem_without_stop_words:[]
2019-03-01 19:09:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 19:09:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 19:09:26	DEBUG	Ngram handler ==>> unigram:['sdfsdfsfsdf', 'asdf', 'sdfsada'] == bigram:['sdfsdfsfsdf asdf', 'asdf sdfsada'] == trigram:['sdfsdfsfsdf asdf sdfsada']
2019-03-01 19:13:14	DEBUG	Punctuation handler ==>> text to process:sdfsdfsfsdf asdf sdfsadas
2019-03-01 19:13:14	DEBUG	Tokenization handler ==>> takens:['sdfsdfsfsdf', 'asdf', 'sdfsadas'] and tokenize_without_stop_words:[]
2019-03-01 19:13:14	DEBUG	Stemmer handler ==>> stem_tokens:['sdfsdfsfsdf', 'asdf', 'sdfsada'] and stem_without_stop_words:[]
2019-03-01 19:13:14	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 19:13:14	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 19:13:14	DEBUG	Ngram handler ==>> unigram:['sdfsdfsfsdf', 'asdf', 'sdfsada'] == bigram:['sdfsdfsfsdf asdf', 'asdf sdfsada'] == trigram:['sdfsdfsfsdf asdf sdfsada']
2019-03-01 19:13:29	DEBUG	Punctuation handler ==>> text to process:sdfsdfsfsdf asdf sdfsadas cdsfsdfsdfd
2019-03-01 19:13:29	DEBUG	Tokenization handler ==>> takens:['sdfsdfsfsdf', 'asdf', 'sdfsadas', 'cdsfsdfsdfd'] and tokenize_without_stop_words:[]
2019-03-01 19:13:29	DEBUG	Stemmer handler ==>> stem_tokens:['sdfsdfsfsdf', 'asdf', 'sdfsada', 'cdsfsdfsdfd'] and stem_without_stop_words:[]
2019-03-01 19:13:29	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 19:13:29	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 19:13:29	DEBUG	Ngram handler ==>> unigram:['sdfsdfsfsdf', 'asdf', 'sdfsada', 'cdsfsdfsdfd'] == bigram:['sdfsdfsfsdf asdf', 'asdf sdfsada', 'sdfsada cdsfsdfsdfd'] == trigram:['sdfsdfsfsdf asdf sdfsada', 'asdf sdfsada cdsfsdfsdfd']
2019-03-01 19:13:50	DEBUG	Punctuation handler ==>> text to process:data recharge
2019-03-01 19:13:50	DEBUG	Tokenization handler ==>> takens:['data', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 19:13:50	DEBUG	Stemmer handler ==>> stem_tokens:['data', 'recharg'] and stem_without_stop_words:[]
2019-03-01 19:13:50	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 19:13:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 19:13:50	DEBUG	Ngram handler ==>> unigram:['data', 'recharg'] == bigram:['data recharg'] == trigram:[]
2019-03-01 19:16:22	DEBUG	Punctuation handler ==>> text to process:data recharge
2019-03-01 19:16:22	DEBUG	Tokenization handler ==>> takens:['data', 'recharge'] and tokenize_without_stop_words:[]
2019-03-01 19:16:22	DEBUG	Stemmer handler ==>> stem_tokens:['data', 'recharg'] and stem_without_stop_words:[]
2019-03-01 19:16:22	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 19:16:22	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 19:16:22	DEBUG	Ngram handler ==>> unigram:['data', 'recharg'] == bigram:['data recharg'] == trigram:[]
2019-03-01 19:17:19	DEBUG	Punctuation handler ==>> text to process:dsdfsdfsdfsdfe sdsfdsfsdf
2019-03-01 19:17:19	DEBUG	Tokenization handler ==>> takens:['dsdfsdfsdfsdfe', 'sdsfdsfsdf'] and tokenize_without_stop_words:[]
2019-03-01 19:17:19	DEBUG	Stemmer handler ==>> stem_tokens:['dsdfsdfsdfsdfe', 'sdsfdsfsdf'] and stem_without_stop_words:[]
2019-03-01 19:17:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 19:17:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 19:17:19	DEBUG	Ngram handler ==>> unigram:['dsdfsdfsdfsdfe', 'sdsfdsfsdf'] == bigram:['dsdfsdfsdfsdfe sdsfdsfsdf'] == trigram:[]
2019-03-01 19:19:44	DEBUG	Punctuation handler ==>> text to process:dsdfsdfsdfsdfe sdsfdsfsdf
2019-03-01 19:19:44	DEBUG	Tokenization handler ==>> takens:['dsdfsdfsdfsdfe', 'sdsfdsfsdf'] and tokenize_without_stop_words:[]
2019-03-01 19:19:44	DEBUG	Stemmer handler ==>> stem_tokens:['dsdfsdfsdfsdfe', 'sdsfdsfsdf'] and stem_without_stop_words:[]
2019-03-01 19:19:44	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-01 19:19:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-01 19:19:44	DEBUG	Ngram handler ==>> unigram:['dsdfsdfsdfsdfe', 'sdsfdsfsdf'] == bigram:['dsdfsdfsdfsdfe sdsfdsfsdf'] == trigram:[]
2019-03-05 11:41:27	DEBUG	Punctuation handler ==>> text to process:dsdfsdfsdfsdfe sdsfdsfsdf
2019-03-05 11:41:27	DEBUG	Tokenization handler ==>> takens:['dsdfsdfsdfsdfe', 'sdsfdsfsdf'] and tokenize_without_stop_words:[]
2019-03-05 11:41:27	DEBUG	Stemmer handler ==>> stem_tokens:['dsdfsdfsdfsdfe', 'sdsfdsfsdf'] and stem_without_stop_words:[]
2019-03-05 11:41:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 11:41:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 11:41:27	DEBUG	Ngram handler ==>> unigram:['dsdfsdfsdfsdfe', 'sdsfdsfsdf'] == bigram:['dsdfsdfsdfsdfe sdsfdsfsdf'] == trigram:[]
2019-03-05 11:41:47	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-05 11:41:47	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-05 11:41:47	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-05 11:41:47	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 11:41:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 11:41:47	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-05 11:42:02	DEBUG	Punctuation handler ==>> text to process:amount data
2019-03-05 11:42:02	DEBUG	Tokenization handler ==>> takens:['amount', 'data'] and tokenize_without_stop_words:[]
2019-03-05 11:42:02	DEBUG	Stemmer handler ==>> stem_tokens:['amount', 'data'] and stem_without_stop_words:[]
2019-03-05 11:42:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 11:42:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 11:42:02	DEBUG	Ngram handler ==>> unigram:['amount', 'data'] == bigram:['amount data'] == trigram:[]
2019-03-05 11:42:27	DEBUG	Punctuation handler ==>> text to process:sdfsdfsdf af asff  as as
2019-03-05 11:42:27	DEBUG	Tokenization handler ==>> takens:['sdfsdfsdf', 'af', 'asff', 'as', 'as'] and tokenize_without_stop_words:[]
2019-03-05 11:42:27	DEBUG	Stemmer handler ==>> stem_tokens:['sdfsdfsdf', 'af', 'asff', 'as', 'as'] and stem_without_stop_words:[]
2019-03-05 11:42:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 11:42:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 11:42:27	DEBUG	Ngram handler ==>> unigram:['sdfsdfsdf', 'af', 'asff'] == bigram:['sdfsdfsdf af', 'af asff', 'asff as'] == trigram:['sdfsdfsdf af asff', 'af asff as', 'asff as as']
2019-03-05 11:43:57	DEBUG	Punctuation handler ==>> text to process:amout data
2019-03-05 11:43:57	DEBUG	Tokenization handler ==>> takens:['amout', 'data'] and tokenize_without_stop_words:[]
2019-03-05 11:43:57	DEBUG	Stemmer handler ==>> stem_tokens:['amout', 'data'] and stem_without_stop_words:[]
2019-03-05 11:43:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 11:43:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 11:43:57	DEBUG	Ngram handler ==>> unigram:['amout', 'data'] == bigram:['amout data'] == trigram:[]
2019-03-05 11:45:30	DEBUG	Punctuation handler ==>> text to process:asdasd as sda adsd
2019-03-05 11:45:30	DEBUG	Tokenization handler ==>> takens:['asdasd', 'as', 'sda', 'adsd'] and tokenize_without_stop_words:[]
2019-03-05 11:45:30	DEBUG	Stemmer handler ==>> stem_tokens:['asdasd', 'as', 'sda', 'adsd'] and stem_without_stop_words:[]
2019-03-05 11:45:30	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 11:45:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 11:45:30	DEBUG	Ngram handler ==>> unigram:['asdasd', 'sda', 'adsd'] == bigram:['asdasd as', 'as sda', 'sda adsd'] == trigram:['asdasd as sda', 'as sda adsd']
2019-03-05 11:52:36	DEBUG	Punctuation handler ==>> text to process:asdasd as sda adsd
2019-03-05 11:52:36	DEBUG	Tokenization handler ==>> takens:['asdasd', 'as', 'sda', 'adsd'] and tokenize_without_stop_words:[]
2019-03-05 11:52:36	DEBUG	Stemmer handler ==>> stem_tokens:['asdasd', 'as', 'sda', 'adsd'] and stem_without_stop_words:[]
2019-03-05 11:52:36	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 11:52:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 11:52:36	DEBUG	Ngram handler ==>> unigram:['asdasd', 'sda', 'adsd'] == bigram:['asdasd as', 'as sda', 'sda adsd'] == trigram:['asdasd as sda', 'as sda adsd']
2019-03-05 11:53:31	DEBUG	Punctuation handler ==>> text to process:asdasd as sda adsd
2019-03-05 11:53:31	DEBUG	Tokenization handler ==>> takens:['asdasd', 'as', 'sda', 'adsd'] and tokenize_without_stop_words:[]
2019-03-05 11:53:31	DEBUG	Stemmer handler ==>> stem_tokens:['asdasd', 'as', 'sda', 'adsd'] and stem_without_stop_words:[]
2019-03-05 11:53:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 11:53:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 11:53:31	DEBUG	Ngram handler ==>> unigram:['asdasd', 'sda', 'adsd'] == bigram:['asdasd as', 'as sda', 'sda adsd'] == trigram:['asdasd as sda', 'as sda adsd']
2019-03-05 11:53:45	DEBUG	Punctuation handler ==>> text to process:amount data
2019-03-05 11:53:45	DEBUG	Tokenization handler ==>> takens:['amount', 'data'] and tokenize_without_stop_words:[]
2019-03-05 11:53:45	DEBUG	Stemmer handler ==>> stem_tokens:['amount', 'data'] and stem_without_stop_words:[]
2019-03-05 11:53:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 11:53:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 11:53:45	DEBUG	Ngram handler ==>> unigram:['amount', 'data'] == bigram:['amount data'] == trigram:[]
2019-03-05 12:23:01	DEBUG	Punctuation handler ==>> text to process:amount data
2019-03-05 12:23:01	DEBUG	Tokenization handler ==>> takens:['amount', 'data'] and tokenize_without_stop_words:[]
2019-03-05 12:23:01	DEBUG	Stemmer handler ==>> stem_tokens:['amount', 'data'] and stem_without_stop_words:[]
2019-03-05 12:23:01	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 12:23:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 12:23:01	DEBUG	Ngram handler ==>> unigram:['amount', 'data'] == bigram:['amount data'] == trigram:[]
2019-03-05 12:24:15	DEBUG	Punctuation handler ==>> text to process:amount data
2019-03-05 12:24:15	DEBUG	Tokenization handler ==>> takens:['amount', 'data'] and tokenize_without_stop_words:[]
2019-03-05 12:24:15	DEBUG	Stemmer handler ==>> stem_tokens:['amount', 'data'] and stem_without_stop_words:[]
2019-03-05 12:24:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 12:24:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 12:24:15	DEBUG	Ngram handler ==>> unigram:['amount', 'data'] == bigram:['amount data'] == trigram:[]
2019-03-05 12:31:30	DEBUG	Punctuation handler ==>> text to process:amount data
2019-03-05 12:31:30	DEBUG	Tokenization handler ==>> takens:['amount', 'data'] and tokenize_without_stop_words:[]
2019-03-05 12:31:30	DEBUG	Stemmer handler ==>> stem_tokens:['amount', 'data'] and stem_without_stop_words:[]
2019-03-05 12:31:30	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 12:31:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 12:31:30	DEBUG	Ngram handler ==>> unigram:['amount', 'data'] == bigram:['amount data'] == trigram:[]
2019-03-05 12:31:49	DEBUG	Punctuation handler ==>> text to process:amount data
2019-03-05 12:31:49	DEBUG	Tokenization handler ==>> takens:['amount', 'data'] and tokenize_without_stop_words:[]
2019-03-05 12:31:49	DEBUG	Stemmer handler ==>> stem_tokens:['amount', 'data'] and stem_without_stop_words:[]
2019-03-05 12:31:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 12:31:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 12:31:49	DEBUG	Ngram handler ==>> unigram:['amount', 'data'] == bigram:['amount data'] == trigram:[]
2019-03-05 12:38:32	DEBUG	Punctuation handler ==>> text to process:hello
2019-03-05 12:38:32	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-03-05 12:38:32	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-03-05 12:38:32	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 12:38:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 12:38:32	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-03-05 12:38:39	DEBUG	Punctuation handler ==>> text to process:hello
2019-03-05 12:38:39	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-03-05 12:38:39	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-03-05 12:38:43	DEBUG	lemmatization handler ==>> lemma_tokens:['hello'] and lemma_without_stop_words:[]
2019-03-05 12:38:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 12:38:43	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-03-05 12:39:33	DEBUG	Punctuation handler ==>> text to process:hello
2019-03-05 12:39:33	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-03-05 12:39:33	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-03-05 12:39:33	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 12:39:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 12:39:33	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-03-05 12:39:33	DEBUG	Punctuation handler ==>> text to process:hello
2019-03-05 12:39:33	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-03-05 12:39:33	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-03-05 12:39:36	DEBUG	lemmatization handler ==>> lemma_tokens:['hello'] and lemma_without_stop_words:[]
2019-03-05 12:39:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 12:39:36	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-03-05 12:40:43	DEBUG	Punctuation handler ==>> text to process:hello
2019-03-05 12:40:43	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-03-05 12:40:43	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-03-05 12:40:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 12:40:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 12:40:43	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-03-05 12:40:44	DEBUG	Punctuation handler ==>> text to process:hello
2019-03-05 12:40:44	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-03-05 12:40:44	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-03-05 12:40:46	DEBUG	lemmatization handler ==>> lemma_tokens:['hello'] and lemma_without_stop_words:[]
2019-03-05 12:40:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 12:40:46	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-03-05 12:42:42	DEBUG	Punctuation handler ==>> text to process:hello
2019-03-05 12:42:42	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-03-05 12:42:42	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-03-05 12:42:42	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 12:42:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 12:42:42	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-03-05 12:42:43	DEBUG	Punctuation handler ==>> text to process:hello
2019-03-05 12:42:43	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-03-05 12:42:43	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-03-05 12:42:45	DEBUG	lemmatization handler ==>> lemma_tokens:['hello'] and lemma_without_stop_words:[]
2019-03-05 12:42:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 12:42:45	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-03-05 12:43:13	DEBUG	Punctuation handler ==>> text to process:hello
2019-03-05 12:43:13	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-03-05 12:43:13	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-03-05 12:43:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 12:43:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 12:43:13	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-03-05 12:43:13	DEBUG	Punctuation handler ==>> text to process:hello
2019-03-05 12:43:13	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-03-05 12:43:13	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-03-05 12:43:13	DEBUG	lemmatization handler ==>> lemma_tokens:['hello'] and lemma_without_stop_words:[]
2019-03-05 12:43:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 12:43:13	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-03-05 12:46:41	DEBUG	Punctuation handler ==>> text to process:hello
2019-03-05 12:46:41	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-03-05 12:46:41	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-03-05 12:46:41	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 12:46:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 12:46:41	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-03-05 12:46:41	DEBUG	Punctuation handler ==>> text to process:hello
2019-03-05 12:46:41	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-03-05 12:46:41	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-03-05 12:46:44	DEBUG	lemmatization handler ==>> lemma_tokens:['hello'] and lemma_without_stop_words:[]
2019-03-05 12:46:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 12:46:44	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-03-05 17:37:47	DEBUG	Punctuation handler ==>> text to process:amount data
2019-03-05 17:37:47	DEBUG	Tokenization handler ==>> takens:['amount', 'data'] and tokenize_without_stop_words:[]
2019-03-05 17:37:47	DEBUG	Stemmer handler ==>> stem_tokens:['amount', 'data'] and stem_without_stop_words:[]
2019-03-05 17:37:47	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 17:37:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 17:37:47	DEBUG	Ngram handler ==>> unigram:['amount', 'data'] == bigram:['amount data'] == trigram:[]
2019-03-05 17:47:36	DEBUG	Punctuation handler ==>> text to process:amount data
2019-03-05 17:47:36	DEBUG	Tokenization handler ==>> takens:['amount', 'data'] and tokenize_without_stop_words:[]
2019-03-05 17:47:36	DEBUG	Stemmer handler ==>> stem_tokens:['amount', 'data'] and stem_without_stop_words:[]
2019-03-05 17:47:36	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 17:47:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 17:47:36	DEBUG	Ngram handler ==>> unigram:['amount', 'data'] == bigram:['amount data'] == trigram:[]
2019-03-05 17:47:55	DEBUG	Punctuation handler ==>> text to process:amount data
2019-03-05 17:47:55	DEBUG	Tokenization handler ==>> takens:['amount', 'data'] and tokenize_without_stop_words:[]
2019-03-05 17:47:55	DEBUG	Stemmer handler ==>> stem_tokens:['amount', 'data'] and stem_without_stop_words:[]
2019-03-05 17:47:55	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 17:47:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 17:47:55	DEBUG	Ngram handler ==>> unigram:['amount', 'data'] == bigram:['amount data'] == trigram:[]
2019-03-05 17:48:39	DEBUG	Punctuation handler ==>> text to process:amount data
2019-03-05 17:48:39	DEBUG	Tokenization handler ==>> takens:['amount', 'data'] and tokenize_without_stop_words:[]
2019-03-05 17:48:39	DEBUG	Stemmer handler ==>> stem_tokens:['amount', 'data'] and stem_without_stop_words:[]
2019-03-05 17:48:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 17:48:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 17:48:39	DEBUG	Ngram handler ==>> unigram:['amount', 'data'] == bigram:['amount data'] == trigram:[]
2019-03-05 17:49:50	DEBUG	Punctuation handler ==>> text to process:amount data
2019-03-05 17:49:50	DEBUG	Tokenization handler ==>> takens:['amount', 'data'] and tokenize_without_stop_words:[]
2019-03-05 17:49:50	DEBUG	Stemmer handler ==>> stem_tokens:['amount', 'data'] and stem_without_stop_words:[]
2019-03-05 17:49:50	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 17:49:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 17:49:50	DEBUG	Ngram handler ==>> unigram:['amount', 'data'] == bigram:['amount data'] == trigram:[]
2019-03-05 17:51:01	DEBUG	Punctuation handler ==>> text to process:amount data
2019-03-05 17:51:01	DEBUG	Tokenization handler ==>> takens:['amount', 'data'] and tokenize_without_stop_words:[]
2019-03-05 17:51:01	DEBUG	Stemmer handler ==>> stem_tokens:['amount', 'data'] and stem_without_stop_words:[]
2019-03-05 17:51:01	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 17:51:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 17:51:01	DEBUG	Ngram handler ==>> unigram:['amount', 'data'] == bigram:['amount data'] == trigram:[]
2019-03-05 17:51:13	DEBUG	Punctuation handler ==>> text to process:amount data
2019-03-05 17:51:13	DEBUG	Tokenization handler ==>> takens:['amount', 'data'] and tokenize_without_stop_words:[]
2019-03-05 17:51:13	DEBUG	Stemmer handler ==>> stem_tokens:['amount', 'data'] and stem_without_stop_words:[]
2019-03-05 17:51:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 17:51:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 17:51:13	DEBUG	Ngram handler ==>> unigram:['amount', 'data'] == bigram:['amount data'] == trigram:[]
2019-03-05 17:53:33	DEBUG	Punctuation handler ==>> text to process:amount data
2019-03-05 17:53:33	DEBUG	Tokenization handler ==>> takens:['amount', 'data'] and tokenize_without_stop_words:[]
2019-03-05 17:53:33	DEBUG	Stemmer handler ==>> stem_tokens:['amount', 'data'] and stem_without_stop_words:[]
2019-03-05 17:53:33	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 17:53:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 17:53:33	DEBUG	Ngram handler ==>> unigram:['amount', 'data'] == bigram:['amount data'] == trigram:[]
2019-03-05 17:56:39	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-05 17:56:39	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-05 17:56:39	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-05 17:56:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 17:56:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 17:56:39	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-05 18:19:30	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-05 18:19:30	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-05 18:19:30	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-05 18:19:30	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 18:19:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 18:19:30	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-05 18:19:30	DEBUG	Punctuation handler ==>> text to process:enter your mobile number
2019-03-05 18:19:30	DEBUG	Tokenization handler ==>> takens:['enter', 'your', 'mobile', 'number'] and tokenize_without_stop_words:[]
2019-03-05 18:19:30	DEBUG	Stemmer handler ==>> stem_tokens:['enter', 'your', 'mobil', 'number'] and stem_without_stop_words:[]
2019-03-05 18:19:30	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 18:19:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 18:19:30	DEBUG	Ngram handler ==>> unigram:['enter', 'mobil'] == bigram:['enter your', 'your mobil', 'mobil number'] == trigram:['enter your mobil', 'your mobil number']
2019-03-05 18:19:30	DEBUG	Punctuation handler ==>> text to process:recharge amount
2019-03-05 18:19:30	DEBUG	Tokenization handler ==>> takens:['recharge', 'amount'] and tokenize_without_stop_words:[]
2019-03-05 18:19:30	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'amount'] and stem_without_stop_words:[]
2019-03-05 18:19:30	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 18:19:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 18:19:30	DEBUG	Ngram handler ==>> unigram:['recharg', 'amount'] == bigram:['recharg amount'] == trigram:[]
2019-03-05 18:19:30	DEBUG	Punctuation handler ==>> text to process:recharge on my phone
2019-03-05 18:19:30	DEBUG	Tokenization handler ==>> takens:['recharge', 'on', 'my', 'phone'] and tokenize_without_stop_words:[]
2019-03-05 18:19:30	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'on', 'my', 'phone'] and stem_without_stop_words:[]
2019-03-05 18:19:30	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 18:19:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 18:19:30	DEBUG	Ngram handler ==>> unigram:['recharg', 'phone'] == bigram:['recharg on', 'my phone'] == trigram:['recharg on my', 'on my phone']
2019-03-05 18:19:30	DEBUG	Punctuation handler ==>> text to process:amount data
2019-03-05 18:19:30	DEBUG	Tokenization handler ==>> takens:['amount', 'data'] and tokenize_without_stop_words:[]
2019-03-05 18:19:30	DEBUG	Stemmer handler ==>> stem_tokens:['amount', 'data'] and stem_without_stop_words:[]
2019-03-05 18:19:30	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 18:19:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 18:19:30	DEBUG	Ngram handler ==>> unigram:['amount', 'data'] == bigram:['amount data'] == trigram:[]
2019-03-05 18:19:30	DEBUG	Punctuation handler ==>> text to process:data
2019-03-05 18:19:30	DEBUG	Tokenization handler ==>> takens:['data'] and tokenize_without_stop_words:[]
2019-03-05 18:19:30	DEBUG	Stemmer handler ==>> stem_tokens:['data'] and stem_without_stop_words:[]
2019-03-05 18:19:30	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 18:19:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 18:19:30	DEBUG	Ngram handler ==>> unigram:['data'] == bigram:[] == trigram:[]
2019-03-05 18:19:30	DEBUG	Punctuation handler ==>> text to process:data here
2019-03-05 18:19:30	DEBUG	Tokenization handler ==>> takens:['data', 'here'] and tokenize_without_stop_words:[]
2019-03-05 18:19:30	DEBUG	Stemmer handler ==>> stem_tokens:['data', 'here'] and stem_without_stop_words:[]
2019-03-05 18:19:30	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 18:19:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 18:19:30	DEBUG	Ngram handler ==>> unigram:['data'] == bigram:['data here'] == trigram:[]
2019-03-05 18:19:30	DEBUG	Punctuation handler ==>> text to process:recharage data
2019-03-05 18:19:30	DEBUG	Tokenization handler ==>> takens:['recharage', 'data'] and tokenize_without_stop_words:[]
2019-03-05 18:19:30	DEBUG	Stemmer handler ==>> stem_tokens:['recharag', 'data'] and stem_without_stop_words:[]
2019-03-05 18:19:30	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 18:19:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 18:19:30	DEBUG	Ngram handler ==>> unigram:['recharag', 'data'] == bigram:['recharag data'] == trigram:[]
2019-03-05 18:19:30	DEBUG	Punctuation handler ==>> text to process:account data info
2019-03-05 18:19:30	DEBUG	Tokenization handler ==>> takens:['account', 'data', 'info'] and tokenize_without_stop_words:[]
2019-03-05 18:19:30	DEBUG	Stemmer handler ==>> stem_tokens:['account', 'data', 'info'] and stem_without_stop_words:[]
2019-03-05 18:19:30	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 18:19:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 18:19:30	DEBUG	Ngram handler ==>> unigram:['account', 'data', 'info'] == bigram:['account data', 'data info'] == trigram:['account data info']
2019-03-05 18:19:30	DEBUG	Punctuation handler ==>> text to process:recharge amount
2019-03-05 18:19:30	DEBUG	Tokenization handler ==>> takens:['recharge', 'amount'] and tokenize_without_stop_words:[]
2019-03-05 18:19:30	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'amount'] and stem_without_stop_words:[]
2019-03-05 18:19:30	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 18:19:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 18:19:30	DEBUG	Ngram handler ==>> unigram:['recharg', 'amount'] == bigram:['recharg amount'] == trigram:[]
2019-03-05 18:19:47	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-05 18:19:47	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-05 18:19:47	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-05 18:19:47	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 18:19:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 18:19:47	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-05 18:19:47	DEBUG	Punctuation handler ==>> text to process:enter your mobile number
2019-03-05 18:19:47	DEBUG	Tokenization handler ==>> takens:['enter', 'your', 'mobile', 'number'] and tokenize_without_stop_words:[]
2019-03-05 18:19:47	DEBUG	Stemmer handler ==>> stem_tokens:['enter', 'your', 'mobil', 'number'] and stem_without_stop_words:[]
2019-03-05 18:19:47	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 18:19:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 18:19:47	DEBUG	Ngram handler ==>> unigram:['enter', 'mobil'] == bigram:['enter your', 'your mobil', 'mobil number'] == trigram:['enter your mobil', 'your mobil number']
2019-03-05 18:19:47	DEBUG	Punctuation handler ==>> text to process:amount data
2019-03-05 18:19:47	DEBUG	Tokenization handler ==>> takens:['amount', 'data'] and tokenize_without_stop_words:[]
2019-03-05 18:19:47	DEBUG	Stemmer handler ==>> stem_tokens:['amount', 'data'] and stem_without_stop_words:[]
2019-03-05 18:19:47	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 18:19:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 18:19:47	DEBUG	Ngram handler ==>> unigram:['amount', 'data'] == bigram:['amount data'] == trigram:[]
2019-03-05 18:19:47	DEBUG	Punctuation handler ==>> text to process:recharge amount
2019-03-05 18:19:47	DEBUG	Tokenization handler ==>> takens:['recharge', 'amount'] and tokenize_without_stop_words:[]
2019-03-05 18:19:47	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'amount'] and stem_without_stop_words:[]
2019-03-05 18:19:47	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 18:19:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 18:19:47	DEBUG	Ngram handler ==>> unigram:['recharg', 'amount'] == bigram:['recharg amount'] == trigram:[]
2019-03-05 18:20:23	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-05 18:20:23	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-05 18:20:23	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-05 18:20:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 18:20:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 18:20:23	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-05 18:22:03	DEBUG	Punctuation handler ==>> text to process:i want to
2019-03-05 18:22:03	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to'] and tokenize_without_stop_words:[]
2019-03-05 18:22:03	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to'] and stem_without_stop_words:[]
2019-03-05 18:22:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 18:22:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 18:22:03	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-03-05 18:22:18	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-05 18:22:18	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-05 18:22:18	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-05 18:22:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 18:22:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 18:22:18	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-05 18:22:28	DEBUG	Punctuation handler ==>> text to process: want recharge
2019-03-05 18:22:28	DEBUG	Tokenization handler ==>> takens:['want', 'recharge'] and tokenize_without_stop_words:[]
2019-03-05 18:22:28	DEBUG	Stemmer handler ==>> stem_tokens:['want', 'recharg'] and stem_without_stop_words:[]
2019-03-05 18:22:28	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 18:22:28	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 18:22:28	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['want recharg'] == trigram:[]
2019-03-05 18:22:37	DEBUG	Punctuation handler ==>> text to process: want to recharge
2019-03-05 18:22:37	DEBUG	Tokenization handler ==>> takens:['want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-05 18:22:37	DEBUG	Stemmer handler ==>> stem_tokens:['want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-05 18:22:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-05 18:22:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-05 18:22:37	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-06 13:56:43	DEBUG	Punctuation handler ==>> text to process:hi
2019-03-06 13:56:43	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-03-06 13:56:43	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-03-06 13:56:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 13:56:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 13:56:43	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-03-06 13:56:44	DEBUG	Punctuation handler ==>> text to process:hi
2019-03-06 13:56:44	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-03-06 13:56:44	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-03-06 13:56:46	DEBUG	lemmatization handler ==>> lemma_tokens:['hi'] and lemma_without_stop_words:[]
2019-03-06 13:56:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 13:56:46	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-03-06 14:06:04	DEBUG	Punctuation handler ==>> text to process:hi
2019-03-06 14:06:04	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-03-06 14:06:04	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-03-06 14:06:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 14:06:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 14:06:04	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-03-06 14:15:04	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-06 14:15:04	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-06 14:15:04	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-06 14:15:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 14:15:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 14:15:04	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-06 15:29:59	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-06 15:29:59	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-06 15:29:59	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-06 15:29:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 15:29:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 15:29:59	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-06 15:39:10	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-06 15:39:10	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-06 15:39:10	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-06 15:39:10	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 15:39:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 15:39:10	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-06 15:40:21	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-06 15:40:21	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-06 15:40:21	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-06 15:40:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 15:40:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 15:40:21	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-06 15:42:35	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-06 15:42:35	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-06 15:42:35	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-06 15:42:35	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 15:42:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 15:42:35	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-06 15:42:35	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-06 15:42:35	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-06 15:42:35	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-06 15:42:35	DEBUG	lemmatization handler ==>> lemma_tokens:['recharge'] and lemma_without_stop_words:[]
2019-03-06 15:42:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 15:42:35	DEBUG	Ngram handler ==>> unigram:['recharge'] == bigram:[] == trigram:[]
2019-03-06 16:35:46	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-06 16:35:47	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-06 16:35:47	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-06 16:35:47	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 16:35:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 16:35:47	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-06 16:36:09	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-06 16:36:09	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-06 16:36:09	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-06 16:36:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 16:36:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 16:36:09	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-06 16:36:37	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-06 16:36:37	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-06 16:36:37	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-06 16:36:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 16:36:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 16:36:37	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-06 16:37:40	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-06 16:37:40	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-06 16:37:40	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-06 16:37:40	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 16:37:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 16:37:40	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-06 16:38:40	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-06 16:38:40	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-06 16:38:40	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-06 16:38:40	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 16:38:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 16:38:40	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-06 16:39:00	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-06 16:39:00	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-06 16:39:00	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-06 16:39:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 16:39:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 16:39:00	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-06 16:39:39	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-06 16:39:39	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-06 16:39:39	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-06 16:39:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 16:39:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 16:39:39	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-06 16:39:45	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-06 16:39:45	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-06 16:39:45	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-06 16:39:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 16:39:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 16:39:45	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-06 17:21:26	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-06 17:21:26	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-06 17:21:26	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-06 17:21:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:21:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:21:26	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-06 17:23:57	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-06 17:23:57	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-06 17:23:57	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-06 17:23:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:23:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:23:57	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-06 17:26:48	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-06 17:26:48	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-06 17:26:48	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-06 17:26:48	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:26:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:26:48	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-06 17:30:36	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-06 17:30:36	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-06 17:30:36	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-06 17:30:36	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:30:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:30:36	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-06 17:30:36	DEBUG	Punctuation handler ==>> text to process:enter your mobile number
2019-03-06 17:30:36	DEBUG	Tokenization handler ==>> takens:['enter', 'your', 'mobile', 'number'] and tokenize_without_stop_words:[]
2019-03-06 17:30:36	DEBUG	Stemmer handler ==>> stem_tokens:['enter', 'your', 'mobil', 'number'] and stem_without_stop_words:[]
2019-03-06 17:30:36	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:30:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:30:36	DEBUG	Ngram handler ==>> unigram:['enter', 'mobil'] == bigram:['enter your', 'your mobil', 'mobil number'] == trigram:['enter your mobil', 'your mobil number']
2019-03-06 17:30:36	DEBUG	Punctuation handler ==>> text to process:amount data
2019-03-06 17:30:36	DEBUG	Tokenization handler ==>> takens:['amount', 'data'] and tokenize_without_stop_words:[]
2019-03-06 17:30:36	DEBUG	Stemmer handler ==>> stem_tokens:['amount', 'data'] and stem_without_stop_words:[]
2019-03-06 17:30:36	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:30:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:30:36	DEBUG	Ngram handler ==>> unigram:['amount', 'data'] == bigram:['amount data'] == trigram:[]
2019-03-06 17:30:36	DEBUG	Punctuation handler ==>> text to process:recharge amount
2019-03-06 17:30:36	DEBUG	Tokenization handler ==>> takens:['recharge', 'amount'] and tokenize_without_stop_words:[]
2019-03-06 17:30:36	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'amount'] and stem_without_stop_words:[]
2019-03-06 17:30:36	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:30:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:30:36	DEBUG	Ngram handler ==>> unigram:['recharg', 'amount'] == bigram:['recharg amount'] == trigram:[]
2019-03-06 17:30:50	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-06 17:30:50	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-06 17:30:50	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-06 17:30:50	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:30:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:30:50	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-06 17:30:50	DEBUG	Punctuation handler ==>> text to process:enter your mobile number
2019-03-06 17:30:50	DEBUG	Tokenization handler ==>> takens:['enter', 'your', 'mobile', 'number'] and tokenize_without_stop_words:[]
2019-03-06 17:30:50	DEBUG	Stemmer handler ==>> stem_tokens:['enter', 'your', 'mobil', 'number'] and stem_without_stop_words:[]
2019-03-06 17:30:50	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:30:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:30:50	DEBUG	Ngram handler ==>> unigram:['enter', 'mobil'] == bigram:['enter your', 'your mobil', 'mobil number'] == trigram:['enter your mobil', 'your mobil number']
2019-03-06 17:30:50	DEBUG	Punctuation handler ==>> text to process:amount data
2019-03-06 17:30:50	DEBUG	Tokenization handler ==>> takens:['amount', 'data'] and tokenize_without_stop_words:[]
2019-03-06 17:30:50	DEBUG	Stemmer handler ==>> stem_tokens:['amount', 'data'] and stem_without_stop_words:[]
2019-03-06 17:30:50	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:30:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:30:50	DEBUG	Ngram handler ==>> unigram:['amount', 'data'] == bigram:['amount data'] == trigram:[]
2019-03-06 17:30:50	DEBUG	Punctuation handler ==>> text to process:recharge amount
2019-03-06 17:30:50	DEBUG	Tokenization handler ==>> takens:['recharge', 'amount'] and tokenize_without_stop_words:[]
2019-03-06 17:30:50	DEBUG	Stemmer handler ==>> stem_tokens:['recharg', 'amount'] and stem_without_stop_words:[]
2019-03-06 17:30:50	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:30:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:30:50	DEBUG	Ngram handler ==>> unigram:['recharg', 'amount'] == bigram:['recharg amount'] == trigram:[]
2019-03-06 17:43:38	DEBUG	Punctuation handler ==>> text to process:travel from one city to other city
2019-03-06 17:43:38	DEBUG	Tokenization handler ==>> takens:['travel', 'from', 'one', 'city', 'to', 'other', 'city'] and tokenize_without_stop_words:[]
2019-03-06 17:43:38	DEBUG	Stemmer handler ==>> stem_tokens:['travel', 'from', 'one', 'citi', 'to', 'other', 'citi'] and stem_without_stop_words:[]
2019-03-06 17:43:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:43:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:43:38	DEBUG	Ngram handler ==>> unigram:['travel', 'one', 'citi', 'citi'] == bigram:['travel from', 'from one', 'one citi', 'citi to', 'other citi'] == trigram:['travel from one', 'from one citi', 'one citi to', 'citi to other', 'to other citi']
2019-03-06 17:43:38	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-03-06 17:43:38	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-03-06 17:43:38	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-03-06 17:43:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:43:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:43:38	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-03-06 17:43:38	DEBUG	Punctuation handler ==>> text to process:i want to book travel
2019-03-06 17:43:38	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'book', 'travel'] and tokenize_without_stop_words:[]
2019-03-06 17:43:38	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'book', 'travel'] and stem_without_stop_words:[]
2019-03-06 17:43:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:43:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:43:38	DEBUG	Ngram handler ==>> unigram:['book', 'travel'] == bigram:['to book', 'book travel'] == trigram:['want to book', 'to book travel']
2019-03-06 17:43:38	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-06 17:43:38	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-06 17:43:38	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-06 17:43:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:43:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:43:38	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-06 17:43:38	DEBUG	Punctuation handler ==>> text to process:i want to travel
2019-03-06 17:43:38	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'travel'] and tokenize_without_stop_words:[]
2019-03-06 17:43:38	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'travel'] and stem_without_stop_words:[]
2019-03-06 17:43:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:43:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:43:38	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:['to travel'] == trigram:['want to travel']
2019-03-06 17:43:38	DEBUG	Punctuation handler ==>> text to process:ask to city
2019-03-06 17:43:38	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'city'] and tokenize_without_stop_words:[]
2019-03-06 17:43:38	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'citi'] and stem_without_stop_words:[]
2019-03-06 17:43:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:43:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:43:38	DEBUG	Ngram handler ==>> unigram:['citi'] == bigram:['to citi'] == trigram:['ask to citi']
2019-03-06 17:43:38	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-03-06 17:43:38	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-03-06 17:43:38	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-03-06 17:43:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:43:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:43:38	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-03-06 17:43:38	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-06 17:43:38	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-06 17:43:38	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-06 17:43:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:43:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:43:38	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-06 17:43:38	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-06 17:43:38	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-06 17:43:38	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-06 17:43:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:43:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:43:38	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-06 17:44:00	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-06 17:44:00	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-06 17:44:00	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-06 17:44:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:44:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:44:00	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-06 17:44:53	DEBUG	Punctuation handler ==>> text to process:9024627167
2019-03-06 17:44:53	DEBUG	Tokenization handler ==>> takens:['9024627167'] and tokenize_without_stop_words:[]
2019-03-06 17:44:53	DEBUG	Stemmer handler ==>> stem_tokens:['9024627167'] and stem_without_stop_words:[]
2019-03-06 17:44:53	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:44:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:44:53	DEBUG	Ngram handler ==>> unigram:['9024627167'] == bigram:[] == trigram:[]
2019-03-06 17:44:53	DEBUG	Punctuation handler ==>> text to process:9024627167
2019-03-06 17:44:53	DEBUG	Tokenization handler ==>> takens:['9024627167'] and tokenize_without_stop_words:[]
2019-03-06 17:44:53	DEBUG	Stemmer handler ==>> stem_tokens:['9024627167'] and stem_without_stop_words:[]
2019-03-06 17:44:55	DEBUG	lemmatization handler ==>> lemma_tokens:['9024627167'] and lemma_without_stop_words:[]
2019-03-06 17:44:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:44:55	DEBUG	Ngram handler ==>> unigram:['9024627167'] == bigram:[] == trigram:[]
2019-03-06 17:45:01	DEBUG	Punctuation handler ==>> text to process:236
2019-03-06 17:45:01	DEBUG	Tokenization handler ==>> takens:['236'] and tokenize_without_stop_words:[]
2019-03-06 17:45:01	DEBUG	Stemmer handler ==>> stem_tokens:['236'] and stem_without_stop_words:[]
2019-03-06 17:45:01	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:45:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:45:01	DEBUG	Ngram handler ==>> unigram:['236'] == bigram:[] == trigram:[]
2019-03-06 17:45:01	DEBUG	Punctuation handler ==>> text to process:236
2019-03-06 17:45:01	DEBUG	Tokenization handler ==>> takens:['236'] and tokenize_without_stop_words:[]
2019-03-06 17:45:01	DEBUG	Stemmer handler ==>> stem_tokens:['236'] and stem_without_stop_words:[]
2019-03-06 17:45:01	DEBUG	lemmatization handler ==>> lemma_tokens:['236'] and lemma_without_stop_words:[]
2019-03-06 17:45:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:45:01	DEBUG	Ngram handler ==>> unigram:['236'] == bigram:[] == trigram:[]
2019-03-06 17:45:46	DEBUG	Punctuation handler ==>> text to process:i want to book travel
2019-03-06 17:45:46	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'book', 'travel'] and tokenize_without_stop_words:[]
2019-03-06 17:45:46	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'book', 'travel'] and stem_without_stop_words:[]
2019-03-06 17:45:46	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:45:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:45:46	DEBUG	Ngram handler ==>> unigram:['book', 'travel'] == bigram:['to book', 'book travel'] == trigram:['want to book', 'to book travel']
2019-03-06 17:45:46	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-06 17:45:46	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-06 17:45:46	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-06 17:45:46	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:45:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:45:46	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-06 17:45:46	DEBUG	Punctuation handler ==>> text to process:i want to travel
2019-03-06 17:45:46	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'travel'] and tokenize_without_stop_words:[]
2019-03-06 17:45:46	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'travel'] and stem_without_stop_words:[]
2019-03-06 17:45:46	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:45:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:45:46	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:['to travel'] == trigram:['want to travel']
2019-03-06 17:45:46	DEBUG	Punctuation handler ==>> text to process:ask to city
2019-03-06 17:45:46	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'city'] and tokenize_without_stop_words:[]
2019-03-06 17:45:46	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'citi'] and stem_without_stop_words:[]
2019-03-06 17:45:46	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:45:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:45:46	DEBUG	Ngram handler ==>> unigram:['citi'] == bigram:['to citi'] == trigram:['ask to citi']
2019-03-06 17:45:46	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-03-06 17:45:46	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-03-06 17:45:46	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-03-06 17:45:46	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:45:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:45:46	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-03-06 17:45:46	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-06 17:45:46	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-06 17:45:46	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-06 17:45:46	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:45:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:45:46	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-06 17:45:46	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-06 17:45:46	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-06 17:45:46	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-06 17:45:46	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:45:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:45:46	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-06 17:56:06	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-03-06 17:56:06	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-03-06 17:56:06	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-03-06 17:56:06	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:56:06	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:56:06	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-03-06 17:56:06	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-06 17:56:06	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-06 17:56:06	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-06 17:56:06	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:56:06	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:56:06	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-06 17:56:06	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-06 17:56:06	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-06 17:56:06	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-06 17:56:06	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:56:06	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:56:06	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-06 17:56:06	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-06 17:56:06	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-06 17:56:06	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-06 17:56:06	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:56:06	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:56:06	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-06 17:56:06	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-03-06 17:56:06	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-03-06 17:56:06	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-03-06 17:56:06	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:56:06	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:56:07	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-03-06 17:56:30	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-06 17:56:30	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-06 17:56:30	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-06 17:56:30	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:56:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:56:30	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-06 17:56:44	DEBUG	Punctuation handler ==>> text to process:9024
2019-03-06 17:56:44	DEBUG	Tokenization handler ==>> takens:['9024'] and tokenize_without_stop_words:[]
2019-03-06 17:56:44	DEBUG	Stemmer handler ==>> stem_tokens:['9024'] and stem_without_stop_words:[]
2019-03-06 17:56:44	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:56:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:56:44	DEBUG	Ngram handler ==>> unigram:['9024'] == bigram:[] == trigram:[]
2019-03-06 17:56:44	DEBUG	Punctuation handler ==>> text to process:9024
2019-03-06 17:56:44	DEBUG	Tokenization handler ==>> takens:['9024'] and tokenize_without_stop_words:[]
2019-03-06 17:56:44	DEBUG	Stemmer handler ==>> stem_tokens:['9024'] and stem_without_stop_words:[]
2019-03-06 17:56:44	DEBUG	lemmatization handler ==>> lemma_tokens:['9024'] and lemma_without_stop_words:[]
2019-03-06 17:56:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:56:44	DEBUG	Ngram handler ==>> unigram:['9024'] == bigram:[] == trigram:[]
2019-03-06 17:56:50	DEBUG	Punctuation handler ==>> text to process:245
2019-03-06 17:56:50	DEBUG	Tokenization handler ==>> takens:['245'] and tokenize_without_stop_words:[]
2019-03-06 17:56:50	DEBUG	Stemmer handler ==>> stem_tokens:['245'] and stem_without_stop_words:[]
2019-03-06 17:56:50	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:56:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:56:50	DEBUG	Ngram handler ==>> unigram:['245'] == bigram:[] == trigram:[]
2019-03-06 17:56:50	DEBUG	Punctuation handler ==>> text to process:245
2019-03-06 17:56:50	DEBUG	Tokenization handler ==>> takens:['245'] and tokenize_without_stop_words:[]
2019-03-06 17:56:50	DEBUG	Stemmer handler ==>> stem_tokens:['245'] and stem_without_stop_words:[]
2019-03-06 17:56:50	DEBUG	lemmatization handler ==>> lemma_tokens:['245'] and lemma_without_stop_words:[]
2019-03-06 17:56:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:56:50	DEBUG	Ngram handler ==>> unigram:['245'] == bigram:[] == trigram:[]
2019-03-06 17:59:27	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-03-06 17:59:27	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-03-06 17:59:27	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-03-06 17:59:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:59:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:59:27	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-03-06 17:59:27	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-06 17:59:27	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-06 17:59:27	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-06 17:59:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:59:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:59:27	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-06 17:59:27	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-06 17:59:27	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-06 17:59:27	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-06 17:59:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:59:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:59:27	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-06 17:59:27	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-06 17:59:27	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-06 17:59:27	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-06 17:59:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:59:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:59:27	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-06 17:59:27	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-03-06 17:59:27	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-03-06 17:59:27	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-03-06 17:59:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 17:59:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 17:59:27	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-03-06 18:00:16	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-03-06 18:00:16	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-03-06 18:00:16	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-03-06 18:00:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 18:00:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:00:16	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:[] == trigram:[]
2019-03-06 18:00:17	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-03-06 18:00:17	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-03-06 18:00:17	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-03-06 18:00:17	DEBUG	lemmatization handler ==>> lemma_tokens:['rechrage'] and lemma_without_stop_words:[]
2019-03-06 18:00:17	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:00:17	DEBUG	Ngram handler ==>> unigram:['rechrage'] == bigram:[] == trigram:[]
2019-03-06 18:00:31	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-03-06 18:00:31	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-03-06 18:00:31	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-03-06 18:00:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 18:00:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:00:31	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-03-06 18:00:31	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-06 18:00:31	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-06 18:00:31	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-06 18:00:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 18:00:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:00:31	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-06 18:00:31	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-06 18:00:31	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-06 18:00:31	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-06 18:00:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 18:00:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:00:31	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-06 18:00:31	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-06 18:00:31	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-06 18:00:31	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-06 18:00:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 18:00:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:00:31	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-06 18:00:31	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-03-06 18:00:31	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-03-06 18:00:31	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-03-06 18:00:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 18:00:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:00:31	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-03-06 18:00:53	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-03-06 18:00:53	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-03-06 18:00:53	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-03-06 18:00:53	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 18:00:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:00:53	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-03-06 18:00:53	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-06 18:00:53	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-06 18:00:53	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-06 18:00:53	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 18:00:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:00:53	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-06 18:00:53	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-06 18:00:53	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-06 18:00:53	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-06 18:00:53	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 18:00:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:00:53	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-06 18:00:53	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-06 18:00:53	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-06 18:00:53	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-06 18:00:53	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 18:00:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:00:53	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-06 18:00:53	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-03-06 18:00:53	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-03-06 18:00:53	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-03-06 18:00:53	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 18:00:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:00:53	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-03-06 18:01:06	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-06 18:01:06	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-06 18:01:06	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-06 18:01:06	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 18:01:06	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:01:06	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-06 18:01:06	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-06 18:01:06	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-06 18:01:06	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-06 18:01:06	DEBUG	lemmatization handler ==>> lemma_tokens:['i', 'want', 'to', 'rechrage'] and lemma_without_stop_words:[]
2019-03-06 18:01:06	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:01:06	DEBUG	Ngram handler ==>> unigram:['i', 'want', 'to', 'rechrage'] == bigram:['i want', 'want to', 'to rechrage'] == trigram:['i want to', 'want to rechrage']
2019-03-06 18:01:44	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-06 18:01:44	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-06 18:01:44	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-06 18:01:44	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 18:01:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:01:44	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-06 18:01:44	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-06 18:01:44	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-06 18:01:44	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-06 18:01:44	DEBUG	lemmatization handler ==>> lemma_tokens:['i', 'want', 'to', 'rechrage'] and lemma_without_stop_words:[]
2019-03-06 18:01:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:01:44	DEBUG	Ngram handler ==>> unigram:['i', 'want', 'to', 'rechrage'] == bigram:['i want', 'want to', 'to rechrage'] == trigram:['i want to', 'want to rechrage']
2019-03-06 18:11:56	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-06 18:11:56	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-06 18:11:56	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-06 18:11:56	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 18:11:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:11:56	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-06 18:11:56	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-06 18:11:56	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-06 18:11:56	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-06 18:11:56	DEBUG	lemmatization handler ==>> lemma_tokens:['i', 'want', 'to', 'rechrage'] and lemma_without_stop_words:[]
2019-03-06 18:11:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:11:56	DEBUG	Ngram handler ==>> unigram:['i', 'want', 'to', 'rechrage'] == bigram:['i want', 'want to', 'to rechrage'] == trigram:['i want to', 'want to rechrage']
2019-03-06 18:12:42	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-06 18:12:42	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-06 18:12:42	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-06 18:12:42	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 18:12:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:12:42	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-06 18:13:10	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-06 18:13:10	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-06 18:13:10	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-06 18:13:13	DEBUG	lemmatization handler ==>> lemma_tokens:['i', 'want', 'to', 'rechrage'] and lemma_without_stop_words:[]
2019-03-06 18:13:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:13:13	DEBUG	Ngram handler ==>> unigram:['i', 'want', 'to', 'rechrage'] == bigram:['i want', 'want to', 'to rechrage'] == trigram:['i want to', 'want to rechrage']
2019-03-06 18:13:40	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-06 18:13:40	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-06 18:13:40	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-06 18:13:40	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 18:13:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:13:40	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-06 18:14:01	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-06 18:14:01	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-06 18:14:01	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-06 18:14:04	DEBUG	lemmatization handler ==>> lemma_tokens:['i', 'want', 'to', 'rechrage'] and lemma_without_stop_words:[]
2019-03-06 18:14:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:14:04	DEBUG	Ngram handler ==>> unigram:['i', 'want', 'to', 'rechrage'] == bigram:['i want', 'want to', 'to rechrage'] == trigram:['i want to', 'want to rechrage']
2019-03-06 18:14:41	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-03-06 18:14:41	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-03-06 18:14:41	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-03-06 18:14:41	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 18:14:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:14:41	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-03-06 18:15:00	DEBUG	Punctuation handler ==>> text to process:90
2019-03-06 18:15:00	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-06 18:15:00	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-06 18:15:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 18:15:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:15:00	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-06 18:15:00	DEBUG	Punctuation handler ==>> text to process:90
2019-03-06 18:15:00	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-06 18:15:00	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-06 18:15:00	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-06 18:15:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:15:00	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-06 18:15:07	DEBUG	Punctuation handler ==>> text to process:23
2019-03-06 18:15:07	DEBUG	Tokenization handler ==>> takens:['23'] and tokenize_without_stop_words:[]
2019-03-06 18:15:07	DEBUG	Stemmer handler ==>> stem_tokens:['23'] and stem_without_stop_words:[]
2019-03-06 18:15:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 18:15:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:15:07	DEBUG	Ngram handler ==>> unigram:['23'] == bigram:[] == trigram:[]
2019-03-06 18:15:08	DEBUG	Punctuation handler ==>> text to process:23
2019-03-06 18:15:08	DEBUG	Tokenization handler ==>> takens:['23'] and tokenize_without_stop_words:[]
2019-03-06 18:15:08	DEBUG	Stemmer handler ==>> stem_tokens:['23'] and stem_without_stop_words:[]
2019-03-06 18:15:08	DEBUG	lemmatization handler ==>> lemma_tokens:['23'] and lemma_without_stop_words:[]
2019-03-06 18:15:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:15:08	DEBUG	Ngram handler ==>> unigram:['23'] == bigram:[] == trigram:[]
2019-03-06 18:17:41	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-03-06 18:17:41	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-03-06 18:17:41	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-03-06 18:17:41	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 18:17:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:17:41	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-03-06 18:17:41	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-06 18:17:41	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-06 18:17:41	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-06 18:17:41	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 18:17:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:17:41	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-06 18:17:41	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-06 18:17:41	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-06 18:17:41	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-06 18:17:41	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 18:17:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:17:41	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-06 18:17:41	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-06 18:17:41	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-06 18:17:41	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-06 18:17:41	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 18:17:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:17:41	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-06 18:17:41	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-03-06 18:17:41	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-03-06 18:17:41	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-03-06 18:17:41	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 18:17:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:17:41	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-03-06 18:39:59	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-03-06 18:39:59	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-03-06 18:39:59	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-03-06 18:39:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 18:39:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:39:59	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-03-06 18:40:02	DEBUG	Punctuation handler ==>> text to process:90
2019-03-06 18:40:02	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-06 18:40:02	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-06 18:40:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 18:40:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:40:02	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-06 18:40:03	DEBUG	Punctuation handler ==>> text to process:90
2019-03-06 18:40:03	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-06 18:40:03	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-06 18:40:05	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-06 18:40:05	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:40:05	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-06 18:40:10	DEBUG	Punctuation handler ==>> text to process:357
2019-03-06 18:40:10	DEBUG	Tokenization handler ==>> takens:['357'] and tokenize_without_stop_words:[]
2019-03-06 18:40:10	DEBUG	Stemmer handler ==>> stem_tokens:['357'] and stem_without_stop_words:[]
2019-03-06 18:40:10	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-06 18:40:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:40:10	DEBUG	Ngram handler ==>> unigram:['357'] == bigram:[] == trigram:[]
2019-03-06 18:40:10	DEBUG	Punctuation handler ==>> text to process:357
2019-03-06 18:40:10	DEBUG	Tokenization handler ==>> takens:['357'] and tokenize_without_stop_words:[]
2019-03-06 18:40:10	DEBUG	Stemmer handler ==>> stem_tokens:['357'] and stem_without_stop_words:[]
2019-03-06 18:40:10	DEBUG	lemmatization handler ==>> lemma_tokens:['357'] and lemma_without_stop_words:[]
2019-03-06 18:40:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-06 18:40:10	DEBUG	Ngram handler ==>> unigram:['357'] == bigram:[] == trigram:[]
2019-03-07 12:55:41	DEBUG	Punctuation handler ==>> text to process:hi
2019-03-07 12:55:41	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-03-07 12:55:41	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-03-07 12:55:41	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-07 12:55:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-07 12:55:41	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-03-07 12:55:41	DEBUG	Punctuation handler ==>> text to process:hi
2019-03-07 12:55:41	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-03-07 12:55:41	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-03-07 12:55:44	DEBUG	lemmatization handler ==>> lemma_tokens:['hi'] and lemma_without_stop_words:[]
2019-03-07 12:55:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-07 12:55:44	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-03-07 12:56:51	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-03-07 12:56:51	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-03-07 12:56:51	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-03-07 12:56:51	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-07 12:56:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-07 12:56:51	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:[] == trigram:[]
2019-03-07 12:56:51	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-03-07 12:56:51	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-03-07 12:56:51	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-03-07 12:56:51	DEBUG	lemmatization handler ==>> lemma_tokens:['rechrage'] and lemma_without_stop_words:[]
2019-03-07 12:56:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-07 12:56:51	DEBUG	Ngram handler ==>> unigram:['rechrage'] == bigram:[] == trigram:[]
2019-03-07 12:58:02	DEBUG	Punctuation handler ==>> text to process:hi
2019-03-07 12:58:02	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-03-07 12:58:02	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-03-07 12:58:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-07 12:58:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-07 12:58:02	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-03-07 12:58:02	DEBUG	Punctuation handler ==>> text to process:hi
2019-03-07 12:58:02	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-03-07 12:58:02	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-03-07 12:58:02	DEBUG	lemmatization handler ==>> lemma_tokens:['hi'] and lemma_without_stop_words:[]
2019-03-07 12:58:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-07 12:58:02	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-03-07 12:58:08	DEBUG	Punctuation handler ==>> text to process:hello
2019-03-07 12:58:08	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-03-07 12:58:08	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-03-07 12:58:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-07 12:58:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-07 12:58:08	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-03-07 12:58:08	DEBUG	Punctuation handler ==>> text to process:hello
2019-03-07 12:58:08	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-03-07 12:58:08	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-03-07 12:58:08	DEBUG	lemmatization handler ==>> lemma_tokens:['hello'] and lemma_without_stop_words:[]
2019-03-07 12:58:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-07 12:58:08	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-03-07 13:01:31	DEBUG	Punctuation handler ==>> text to process:can you rechrage
2019-03-07 13:01:31	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-07 13:01:31	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'rechrag'] and stem_without_stop_words:[]
2019-03-07 13:01:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-07 13:01:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-07 13:01:31	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['you rechrag'] == trigram:['can you rechrag']
2019-03-07 13:01:31	DEBUG	Punctuation handler ==>> text to process:can you rechrage
2019-03-07 13:01:31	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-07 13:01:31	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'rechrag'] and stem_without_stop_words:[]
2019-03-07 13:01:31	DEBUG	lemmatization handler ==>> lemma_tokens:['can', 'you', 'rechrage'] and lemma_without_stop_words:[]
2019-03-07 13:01:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-07 13:01:31	DEBUG	Ngram handler ==>> unigram:['can', 'you', 'rechrage'] == bigram:['can you', 'you rechrage'] == trigram:['can you rechrage']
2019-03-07 14:15:17	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-03-07 14:15:17	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-03-07 14:15:17	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-03-07 14:15:17	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-07 14:15:17	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-07 14:15:17	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:[] == trigram:[]
2019-03-07 14:15:17	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-03-07 14:15:17	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-03-07 14:15:17	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-03-07 14:15:20	DEBUG	lemmatization handler ==>> lemma_tokens:['rechrage'] and lemma_without_stop_words:[]
2019-03-07 14:15:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-07 14:15:20	DEBUG	Ngram handler ==>> unigram:['rechrage'] == bigram:[] == trigram:[]
2019-03-07 14:15:35	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-03-07 14:15:35	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-03-07 14:15:35	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-03-07 14:15:35	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-07 14:15:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-07 14:15:35	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-03-07 14:15:44	DEBUG	Punctuation handler ==>> text to process:90
2019-03-07 14:15:44	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-07 14:15:44	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-07 14:15:44	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-07 14:15:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-07 14:15:44	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-07 14:15:44	DEBUG	Punctuation handler ==>> text to process:90
2019-03-07 14:15:44	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-07 14:15:44	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-07 14:15:44	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-07 14:15:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-07 14:15:44	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-07 14:15:48	DEBUG	Punctuation handler ==>> text to process:24
2019-03-07 14:15:48	DEBUG	Tokenization handler ==>> takens:['24'] and tokenize_without_stop_words:[]
2019-03-07 14:15:48	DEBUG	Stemmer handler ==>> stem_tokens:['24'] and stem_without_stop_words:[]
2019-03-07 14:15:48	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-07 14:15:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-07 14:15:48	DEBUG	Ngram handler ==>> unigram:['24'] == bigram:[] == trigram:[]
2019-03-07 14:15:48	DEBUG	Punctuation handler ==>> text to process:24
2019-03-07 14:15:48	DEBUG	Tokenization handler ==>> takens:['24'] and tokenize_without_stop_words:[]
2019-03-07 14:15:48	DEBUG	Stemmer handler ==>> stem_tokens:['24'] and stem_without_stop_words:[]
2019-03-07 14:15:48	DEBUG	lemmatization handler ==>> lemma_tokens:['24'] and lemma_without_stop_words:[]
2019-03-07 14:15:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-07 14:15:48	DEBUG	Ngram handler ==>> unigram:['24'] == bigram:[] == trigram:[]
2019-03-07 18:12:37	DEBUG	Punctuation handler ==>> text to process: want to recharge
2019-03-07 18:12:37	DEBUG	Tokenization handler ==>> takens:['want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-07 18:12:37	DEBUG	Stemmer handler ==>> stem_tokens:['want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-07 18:12:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-07 18:12:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-07 18:12:37	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-07 18:14:12	DEBUG	Punctuation handler ==>> text to process: want to recharge
2019-03-07 18:14:12	DEBUG	Tokenization handler ==>> takens:['want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-07 18:14:12	DEBUG	Stemmer handler ==>> stem_tokens:['want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-07 18:14:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-07 18:14:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-07 18:14:12	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-07 18:14:43	DEBUG	Punctuation handler ==>> text to process: want to recharge
2019-03-07 18:14:43	DEBUG	Tokenization handler ==>> takens:['want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-07 18:14:43	DEBUG	Stemmer handler ==>> stem_tokens:['want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-07 18:14:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-07 18:14:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-07 18:14:43	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-07 18:19:15	DEBUG	Punctuation handler ==>> text to process: want to recharge
2019-03-07 18:19:15	DEBUG	Tokenization handler ==>> takens:['want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-07 18:19:15	DEBUG	Stemmer handler ==>> stem_tokens:['want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-07 18:19:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-07 18:19:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-07 18:19:15	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 10:02:58	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-03-14 10:02:58	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-03-14 10:02:58	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-03-14 10:02:58	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:02:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:02:58	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-03-14 10:02:58	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 10:02:58	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 10:02:58	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 10:02:58	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:02:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:02:58	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 10:02:58	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-14 10:02:58	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-14 10:02:58	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-14 10:02:58	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:02:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:02:58	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-14 10:02:58	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-14 10:02:58	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-14 10:02:58	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-14 10:02:58	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:02:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:02:58	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-14 10:02:58	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-03-14 10:02:58	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-03-14 10:02:58	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-03-14 10:02:58	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:02:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:02:58	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-03-14 10:03:42	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-03-14 10:03:42	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-03-14 10:03:42	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-03-14 10:03:42	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:03:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:03:42	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-03-14 10:03:42	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 10:03:42	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 10:03:42	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 10:03:42	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:03:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:03:42	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 10:03:42	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-14 10:03:42	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-14 10:03:42	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-14 10:03:42	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:03:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:03:42	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-14 10:03:42	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-14 10:03:42	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-14 10:03:42	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-14 10:03:42	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:03:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:03:42	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-14 10:03:42	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-03-14 10:03:42	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-03-14 10:03:42	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-03-14 10:03:42	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:03:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:03:42	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-03-14 10:28:05	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-14 10:28:05	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-14 10:28:05	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-14 10:28:05	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:28:05	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:28:05	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-14 10:28:09	DEBUG	Punctuation handler ==>> text to process:9024
2019-03-14 10:28:09	DEBUG	Tokenization handler ==>> takens:['9024'] and tokenize_without_stop_words:[]
2019-03-14 10:28:09	DEBUG	Stemmer handler ==>> stem_tokens:['9024'] and stem_without_stop_words:[]
2019-03-14 10:28:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:28:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:28:09	DEBUG	Ngram handler ==>> unigram:['9024'] == bigram:[] == trigram:[]
2019-03-14 10:28:09	DEBUG	Punctuation handler ==>> text to process:9024
2019-03-14 10:28:09	DEBUG	Tokenization handler ==>> takens:['9024'] and tokenize_without_stop_words:[]
2019-03-14 10:28:09	DEBUG	Stemmer handler ==>> stem_tokens:['9024'] and stem_without_stop_words:[]
2019-03-14 10:28:11	DEBUG	lemmatization handler ==>> lemma_tokens:['9024'] and lemma_without_stop_words:[]
2019-03-14 10:28:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:28:11	DEBUG	Ngram handler ==>> unigram:['9024'] == bigram:[] == trigram:[]
2019-03-14 10:28:18	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 10:28:18	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 10:28:18	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 10:28:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:28:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:28:18	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 10:28:18	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 10:28:18	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 10:28:18	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 10:28:18	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-14 10:28:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:28:18	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 10:30:19	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-14 10:30:19	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-14 10:30:19	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-14 10:30:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:30:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:30:19	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-14 10:30:22	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 10:30:22	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 10:30:22	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 10:30:22	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:30:22	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:30:22	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 10:30:22	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 10:30:22	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 10:30:22	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 10:30:22	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-14 10:30:22	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:30:22	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 10:30:25	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 10:30:25	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 10:30:25	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 10:30:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:30:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:30:25	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 10:30:25	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 10:30:25	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 10:30:25	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 10:30:25	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-14 10:30:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:30:25	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 10:31:14	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 10:31:14	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 10:31:14	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 10:31:14	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:31:14	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:31:14	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 10:31:15	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 10:31:15	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 10:31:15	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 10:31:15	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-14 10:31:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:31:15	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 10:31:22	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-14 10:31:22	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-14 10:31:22	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-14 10:31:22	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:31:22	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:31:22	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-14 10:31:27	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 10:31:27	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 10:31:27	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 10:31:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:31:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:31:27	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 10:31:27	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 10:31:27	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 10:31:27	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 10:31:27	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-14 10:31:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:31:27	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 10:31:30	DEBUG	Punctuation handler ==>> text to process:9
2019-03-14 10:31:30	DEBUG	Tokenization handler ==>> takens:['9'] and tokenize_without_stop_words:[]
2019-03-14 10:31:30	DEBUG	Stemmer handler ==>> stem_tokens:['9'] and stem_without_stop_words:[]
2019-03-14 10:31:30	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:31:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:31:30	DEBUG	Ngram handler ==>> unigram:['9'] == bigram:[] == trigram:[]
2019-03-14 10:31:30	DEBUG	Punctuation handler ==>> text to process:9
2019-03-14 10:31:30	DEBUG	Tokenization handler ==>> takens:['9'] and tokenize_without_stop_words:[]
2019-03-14 10:31:30	DEBUG	Stemmer handler ==>> stem_tokens:['9'] and stem_without_stop_words:[]
2019-03-14 10:31:30	DEBUG	lemmatization handler ==>> lemma_tokens:['9'] and lemma_without_stop_words:[]
2019-03-14 10:31:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:31:30	DEBUG	Ngram handler ==>> unigram:['9'] == bigram:[] == trigram:[]
2019-03-14 10:35:50	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-14 10:35:50	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-14 10:35:50	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-14 10:35:50	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:35:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:35:50	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-14 10:35:57	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 10:35:57	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 10:35:57	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 10:35:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:35:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:35:57	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 10:35:57	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 10:35:57	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 10:35:57	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 10:35:57	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-14 10:35:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:35:57	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 10:36:06	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 10:36:06	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 10:36:06	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 10:36:06	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:36:06	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:36:06	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 10:36:06	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 10:36:06	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 10:36:06	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 10:36:06	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-14 10:36:06	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:36:06	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 10:36:37	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-03-14 10:36:37	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-03-14 10:36:37	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-03-14 10:36:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:36:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:36:37	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:[] == trigram:[]
2019-03-14 10:36:37	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-03-14 10:36:37	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-03-14 10:36:37	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-03-14 10:36:37	DEBUG	lemmatization handler ==>> lemma_tokens:['rechrage'] and lemma_without_stop_words:[]
2019-03-14 10:36:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:36:37	DEBUG	Ngram handler ==>> unigram:['rechrage'] == bigram:[] == trigram:[]
2019-03-14 10:36:54	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-03-14 10:36:54	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-03-14 10:36:54	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-03-14 10:36:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:36:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:36:54	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:[] == trigram:[]
2019-03-14 10:36:55	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-03-14 10:36:55	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-03-14 10:36:55	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-03-14 10:36:55	DEBUG	lemmatization handler ==>> lemma_tokens:['rechrage'] and lemma_without_stop_words:[]
2019-03-14 10:36:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:36:55	DEBUG	Ngram handler ==>> unigram:['rechrage'] == bigram:[] == trigram:[]
2019-03-14 10:37:14	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 10:37:14	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 10:37:14	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 10:37:14	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:37:14	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:37:14	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 10:37:19	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 10:37:19	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 10:37:19	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 10:37:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:37:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:37:19	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 10:37:19	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 10:37:19	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 10:37:19	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 10:37:19	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-14 10:37:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:37:19	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 10:37:24	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 10:37:24	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 10:37:24	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 10:37:24	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:37:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:37:24	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 10:37:24	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 10:37:24	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 10:37:24	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 10:37:24	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-14 10:37:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:37:24	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 10:38:49	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 10:38:49	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 10:38:49	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 10:38:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:38:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:38:49	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 10:39:47	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 10:39:47	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 10:39:47	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 10:39:47	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:39:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:39:47	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 10:39:47	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 10:39:47	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 10:39:47	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 10:39:47	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-14 10:39:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:39:47	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 10:40:00	DEBUG	Punctuation handler ==>> text to process:80
2019-03-14 10:40:00	DEBUG	Tokenization handler ==>> takens:['80'] and tokenize_without_stop_words:[]
2019-03-14 10:40:00	DEBUG	Stemmer handler ==>> stem_tokens:['80'] and stem_without_stop_words:[]
2019-03-14 10:40:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:40:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:40:00	DEBUG	Ngram handler ==>> unigram:['80'] == bigram:[] == trigram:[]
2019-03-14 10:40:00	DEBUG	Punctuation handler ==>> text to process:80
2019-03-14 10:40:00	DEBUG	Tokenization handler ==>> takens:['80'] and tokenize_without_stop_words:[]
2019-03-14 10:40:00	DEBUG	Stemmer handler ==>> stem_tokens:['80'] and stem_without_stop_words:[]
2019-03-14 10:40:00	DEBUG	lemmatization handler ==>> lemma_tokens:['80'] and lemma_without_stop_words:[]
2019-03-14 10:40:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:40:00	DEBUG	Ngram handler ==>> unigram:['80'] == bigram:[] == trigram:[]
2019-03-14 10:42:11	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-03-14 10:42:11	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-03-14 10:42:11	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-03-14 10:42:11	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:42:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:42:11	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-03-14 10:42:11	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 10:42:11	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 10:42:11	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 10:42:11	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:42:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:42:11	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 10:42:11	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-14 10:42:11	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-14 10:42:11	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-14 10:42:11	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:42:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:42:11	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-14 10:42:11	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-14 10:42:11	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-14 10:42:11	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-14 10:42:11	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:42:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:42:11	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-14 10:42:11	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-03-14 10:42:11	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-03-14 10:42:11	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-03-14 10:42:11	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:42:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:42:11	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-03-14 10:42:46	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-14 10:42:46	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-14 10:42:46	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-14 10:42:46	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:42:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:42:46	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-14 10:43:04	DEBUG	Punctuation handler ==>> text to process:jaipur
2019-03-14 10:43:04	DEBUG	Tokenization handler ==>> takens:['jaipur'] and tokenize_without_stop_words:[]
2019-03-14 10:43:04	DEBUG	Stemmer handler ==>> stem_tokens:['jaipur'] and stem_without_stop_words:[]
2019-03-14 10:43:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:43:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:43:04	DEBUG	Ngram handler ==>> unigram:['jaipur'] == bigram:[] == trigram:[]
2019-03-14 10:43:04	DEBUG	Punctuation handler ==>> text to process:jaipur
2019-03-14 10:43:04	DEBUG	Tokenization handler ==>> takens:['jaipur'] and tokenize_without_stop_words:[]
2019-03-14 10:43:04	DEBUG	Stemmer handler ==>> stem_tokens:['jaipur'] and stem_without_stop_words:[]
2019-03-14 10:43:04	DEBUG	lemmatization handler ==>> lemma_tokens:['jaipur'] and lemma_without_stop_words:[]
2019-03-14 10:43:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:43:04	DEBUG	Ngram handler ==>> unigram:['jaipur'] == bigram:[] == trigram:[]
2019-03-14 10:43:11	DEBUG	Punctuation handler ==>> text to process:delhi
2019-03-14 10:43:11	DEBUG	Tokenization handler ==>> takens:['delhi'] and tokenize_without_stop_words:[]
2019-03-14 10:43:11	DEBUG	Stemmer handler ==>> stem_tokens:['delhi'] and stem_without_stop_words:[]
2019-03-14 10:43:11	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:43:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:43:11	DEBUG	Ngram handler ==>> unigram:['delhi'] == bigram:[] == trigram:[]
2019-03-14 10:43:11	DEBUG	Punctuation handler ==>> text to process:delhi
2019-03-14 10:43:11	DEBUG	Tokenization handler ==>> takens:['delhi'] and tokenize_without_stop_words:[]
2019-03-14 10:43:11	DEBUG	Stemmer handler ==>> stem_tokens:['delhi'] and stem_without_stop_words:[]
2019-03-14 10:43:11	DEBUG	lemmatization handler ==>> lemma_tokens:['delhi'] and lemma_without_stop_words:[]
2019-03-14 10:43:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:43:11	DEBUG	Ngram handler ==>> unigram:['delhi'] == bigram:[] == trigram:[]
2019-03-14 10:44:06	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-14 10:44:06	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-14 10:44:06	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-14 10:44:06	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:44:06	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:44:06	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-14 10:44:31	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 10:44:31	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 10:44:31	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 10:44:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:44:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:44:31	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 10:45:49	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 10:45:49	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 10:45:49	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 10:45:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 10:45:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 10:45:49	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 11:02:54	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 11:02:54	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 11:02:54	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 11:02:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 11:02:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 11:02:54	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 11:27:39	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-14 11:27:39	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-14 11:27:39	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-14 11:27:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 11:27:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 11:27:39	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-14 11:27:40	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-14 11:27:40	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-14 11:27:40	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-14 11:27:40	DEBUG	lemmatization handler ==>> lemma_tokens:['i', 'want', 'to', 'rechrage'] and lemma_without_stop_words:[]
2019-03-14 11:27:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 11:27:40	DEBUG	Ngram handler ==>> unigram:['i', 'want', 'to', 'rechrage'] == bigram:['i want', 'want to', 'to rechrage'] == trigram:['i want to', 'want to rechrage']
2019-03-14 11:29:02	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-14 11:29:02	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-14 11:29:02	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-14 11:29:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 11:29:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 11:29:02	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-14 11:29:02	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 11:29:02	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 11:29:02	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 11:29:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 11:29:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 11:29:02	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 11:29:02	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-03-14 11:29:02	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-03-14 11:29:02	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-03-14 11:29:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 11:29:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 11:29:02	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-03-14 11:29:02	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-14 11:29:02	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-14 11:29:02	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-14 11:29:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 11:29:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 11:29:02	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-14 11:29:02	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-14 11:29:02	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-14 11:29:02	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-14 11:29:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 11:29:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 11:29:02	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-14 11:29:02	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-03-14 11:29:02	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-03-14 11:29:02	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-03-14 11:29:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 11:29:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 11:29:02	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-03-14 11:31:11	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 11:31:11	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 11:31:11	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 11:31:11	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 11:31:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 11:31:11	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 11:42:39	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 11:42:39	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 11:42:39	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 11:42:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 11:42:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 11:42:39	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 11:43:31	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 11:43:31	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 11:43:31	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 11:43:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 11:43:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 11:43:31	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 11:44:31	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 11:44:31	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 11:44:31	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 11:44:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 11:44:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 11:44:31	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 11:44:35	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 11:44:35	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 11:44:35	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 11:44:35	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 11:44:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 11:44:35	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 11:44:36	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 11:44:36	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 11:44:36	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 11:44:36	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-14 11:44:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 11:44:36	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 11:44:38	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 11:44:38	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 11:44:38	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 11:44:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 11:44:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 11:44:38	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 11:44:38	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 11:44:38	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 11:44:38	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 11:44:38	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-14 11:44:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 11:44:38	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 11:55:02	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 11:55:02	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 11:55:02	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 11:55:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 11:55:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 11:55:02	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 11:55:46	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 11:55:46	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 11:55:46	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 11:55:46	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 11:55:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 11:55:46	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 12:05:33	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 12:05:33	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 12:05:33	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 12:05:33	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 12:05:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 12:05:33	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 12:18:27	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 12:18:27	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 12:18:27	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 12:18:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 12:18:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 12:18:27	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 12:18:53	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 12:18:53	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 12:18:53	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 12:18:53	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 12:18:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 12:18:53	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 12:19:23	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 12:19:23	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 12:19:23	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 12:19:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 12:19:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 12:19:23	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 12:23:33	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 12:23:33	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 12:23:33	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 12:23:33	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 12:23:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 12:23:33	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 12:24:14	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-14 12:24:14	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-14 12:24:14	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-14 12:24:14	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 12:24:14	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 12:24:14	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-14 12:25:46	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 12:25:46	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 12:25:46	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 12:25:46	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 12:25:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 12:25:46	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 12:29:52	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 12:29:52	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 12:29:52	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 12:29:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 12:29:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 12:29:52	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 12:32:15	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 12:32:15	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 12:32:15	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 12:32:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 12:32:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 12:32:15	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 12:33:13	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 12:33:13	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 12:33:13	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 12:33:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 12:33:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 12:33:13	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 12:36:09	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 12:36:09	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 12:36:09	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 12:36:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 12:36:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 12:36:09	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 12:37:21	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 12:37:21	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 12:37:21	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 12:37:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 12:37:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 12:37:21	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 12:38:03	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 12:38:03	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 12:38:03	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 12:38:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 12:38:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 12:38:03	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 14:46:23	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 14:46:23	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 14:46:23	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 14:46:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:46:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:46:23	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 14:48:22	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 14:48:22	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 14:48:22	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 14:48:22	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:48:22	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:48:22	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 14:51:23	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 14:51:23	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 14:51:23	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 14:51:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:51:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:51:23	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 14:51:28	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 14:51:28	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 14:51:28	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 14:51:28	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:51:28	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:51:28	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 14:51:29	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 14:51:29	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 14:51:29	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 14:51:31	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-14 14:51:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:51:31	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 14:51:35	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 14:51:35	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 14:51:35	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 14:51:35	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:51:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:51:35	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 14:51:35	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 14:51:35	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 14:51:35	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 14:51:35	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-14 14:51:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:51:35	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 14:53:16	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 14:53:16	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 14:53:16	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 14:53:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:53:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:53:16	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 14:53:21	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 14:53:21	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 14:53:21	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 14:53:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:53:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:53:21	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 14:53:21	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 14:53:21	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 14:53:21	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 14:53:21	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-14 14:53:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:53:21	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 14:53:37	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 14:53:37	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 14:53:38	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 14:53:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:53:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:53:38	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 14:53:38	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 14:53:38	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 14:53:38	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 14:53:38	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-14 14:53:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:53:38	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 14:55:03	DEBUG	Punctuation handler ==>> text to process:hi
2019-03-14 14:55:03	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-03-14 14:55:03	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-03-14 14:55:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:55:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:55:03	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-03-14 14:55:03	DEBUG	Punctuation handler ==>> text to process:hi
2019-03-14 14:55:03	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-03-14 14:55:03	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-03-14 14:55:03	DEBUG	lemmatization handler ==>> lemma_tokens:['hi'] and lemma_without_stop_words:[]
2019-03-14 14:55:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:55:03	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-03-14 14:55:15	DEBUG	Punctuation handler ==>> text to process:hi
2019-03-14 14:55:15	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-03-14 14:55:15	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-03-14 14:55:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:55:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:55:15	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-03-14 14:55:16	DEBUG	Punctuation handler ==>> text to process:hi
2019-03-14 14:55:16	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-03-14 14:55:16	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-03-14 14:55:16	DEBUG	lemmatization handler ==>> lemma_tokens:['hi'] and lemma_without_stop_words:[]
2019-03-14 14:55:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:55:16	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-03-14 14:55:32	DEBUG	Punctuation handler ==>> text to process:hello
2019-03-14 14:55:32	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-03-14 14:55:32	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-03-14 14:55:32	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:55:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:55:32	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-03-14 14:55:32	DEBUG	Punctuation handler ==>> text to process:hello
2019-03-14 14:55:32	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-03-14 14:55:32	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-03-14 14:55:32	DEBUG	lemmatization handler ==>> lemma_tokens:['hello'] and lemma_without_stop_words:[]
2019-03-14 14:55:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:55:32	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-03-14 14:56:03	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 14:56:03	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 14:56:03	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 14:56:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:56:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:56:03	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 14:56:06	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 14:56:06	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 14:56:06	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 14:56:06	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:56:06	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:56:06	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 14:56:06	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 14:56:06	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 14:56:06	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 14:56:06	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-14 14:56:06	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:56:06	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 14:56:09	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 14:56:09	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 14:56:09	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 14:56:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:56:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:56:09	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 14:56:09	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 14:56:09	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 14:56:09	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 14:56:09	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-14 14:56:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:56:09	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 14:56:37	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-03-14 14:56:37	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-03-14 14:56:37	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-03-14 14:56:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:56:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:56:37	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-03-14 14:56:37	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 14:56:37	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 14:56:37	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 14:56:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:56:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:56:37	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 14:56:37	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-14 14:56:37	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-14 14:56:37	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-14 14:56:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:56:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:56:37	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-14 14:56:37	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-14 14:56:37	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-14 14:56:37	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-14 14:56:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:56:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:56:37	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-14 14:56:37	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-14 14:56:37	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-14 14:56:37	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-14 14:56:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:56:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:56:37	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-14 14:56:37	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-03-14 14:56:37	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-03-14 14:56:38	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-03-14 14:56:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:56:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:56:38	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-03-14 14:57:12	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 14:57:12	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 14:57:12	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 14:57:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:57:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:57:12	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 14:57:15	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 14:57:15	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 14:57:15	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 14:57:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:57:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:57:15	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 14:57:15	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 14:57:15	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 14:57:15	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 14:57:15	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-14 14:57:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:57:15	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 14:57:18	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 14:57:18	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 14:57:18	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 14:57:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:57:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:57:18	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 14:57:18	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 14:57:18	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 14:57:18	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 14:57:18	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-14 14:57:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:57:18	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 14:57:26	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-03-14 14:57:26	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-03-14 14:57:26	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-03-14 14:57:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:57:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:57:26	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-03-14 14:57:26	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 14:57:26	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 14:57:26	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 14:57:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:57:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:57:26	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 14:57:26	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-14 14:57:26	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-14 14:57:26	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-14 14:57:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:57:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:57:26	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-14 14:57:26	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-14 14:57:26	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-14 14:57:26	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-14 14:57:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:57:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:57:26	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-14 14:57:26	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-14 14:57:26	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-14 14:57:26	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-14 14:57:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:57:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:57:26	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-14 14:57:26	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-03-14 14:57:26	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-03-14 14:57:26	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-03-14 14:57:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:57:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:57:26	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-03-14 14:58:08	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-03-14 14:58:08	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-03-14 14:58:08	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-03-14 14:58:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:58:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:58:08	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-03-14 14:58:08	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 14:58:08	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 14:58:08	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 14:58:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:58:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:58:08	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 14:58:08	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-14 14:58:08	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-14 14:58:08	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-14 14:58:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:58:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:58:08	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-14 14:58:08	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-14 14:58:08	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-14 14:58:08	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-14 14:58:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:58:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:58:08	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-14 14:58:08	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-14 14:58:08	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-14 14:58:08	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-14 14:58:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:58:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:58:08	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-14 14:58:08	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-03-14 14:58:08	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-03-14 14:58:08	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-03-14 14:58:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 14:58:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 14:58:08	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-03-14 15:01:15	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 15:01:15	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 15:01:15	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 15:01:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:01:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:01:15	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 15:01:21	DEBUG	Punctuation handler ==>> text to process:9024627167
2019-03-14 15:01:21	DEBUG	Tokenization handler ==>> takens:['9024627167'] and tokenize_without_stop_words:[]
2019-03-14 15:01:21	DEBUG	Stemmer handler ==>> stem_tokens:['9024627167'] and stem_without_stop_words:[]
2019-03-14 15:01:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:01:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:01:21	DEBUG	Ngram handler ==>> unigram:['9024627167'] == bigram:[] == trigram:[]
2019-03-14 15:01:22	DEBUG	Punctuation handler ==>> text to process:9024627167
2019-03-14 15:01:22	DEBUG	Tokenization handler ==>> takens:['9024627167'] and tokenize_without_stop_words:[]
2019-03-14 15:01:22	DEBUG	Stemmer handler ==>> stem_tokens:['9024627167'] and stem_without_stop_words:[]
2019-03-14 15:01:22	DEBUG	lemmatization handler ==>> lemma_tokens:['9024627167'] and lemma_without_stop_words:[]
2019-03-14 15:01:22	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:01:22	DEBUG	Ngram handler ==>> unigram:['9024627167'] == bigram:[] == trigram:[]
2019-03-14 15:01:25	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 15:01:25	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 15:01:25	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 15:01:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:01:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:01:25	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 15:01:25	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 15:01:25	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 15:01:25	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 15:01:25	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-14 15:01:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:01:25	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 15:01:36	DEBUG	Punctuation handler ==>> text to process:process
2019-03-14 15:01:36	DEBUG	Tokenization handler ==>> takens:['process'] and tokenize_without_stop_words:[]
2019-03-14 15:01:36	DEBUG	Stemmer handler ==>> stem_tokens:['process'] and stem_without_stop_words:[]
2019-03-14 15:01:36	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:01:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:01:36	DEBUG	Ngram handler ==>> unigram:['process'] == bigram:[] == trigram:[]
2019-03-14 15:01:36	DEBUG	Punctuation handler ==>> text to process:process
2019-03-14 15:01:36	DEBUG	Tokenization handler ==>> takens:['process'] and tokenize_without_stop_words:[]
2019-03-14 15:01:36	DEBUG	Stemmer handler ==>> stem_tokens:['process'] and stem_without_stop_words:[]
2019-03-14 15:01:36	DEBUG	lemmatization handler ==>> lemma_tokens:['process'] and lemma_without_stop_words:[]
2019-03-14 15:01:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:01:36	DEBUG	Ngram handler ==>> unigram:['process'] == bigram:[] == trigram:[]
2019-03-14 15:01:54	DEBUG	Punctuation handler ==>> text to process:i want to rechrage again
2019-03-14 15:01:54	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage', 'again'] and tokenize_without_stop_words:[]
2019-03-14 15:01:54	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag', 'again'] and stem_without_stop_words:[]
2019-03-14 15:01:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:01:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:01:54	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag', 'rechrag again'] == trigram:['want to rechrag', 'to rechrag again']
2019-03-14 15:02:03	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-03-14 15:02:03	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-03-14 15:02:03	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-03-14 15:02:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:02:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:02:03	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-03-14 15:02:03	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 15:02:03	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 15:02:03	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 15:02:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:02:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:02:03	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 15:02:03	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-14 15:02:03	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-14 15:02:03	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-14 15:02:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:02:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:02:03	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-14 15:02:03	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-14 15:02:03	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-14 15:02:03	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-14 15:02:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:02:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:02:03	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-14 15:02:03	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-14 15:02:03	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-14 15:02:03	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-14 15:02:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:02:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:02:04	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-14 15:02:04	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-03-14 15:02:04	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-03-14 15:02:04	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-03-14 15:02:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:02:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:02:04	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-03-14 15:02:45	DEBUG	Punctuation handler ==>> text to process:process
2019-03-14 15:02:45	DEBUG	Tokenization handler ==>> takens:['process'] and tokenize_without_stop_words:[]
2019-03-14 15:02:45	DEBUG	Stemmer handler ==>> stem_tokens:['process'] and stem_without_stop_words:[]
2019-03-14 15:02:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:02:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:02:45	DEBUG	Ngram handler ==>> unigram:['process'] == bigram:[] == trigram:[]
2019-03-14 15:02:45	DEBUG	Punctuation handler ==>> text to process:process
2019-03-14 15:02:45	DEBUG	Tokenization handler ==>> takens:['process'] and tokenize_without_stop_words:[]
2019-03-14 15:02:45	DEBUG	Stemmer handler ==>> stem_tokens:['process'] and stem_without_stop_words:[]
2019-03-14 15:02:45	DEBUG	lemmatization handler ==>> lemma_tokens:['process'] and lemma_without_stop_words:[]
2019-03-14 15:02:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:02:45	DEBUG	Ngram handler ==>> unigram:['process'] == bigram:[] == trigram:[]
2019-03-14 15:02:53	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-14 15:02:53	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-14 15:02:53	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-14 15:02:53	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:02:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:02:53	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-14 15:03:08	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-14 15:03:08	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-14 15:03:08	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-14 15:03:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:03:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:03:08	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-14 15:03:16	DEBUG	Punctuation handler ==>> text to process:9024627167
2019-03-14 15:03:16	DEBUG	Tokenization handler ==>> takens:['9024627167'] and tokenize_without_stop_words:[]
2019-03-14 15:03:16	DEBUG	Stemmer handler ==>> stem_tokens:['9024627167'] and stem_without_stop_words:[]
2019-03-14 15:03:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:03:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:03:16	DEBUG	Ngram handler ==>> unigram:['9024627167'] == bigram:[] == trigram:[]
2019-03-14 15:03:17	DEBUG	Punctuation handler ==>> text to process:9024627167
2019-03-14 15:03:17	DEBUG	Tokenization handler ==>> takens:['9024627167'] and tokenize_without_stop_words:[]
2019-03-14 15:03:17	DEBUG	Stemmer handler ==>> stem_tokens:['9024627167'] and stem_without_stop_words:[]
2019-03-14 15:03:17	DEBUG	lemmatization handler ==>> lemma_tokens:['9024627167'] and lemma_without_stop_words:[]
2019-03-14 15:03:17	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:03:17	DEBUG	Ngram handler ==>> unigram:['9024627167'] == bigram:[] == trigram:[]
2019-03-14 15:03:20	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 15:03:20	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 15:03:20	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 15:03:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:03:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:03:20	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 15:03:20	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 15:03:20	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 15:03:20	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 15:03:20	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-14 15:03:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:03:20	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 15:03:28	DEBUG	Punctuation handler ==>> text to process:process
2019-03-14 15:03:28	DEBUG	Tokenization handler ==>> takens:['process'] and tokenize_without_stop_words:[]
2019-03-14 15:03:28	DEBUG	Stemmer handler ==>> stem_tokens:['process'] and stem_without_stop_words:[]
2019-03-14 15:03:28	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:03:28	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:03:28	DEBUG	Ngram handler ==>> unigram:['process'] == bigram:[] == trigram:[]
2019-03-14 15:03:28	DEBUG	Punctuation handler ==>> text to process:process
2019-03-14 15:03:28	DEBUG	Tokenization handler ==>> takens:['process'] and tokenize_without_stop_words:[]
2019-03-14 15:03:28	DEBUG	Stemmer handler ==>> stem_tokens:['process'] and stem_without_stop_words:[]
2019-03-14 15:03:28	DEBUG	lemmatization handler ==>> lemma_tokens:['process'] and lemma_without_stop_words:[]
2019-03-14 15:03:28	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:03:28	DEBUG	Ngram handler ==>> unigram:['process'] == bigram:[] == trigram:[]
2019-03-14 15:03:41	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-14 15:03:41	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-14 15:03:41	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-14 15:03:41	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:03:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:03:41	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-14 15:03:46	DEBUG	Punctuation handler ==>> text to process:9024627167
2019-03-14 15:03:46	DEBUG	Tokenization handler ==>> takens:['9024627167'] and tokenize_without_stop_words:[]
2019-03-14 15:03:46	DEBUG	Stemmer handler ==>> stem_tokens:['9024627167'] and stem_without_stop_words:[]
2019-03-14 15:03:46	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:03:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:03:46	DEBUG	Ngram handler ==>> unigram:['9024627167'] == bigram:[] == trigram:[]
2019-03-14 15:03:46	DEBUG	Punctuation handler ==>> text to process:9024627167
2019-03-14 15:03:46	DEBUG	Tokenization handler ==>> takens:['9024627167'] and tokenize_without_stop_words:[]
2019-03-14 15:03:46	DEBUG	Stemmer handler ==>> stem_tokens:['9024627167'] and stem_without_stop_words:[]
2019-03-14 15:03:46	DEBUG	lemmatization handler ==>> lemma_tokens:['9024627167'] and lemma_without_stop_words:[]
2019-03-14 15:03:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:03:46	DEBUG	Ngram handler ==>> unigram:['9024627167'] == bigram:[] == trigram:[]
2019-03-14 15:03:49	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 15:03:49	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 15:03:49	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 15:03:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:03:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:03:49	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 15:03:49	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 15:03:49	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 15:03:49	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 15:03:49	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-14 15:03:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:03:49	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 15:04:09	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-03-14 15:04:09	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-03-14 15:04:09	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-03-14 15:04:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:04:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:04:09	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-03-14 15:04:09	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 15:04:09	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 15:04:09	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 15:04:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:04:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:04:09	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 15:04:09	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-14 15:04:09	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-14 15:04:09	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-14 15:04:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:04:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:04:09	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-14 15:04:09	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-14 15:04:09	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-14 15:04:09	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-14 15:04:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:04:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:04:09	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-14 15:04:09	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-14 15:04:09	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-14 15:04:09	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-14 15:04:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:04:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:04:09	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-14 15:04:09	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-03-14 15:04:09	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-03-14 15:04:09	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-03-14 15:04:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:04:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:04:09	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-03-14 15:04:59	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-14 15:04:59	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-14 15:04:59	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-14 15:04:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:04:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:04:59	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-14 15:05:04	DEBUG	Punctuation handler ==>> text to process:9024627167
2019-03-14 15:05:04	DEBUG	Tokenization handler ==>> takens:['9024627167'] and tokenize_without_stop_words:[]
2019-03-14 15:05:04	DEBUG	Stemmer handler ==>> stem_tokens:['9024627167'] and stem_without_stop_words:[]
2019-03-14 15:05:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:05:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:05:04	DEBUG	Ngram handler ==>> unigram:['9024627167'] == bigram:[] == trigram:[]
2019-03-14 15:05:04	DEBUG	Punctuation handler ==>> text to process:9024627167
2019-03-14 15:05:04	DEBUG	Tokenization handler ==>> takens:['9024627167'] and tokenize_without_stop_words:[]
2019-03-14 15:05:04	DEBUG	Stemmer handler ==>> stem_tokens:['9024627167'] and stem_without_stop_words:[]
2019-03-14 15:05:04	DEBUG	lemmatization handler ==>> lemma_tokens:['9024627167'] and lemma_without_stop_words:[]
2019-03-14 15:05:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:05:04	DEBUG	Ngram handler ==>> unigram:['9024627167'] == bigram:[] == trigram:[]
2019-03-14 15:05:07	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 15:05:07	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 15:05:07	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 15:05:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:05:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:05:07	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 15:05:07	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 15:05:07	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 15:05:07	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 15:05:07	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-14 15:05:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:05:07	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 15:05:14	DEBUG	Punctuation handler ==>> text to process:process
2019-03-14 15:05:14	DEBUG	Tokenization handler ==>> takens:['process'] and tokenize_without_stop_words:[]
2019-03-14 15:05:14	DEBUG	Stemmer handler ==>> stem_tokens:['process'] and stem_without_stop_words:[]
2019-03-14 15:05:14	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:05:14	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:05:14	DEBUG	Ngram handler ==>> unigram:['process'] == bigram:[] == trigram:[]
2019-03-14 15:05:14	DEBUG	Punctuation handler ==>> text to process:process
2019-03-14 15:05:14	DEBUG	Tokenization handler ==>> takens:['process'] and tokenize_without_stop_words:[]
2019-03-14 15:05:14	DEBUG	Stemmer handler ==>> stem_tokens:['process'] and stem_without_stop_words:[]
2019-03-14 15:05:14	DEBUG	lemmatization handler ==>> lemma_tokens:['process'] and lemma_without_stop_words:[]
2019-03-14 15:05:14	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:05:14	DEBUG	Ngram handler ==>> unigram:['process'] == bigram:[] == trigram:[]
2019-03-14 15:05:26	DEBUG	Punctuation handler ==>> text to process:ok plz modified your detail
2019-03-14 15:05:26	DEBUG	Tokenization handler ==>> takens:['ok', 'plz', 'modified', 'your', 'detail'] and tokenize_without_stop_words:[]
2019-03-14 15:05:26	DEBUG	Stemmer handler ==>> stem_tokens:['ok', 'plz', 'modifi', 'your', 'detail'] and stem_without_stop_words:[]
2019-03-14 15:05:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:05:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:05:26	DEBUG	Ngram handler ==>> unigram:['ok', 'plz', 'modifi', 'detail'] == bigram:['ok plz', 'plz modifi', 'modifi your', 'your detail'] == trigram:['ok plz modifi', 'plz modifi your', 'modifi your detail']
2019-03-14 15:05:26	DEBUG	Punctuation handler ==>> text to process:ok plz modified your detail
2019-03-14 15:05:26	DEBUG	Tokenization handler ==>> takens:['ok', 'plz', 'modified', 'your', 'detail'] and tokenize_without_stop_words:[]
2019-03-14 15:05:26	DEBUG	Stemmer handler ==>> stem_tokens:['ok', 'plz', 'modifi', 'your', 'detail'] and stem_without_stop_words:[]
2019-03-14 15:05:26	DEBUG	lemmatization handler ==>> lemma_tokens:['ok', 'plz', 'modified', 'your', 'detail'] and lemma_without_stop_words:[]
2019-03-14 15:05:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:05:26	DEBUG	Ngram handler ==>> unigram:['ok', 'plz', 'modified', 'your', 'detail'] == bigram:['ok plz', 'plz modified', 'modified your', 'your detail'] == trigram:['ok plz modified', 'plz modified your', 'modified your detail']
2019-03-14 15:05:47	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-14 15:05:47	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-14 15:05:47	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-14 15:05:47	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:05:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:05:47	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-14 15:05:51	DEBUG	Punctuation handler ==>> text to process:9024
2019-03-14 15:05:51	DEBUG	Tokenization handler ==>> takens:['9024'] and tokenize_without_stop_words:[]
2019-03-14 15:05:51	DEBUG	Stemmer handler ==>> stem_tokens:['9024'] and stem_without_stop_words:[]
2019-03-14 15:05:51	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:05:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:05:51	DEBUG	Ngram handler ==>> unigram:['9024'] == bigram:[] == trigram:[]
2019-03-14 15:05:51	DEBUG	Punctuation handler ==>> text to process:9024
2019-03-14 15:05:51	DEBUG	Tokenization handler ==>> takens:['9024'] and tokenize_without_stop_words:[]
2019-03-14 15:05:51	DEBUG	Stemmer handler ==>> stem_tokens:['9024'] and stem_without_stop_words:[]
2019-03-14 15:05:51	DEBUG	lemmatization handler ==>> lemma_tokens:['9024'] and lemma_without_stop_words:[]
2019-03-14 15:05:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:05:51	DEBUG	Ngram handler ==>> unigram:['9024'] == bigram:[] == trigram:[]
2019-03-14 15:05:54	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 15:05:54	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 15:05:54	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 15:05:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:05:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:05:54	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 15:05:54	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 15:05:54	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 15:05:54	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 15:05:54	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-14 15:05:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:05:54	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 15:06:22	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-03-14 15:06:22	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-03-14 15:06:22	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-03-14 15:06:22	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:06:22	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:06:22	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-03-14 15:06:22	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 15:06:22	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 15:06:22	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 15:06:22	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:06:22	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:06:22	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 15:06:22	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-14 15:06:22	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-14 15:06:22	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-14 15:06:22	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:06:22	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:06:22	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-14 15:06:22	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-14 15:06:22	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-14 15:06:22	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-14 15:06:22	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:06:22	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:06:22	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-14 15:06:22	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-14 15:06:22	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-14 15:06:22	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-14 15:06:22	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:06:22	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:06:22	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-14 15:06:22	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-03-14 15:06:22	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-03-14 15:06:22	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-03-14 15:06:22	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:06:22	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:06:22	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-03-14 15:07:27	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-03-14 15:07:27	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-03-14 15:07:27	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-03-14 15:07:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:07:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:07:27	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-03-14 15:07:27	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 15:07:27	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 15:07:27	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 15:07:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:07:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:07:27	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 15:07:27	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-14 15:07:27	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-14 15:07:27	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-14 15:07:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:07:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:07:27	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-14 15:07:27	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-14 15:07:27	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-14 15:07:27	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-14 15:07:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:07:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:07:27	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-14 15:07:27	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-14 15:07:27	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-14 15:07:27	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-14 15:07:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:07:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:07:27	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-14 15:07:27	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-03-14 15:07:27	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-03-14 15:07:27	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-03-14 15:07:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:07:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:07:27	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-03-14 15:09:17	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-03-14 15:09:17	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-03-14 15:09:17	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-03-14 15:09:17	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:09:17	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:09:17	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-03-14 15:09:17	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 15:09:17	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 15:09:17	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 15:09:17	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:09:17	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:09:17	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 15:09:17	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-14 15:09:17	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-14 15:09:17	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-14 15:09:17	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:09:17	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:09:17	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-14 15:09:17	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-14 15:09:17	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-14 15:09:17	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-14 15:09:17	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:09:17	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:09:17	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-14 15:09:17	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-14 15:09:17	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-14 15:09:17	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-14 15:09:17	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:09:17	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:09:17	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-14 15:09:17	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-03-14 15:09:17	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-03-14 15:09:17	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-03-14 15:09:17	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:09:17	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:09:17	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-03-14 15:09:23	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-03-14 15:09:23	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-03-14 15:09:23	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-03-14 15:09:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:09:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:09:23	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-03-14 15:09:23	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 15:09:23	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 15:09:23	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 15:09:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:09:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:09:23	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 15:09:23	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-14 15:09:23	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-14 15:09:23	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-14 15:09:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:09:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:09:23	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-14 15:09:23	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-14 15:09:23	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-14 15:09:23	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-14 15:09:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:09:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:09:23	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-14 15:09:23	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-14 15:09:23	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-14 15:09:23	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-14 15:09:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:09:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:09:23	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-14 15:09:23	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-03-14 15:09:23	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-03-14 15:09:23	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-03-14 15:09:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:09:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:09:23	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-03-14 15:10:08	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-14 15:10:08	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-14 15:10:08	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-14 15:10:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:10:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:10:08	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-14 15:10:12	DEBUG	Punctuation handler ==>> text to process:9024627167
2019-03-14 15:10:12	DEBUG	Tokenization handler ==>> takens:['9024627167'] and tokenize_without_stop_words:[]
2019-03-14 15:10:12	DEBUG	Stemmer handler ==>> stem_tokens:['9024627167'] and stem_without_stop_words:[]
2019-03-14 15:10:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:10:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:10:12	DEBUG	Ngram handler ==>> unigram:['9024627167'] == bigram:[] == trigram:[]
2019-03-14 15:10:13	DEBUG	Punctuation handler ==>> text to process:9024627167
2019-03-14 15:10:13	DEBUG	Tokenization handler ==>> takens:['9024627167'] and tokenize_without_stop_words:[]
2019-03-14 15:10:13	DEBUG	Stemmer handler ==>> stem_tokens:['9024627167'] and stem_without_stop_words:[]
2019-03-14 15:10:13	DEBUG	lemmatization handler ==>> lemma_tokens:['9024627167'] and lemma_without_stop_words:[]
2019-03-14 15:10:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:10:13	DEBUG	Ngram handler ==>> unigram:['9024627167'] == bigram:[] == trigram:[]
2019-03-14 15:10:16	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 15:10:16	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 15:10:16	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 15:10:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:10:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:10:16	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 15:10:16	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 15:10:16	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 15:10:16	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 15:10:16	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-14 15:10:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:10:16	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 15:10:22	DEBUG	Punctuation handler ==>> text to process:postpaid
2019-03-14 15:10:22	DEBUG	Tokenization handler ==>> takens:['postpaid'] and tokenize_without_stop_words:[]
2019-03-14 15:10:22	DEBUG	Stemmer handler ==>> stem_tokens:['postpaid'] and stem_without_stop_words:[]
2019-03-14 15:10:22	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:10:22	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:10:22	DEBUG	Ngram handler ==>> unigram:['postpaid'] == bigram:[] == trigram:[]
2019-03-14 15:10:22	DEBUG	Punctuation handler ==>> text to process:postpaid
2019-03-14 15:10:22	DEBUG	Tokenization handler ==>> takens:['postpaid'] and tokenize_without_stop_words:[]
2019-03-14 15:10:22	DEBUG	Stemmer handler ==>> stem_tokens:['postpaid'] and stem_without_stop_words:[]
2019-03-14 15:10:22	DEBUG	lemmatization handler ==>> lemma_tokens:['postpaid'] and lemma_without_stop_words:[]
2019-03-14 15:10:22	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:10:22	DEBUG	Ngram handler ==>> unigram:['postpaid'] == bigram:[] == trigram:[]
2019-03-14 15:10:31	DEBUG	Punctuation handler ==>> text to process:process
2019-03-14 15:10:31	DEBUG	Tokenization handler ==>> takens:['process'] and tokenize_without_stop_words:[]
2019-03-14 15:10:31	DEBUG	Stemmer handler ==>> stem_tokens:['process'] and stem_without_stop_words:[]
2019-03-14 15:10:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:10:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:10:31	DEBUG	Ngram handler ==>> unigram:['process'] == bigram:[] == trigram:[]
2019-03-14 15:10:31	DEBUG	Punctuation handler ==>> text to process:process
2019-03-14 15:10:31	DEBUG	Tokenization handler ==>> takens:['process'] and tokenize_without_stop_words:[]
2019-03-14 15:10:31	DEBUG	Stemmer handler ==>> stem_tokens:['process'] and stem_without_stop_words:[]
2019-03-14 15:10:31	DEBUG	lemmatization handler ==>> lemma_tokens:['process'] and lemma_without_stop_words:[]
2019-03-14 15:10:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:10:31	DEBUG	Ngram handler ==>> unigram:['process'] == bigram:[] == trigram:[]
2019-03-14 15:11:17	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-14 15:11:17	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-14 15:11:17	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-14 15:11:17	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:11:17	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:11:17	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-14 15:11:44	DEBUG	Punctuation handler ==>> text to process:9024627167
2019-03-14 15:11:44	DEBUG	Tokenization handler ==>> takens:['9024627167'] and tokenize_without_stop_words:[]
2019-03-14 15:11:44	DEBUG	Stemmer handler ==>> stem_tokens:['9024627167'] and stem_without_stop_words:[]
2019-03-14 15:11:44	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:11:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:11:44	DEBUG	Ngram handler ==>> unigram:['9024627167'] == bigram:[] == trigram:[]
2019-03-14 15:11:44	DEBUG	Punctuation handler ==>> text to process:9024627167
2019-03-14 15:11:44	DEBUG	Tokenization handler ==>> takens:['9024627167'] and tokenize_without_stop_words:[]
2019-03-14 15:11:44	DEBUG	Stemmer handler ==>> stem_tokens:['9024627167'] and stem_without_stop_words:[]
2019-03-14 15:11:44	DEBUG	lemmatization handler ==>> lemma_tokens:['9024627167'] and lemma_without_stop_words:[]
2019-03-14 15:11:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:11:44	DEBUG	Ngram handler ==>> unigram:['9024627167'] == bigram:[] == trigram:[]
2019-03-14 15:11:52	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 15:11:52	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 15:11:52	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 15:11:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:11:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:11:52	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 15:11:52	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 15:11:52	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 15:11:52	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 15:11:52	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-14 15:11:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:11:52	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 15:12:08	DEBUG	Punctuation handler ==>> text to process:prepaid
2019-03-14 15:12:08	DEBUG	Tokenization handler ==>> takens:['prepaid'] and tokenize_without_stop_words:[]
2019-03-14 15:12:08	DEBUG	Stemmer handler ==>> stem_tokens:['prepaid'] and stem_without_stop_words:[]
2019-03-14 15:12:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:12:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:12:08	DEBUG	Ngram handler ==>> unigram:['prepaid'] == bigram:[] == trigram:[]
2019-03-14 15:12:08	DEBUG	Punctuation handler ==>> text to process:prepaid
2019-03-14 15:12:08	DEBUG	Tokenization handler ==>> takens:['prepaid'] and tokenize_without_stop_words:[]
2019-03-14 15:12:08	DEBUG	Stemmer handler ==>> stem_tokens:['prepaid'] and stem_without_stop_words:[]
2019-03-14 15:12:08	DEBUG	lemmatization handler ==>> lemma_tokens:['prepaid'] and lemma_without_stop_words:[]
2019-03-14 15:12:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:12:08	DEBUG	Ngram handler ==>> unigram:['prepaid'] == bigram:[] == trigram:[]
2019-03-14 15:12:18	DEBUG	Punctuation handler ==>> text to process:process
2019-03-14 15:12:18	DEBUG	Tokenization handler ==>> takens:['process'] and tokenize_without_stop_words:[]
2019-03-14 15:12:18	DEBUG	Stemmer handler ==>> stem_tokens:['process'] and stem_without_stop_words:[]
2019-03-14 15:12:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:12:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:12:18	DEBUG	Ngram handler ==>> unigram:['process'] == bigram:[] == trigram:[]
2019-03-14 15:12:18	DEBUG	Punctuation handler ==>> text to process:process
2019-03-14 15:12:18	DEBUG	Tokenization handler ==>> takens:['process'] and tokenize_without_stop_words:[]
2019-03-14 15:12:18	DEBUG	Stemmer handler ==>> stem_tokens:['process'] and stem_without_stop_words:[]
2019-03-14 15:12:18	DEBUG	lemmatization handler ==>> lemma_tokens:['process'] and lemma_without_stop_words:[]
2019-03-14 15:12:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:12:18	DEBUG	Ngram handler ==>> unigram:['process'] == bigram:[] == trigram:[]
2019-03-14 15:13:40	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-03-14 15:13:40	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-03-14 15:13:40	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-03-14 15:13:40	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:13:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:13:40	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-03-14 15:13:40	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 15:13:40	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 15:13:40	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 15:13:40	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:13:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:13:40	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 15:13:40	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-14 15:13:40	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-14 15:13:40	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-14 15:13:40	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:13:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:13:40	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-14 15:13:40	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-14 15:13:40	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-14 15:13:40	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-14 15:13:40	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:13:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:13:40	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-14 15:13:40	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-14 15:13:40	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-14 15:13:40	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-14 15:13:40	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:13:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:13:40	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-14 15:13:40	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-03-14 15:13:40	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-03-14 15:13:40	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-03-14 15:13:40	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:13:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:13:40	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-03-14 15:15:18	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-14 15:15:18	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-14 15:15:18	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-14 15:15:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:15:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:15:18	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-14 15:15:22	DEBUG	Punctuation handler ==>> text to process:9024
2019-03-14 15:15:22	DEBUG	Tokenization handler ==>> takens:['9024'] and tokenize_without_stop_words:[]
2019-03-14 15:15:22	DEBUG	Stemmer handler ==>> stem_tokens:['9024'] and stem_without_stop_words:[]
2019-03-14 15:15:22	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:15:22	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:15:22	DEBUG	Ngram handler ==>> unigram:['9024'] == bigram:[] == trigram:[]
2019-03-14 15:15:22	DEBUG	Punctuation handler ==>> text to process:9024
2019-03-14 15:15:22	DEBUG	Tokenization handler ==>> takens:['9024'] and tokenize_without_stop_words:[]
2019-03-14 15:15:22	DEBUG	Stemmer handler ==>> stem_tokens:['9024'] and stem_without_stop_words:[]
2019-03-14 15:15:22	DEBUG	lemmatization handler ==>> lemma_tokens:['9024'] and lemma_without_stop_words:[]
2019-03-14 15:15:22	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:15:22	DEBUG	Ngram handler ==>> unigram:['9024'] == bigram:[] == trigram:[]
2019-03-14 15:15:24	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 15:15:24	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 15:15:24	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 15:15:24	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:15:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:15:24	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 15:15:24	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 15:15:24	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 15:15:24	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 15:15:24	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-14 15:15:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:15:24	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 15:15:30	DEBUG	Punctuation handler ==>> text to process:postpaid
2019-03-14 15:15:30	DEBUG	Tokenization handler ==>> takens:['postpaid'] and tokenize_without_stop_words:[]
2019-03-14 15:15:30	DEBUG	Stemmer handler ==>> stem_tokens:['postpaid'] and stem_without_stop_words:[]
2019-03-14 15:15:30	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:15:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:15:30	DEBUG	Ngram handler ==>> unigram:['postpaid'] == bigram:[] == trigram:[]
2019-03-14 15:15:30	DEBUG	Punctuation handler ==>> text to process:postpaid
2019-03-14 15:15:30	DEBUG	Tokenization handler ==>> takens:['postpaid'] and tokenize_without_stop_words:[]
2019-03-14 15:15:30	DEBUG	Stemmer handler ==>> stem_tokens:['postpaid'] and stem_without_stop_words:[]
2019-03-14 15:15:30	DEBUG	lemmatization handler ==>> lemma_tokens:['postpaid'] and lemma_without_stop_words:[]
2019-03-14 15:15:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:15:30	DEBUG	Ngram handler ==>> unigram:['postpaid'] == bigram:[] == trigram:[]
2019-03-14 15:15:38	DEBUG	Punctuation handler ==>> text to process:process
2019-03-14 15:15:38	DEBUG	Tokenization handler ==>> takens:['process'] and tokenize_without_stop_words:[]
2019-03-14 15:15:38	DEBUG	Stemmer handler ==>> stem_tokens:['process'] and stem_without_stop_words:[]
2019-03-14 15:15:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:15:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:15:38	DEBUG	Ngram handler ==>> unigram:['process'] == bigram:[] == trigram:[]
2019-03-14 15:15:38	DEBUG	Punctuation handler ==>> text to process:process
2019-03-14 15:15:38	DEBUG	Tokenization handler ==>> takens:['process'] and tokenize_without_stop_words:[]
2019-03-14 15:15:38	DEBUG	Stemmer handler ==>> stem_tokens:['process'] and stem_without_stop_words:[]
2019-03-14 15:15:38	DEBUG	lemmatization handler ==>> lemma_tokens:['process'] and lemma_without_stop_words:[]
2019-03-14 15:15:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:15:38	DEBUG	Ngram handler ==>> unigram:['process'] == bigram:[] == trigram:[]
2019-03-14 15:15:45	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-03-14 15:15:45	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-03-14 15:15:45	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-03-14 15:15:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:15:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:15:45	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-03-14 15:15:45	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 15:15:45	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 15:15:45	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 15:15:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:15:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:15:45	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 15:15:45	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-14 15:15:45	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-14 15:15:45	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-14 15:15:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:15:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:15:45	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-14 15:15:45	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-14 15:15:45	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-14 15:15:45	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-14 15:15:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:15:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:15:45	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-14 15:15:45	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-14 15:15:45	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-14 15:15:45	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-14 15:15:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:15:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:15:45	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-14 15:15:45	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-03-14 15:15:45	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-03-14 15:15:45	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-03-14 15:15:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:15:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:15:45	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-03-14 15:16:17	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-03-14 15:16:17	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-03-14 15:16:17	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-03-14 15:16:17	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:16:17	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:16:17	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-03-14 15:16:17	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 15:16:17	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 15:16:17	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 15:16:17	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:16:17	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:16:17	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 15:16:17	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-14 15:16:17	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-14 15:16:17	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-14 15:16:17	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:16:17	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:16:17	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-14 15:16:17	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-14 15:16:17	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-14 15:16:17	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-14 15:16:17	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:16:17	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:16:17	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-14 15:16:17	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-14 15:16:17	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-14 15:16:17	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-14 15:16:17	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:16:17	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:16:17	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-14 15:16:17	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-03-14 15:16:17	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-03-14 15:16:17	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-03-14 15:16:17	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:16:17	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:16:17	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-03-14 15:16:44	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-14 15:16:44	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-14 15:16:44	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-14 15:16:44	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:16:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:16:44	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-14 15:16:49	DEBUG	Punctuation handler ==>> text to process:jaipur
2019-03-14 15:16:49	DEBUG	Tokenization handler ==>> takens:['jaipur'] and tokenize_without_stop_words:[]
2019-03-14 15:16:49	DEBUG	Stemmer handler ==>> stem_tokens:['jaipur'] and stem_without_stop_words:[]
2019-03-14 15:16:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:16:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:16:49	DEBUG	Ngram handler ==>> unigram:['jaipur'] == bigram:[] == trigram:[]
2019-03-14 15:16:49	DEBUG	Punctuation handler ==>> text to process:jaipur
2019-03-14 15:16:49	DEBUG	Tokenization handler ==>> takens:['jaipur'] and tokenize_without_stop_words:[]
2019-03-14 15:16:49	DEBUG	Stemmer handler ==>> stem_tokens:['jaipur'] and stem_without_stop_words:[]
2019-03-14 15:16:49	DEBUG	lemmatization handler ==>> lemma_tokens:['jaipur'] and lemma_without_stop_words:[]
2019-03-14 15:16:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:16:49	DEBUG	Ngram handler ==>> unigram:['jaipur'] == bigram:[] == trigram:[]
2019-03-14 15:16:52	DEBUG	Punctuation handler ==>> text to process:delhi
2019-03-14 15:16:52	DEBUG	Tokenization handler ==>> takens:['delhi'] and tokenize_without_stop_words:[]
2019-03-14 15:16:52	DEBUG	Stemmer handler ==>> stem_tokens:['delhi'] and stem_without_stop_words:[]
2019-03-14 15:16:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:16:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:16:52	DEBUG	Ngram handler ==>> unigram:['delhi'] == bigram:[] == trigram:[]
2019-03-14 15:16:52	DEBUG	Punctuation handler ==>> text to process:delhi
2019-03-14 15:16:52	DEBUG	Tokenization handler ==>> takens:['delhi'] and tokenize_without_stop_words:[]
2019-03-14 15:16:52	DEBUG	Stemmer handler ==>> stem_tokens:['delhi'] and stem_without_stop_words:[]
2019-03-14 15:16:52	DEBUG	lemmatization handler ==>> lemma_tokens:['delhi'] and lemma_without_stop_words:[]
2019-03-14 15:16:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:16:52	DEBUG	Ngram handler ==>> unigram:['delhi'] == bigram:[] == trigram:[]
2019-03-14 15:17:01	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-03-14 15:17:01	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-03-14 15:17:01	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-03-14 15:17:01	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:17:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:17:01	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-03-14 15:17:01	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 15:17:01	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 15:17:01	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 15:17:01	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:17:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:17:01	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 15:17:01	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-14 15:17:01	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-14 15:17:01	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-14 15:17:01	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:17:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:17:01	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-14 15:17:01	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-14 15:17:01	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-14 15:17:01	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-14 15:17:01	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:17:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:17:01	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-14 15:17:01	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-14 15:17:01	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-14 15:17:01	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-14 15:17:01	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:17:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:17:01	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-14 15:17:01	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-03-14 15:17:01	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-03-14 15:17:01	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-03-14 15:17:01	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:17:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:17:01	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-03-14 15:17:19	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-14 15:17:19	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-14 15:17:19	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-14 15:17:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:17:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:17:19	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-14 15:18:40	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-03-14 15:18:40	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-03-14 15:18:40	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-03-14 15:18:40	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:18:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:18:40	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-03-14 15:18:40	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 15:18:40	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 15:18:40	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 15:18:40	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:18:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:18:40	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 15:18:40	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-14 15:18:40	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-14 15:18:40	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-14 15:18:40	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:18:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:18:40	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-14 15:18:40	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-14 15:18:40	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-14 15:18:40	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-14 15:18:40	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:18:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:18:40	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-14 15:18:40	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-14 15:18:40	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-14 15:18:40	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-14 15:18:40	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:18:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:18:40	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-14 15:18:40	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-03-14 15:18:40	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-03-14 15:18:40	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-03-14 15:18:40	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:18:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:18:40	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-03-14 15:21:08	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-03-14 15:21:08	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-03-14 15:21:08	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-03-14 15:21:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:21:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:21:08	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-03-14 15:21:08	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 15:21:08	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 15:21:08	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 15:21:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:21:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:21:08	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 15:21:08	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-14 15:21:08	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-14 15:21:08	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-14 15:21:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:21:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:21:08	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-14 15:21:08	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-14 15:21:08	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-14 15:21:08	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-14 15:21:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:21:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:21:09	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-14 15:21:09	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-14 15:21:09	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-14 15:21:09	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-14 15:21:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:21:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:21:09	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-14 15:21:09	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-03-14 15:21:09	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-03-14 15:21:09	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-03-14 15:21:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:21:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:21:09	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-03-14 15:22:44	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-14 15:22:44	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-14 15:22:44	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-14 15:22:44	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:22:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:22:44	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-14 15:23:09	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-03-14 15:23:09	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-03-14 15:23:09	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-03-14 15:23:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:23:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:23:09	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-03-14 15:23:09	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 15:23:09	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 15:23:09	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 15:23:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:23:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:23:09	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 15:23:09	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-14 15:23:09	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-14 15:23:09	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-14 15:23:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:23:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:23:09	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-14 15:23:09	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-14 15:23:09	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-14 15:23:09	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-14 15:23:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:23:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:23:09	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-14 15:23:09	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-14 15:23:09	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-14 15:23:09	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-14 15:23:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:23:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:23:09	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-14 15:23:09	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-03-14 15:23:09	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-03-14 15:23:09	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-03-14 15:23:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:23:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:23:09	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-03-14 15:24:54	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-03-14 15:24:54	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-03-14 15:24:54	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-03-14 15:24:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:24:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:24:54	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-03-14 15:24:54	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 15:24:54	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 15:24:54	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 15:24:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:24:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:24:54	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 15:24:54	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-03-14 15:24:54	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-03-14 15:24:54	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-03-14 15:24:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:24:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:24:54	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-03-14 15:24:54	DEBUG	Punctuation handler ==>> text to process:recharge
2019-03-14 15:24:54	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-03-14 15:24:54	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-03-14 15:24:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:24:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:24:54	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-03-14 15:24:54	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-14 15:24:54	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-14 15:24:54	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-14 15:24:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:24:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:24:54	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-14 15:24:54	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-03-14 15:24:54	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-03-14 15:24:54	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-03-14 15:24:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 15:24:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 15:24:54	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-03-14 17:47:40	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-03-14 17:47:40	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-03-14 17:47:40	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-03-14 17:47:40	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 17:47:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 17:47:40	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-03-14 17:47:43	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 17:47:43	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 17:47:43	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 17:47:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 17:47:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 17:47:43	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 17:47:43	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 17:47:43	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 17:47:43	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 17:47:43	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-14 17:47:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 17:47:43	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 17:47:46	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 17:47:46	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 17:47:46	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 17:47:46	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 17:47:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 17:47:46	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 17:47:46	DEBUG	Punctuation handler ==>> text to process:90
2019-03-14 17:47:46	DEBUG	Tokenization handler ==>> takens:['90'] and tokenize_without_stop_words:[]
2019-03-14 17:47:46	DEBUG	Stemmer handler ==>> stem_tokens:['90'] and stem_without_stop_words:[]
2019-03-14 17:47:46	DEBUG	lemmatization handler ==>> lemma_tokens:['90'] and lemma_without_stop_words:[]
2019-03-14 17:47:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 17:47:46	DEBUG	Ngram handler ==>> unigram:['90'] == bigram:[] == trigram:[]
2019-03-14 17:47:51	DEBUG	Punctuation handler ==>> text to process:prepaid
2019-03-14 17:47:51	DEBUG	Tokenization handler ==>> takens:['prepaid'] and tokenize_without_stop_words:[]
2019-03-14 17:47:51	DEBUG	Stemmer handler ==>> stem_tokens:['prepaid'] and stem_without_stop_words:[]
2019-03-14 17:47:51	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 17:47:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 17:47:51	DEBUG	Ngram handler ==>> unigram:['prepaid'] == bigram:[] == trigram:[]
2019-03-14 17:47:51	DEBUG	Punctuation handler ==>> text to process:prepaid
2019-03-14 17:47:51	DEBUG	Tokenization handler ==>> takens:['prepaid'] and tokenize_without_stop_words:[]
2019-03-14 17:47:51	DEBUG	Stemmer handler ==>> stem_tokens:['prepaid'] and stem_without_stop_words:[]
2019-03-14 17:47:51	DEBUG	lemmatization handler ==>> lemma_tokens:['prepaid'] and lemma_without_stop_words:[]
2019-03-14 17:47:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 17:47:51	DEBUG	Ngram handler ==>> unigram:['prepaid'] == bigram:[] == trigram:[]
2019-03-14 17:48:01	DEBUG	Punctuation handler ==>> text to process:process
2019-03-14 17:48:01	DEBUG	Tokenization handler ==>> takens:['process'] and tokenize_without_stop_words:[]
2019-03-14 17:48:01	DEBUG	Stemmer handler ==>> stem_tokens:['process'] and stem_without_stop_words:[]
2019-03-14 17:48:01	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 17:48:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 17:48:01	DEBUG	Ngram handler ==>> unigram:['process'] == bigram:[] == trigram:[]
2019-03-14 17:48:01	DEBUG	Punctuation handler ==>> text to process:process
2019-03-14 17:48:01	DEBUG	Tokenization handler ==>> takens:['process'] and tokenize_without_stop_words:[]
2019-03-14 17:48:01	DEBUG	Stemmer handler ==>> stem_tokens:['process'] and stem_without_stop_words:[]
2019-03-14 17:48:01	DEBUG	lemmatization handler ==>> lemma_tokens:['process'] and lemma_without_stop_words:[]
2019-03-14 17:48:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 17:48:01	DEBUG	Ngram handler ==>> unigram:['process'] == bigram:[] == trigram:[]
2019-03-14 17:48:43	DEBUG	Punctuation handler ==>> text to process:travel
2019-03-14 17:48:43	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-03-14 17:48:43	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-03-14 17:48:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 17:48:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 17:48:43	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-03-14 17:48:47	DEBUG	Punctuation handler ==>> text to process:jaipur
2019-03-14 17:48:47	DEBUG	Tokenization handler ==>> takens:['jaipur'] and tokenize_without_stop_words:[]
2019-03-14 17:48:47	DEBUG	Stemmer handler ==>> stem_tokens:['jaipur'] and stem_without_stop_words:[]
2019-03-14 17:48:47	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 17:48:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 17:48:47	DEBUG	Ngram handler ==>> unigram:['jaipur'] == bigram:[] == trigram:[]
2019-03-14 17:48:47	DEBUG	Punctuation handler ==>> text to process:jaipur
2019-03-14 17:48:47	DEBUG	Tokenization handler ==>> takens:['jaipur'] and tokenize_without_stop_words:[]
2019-03-14 17:48:47	DEBUG	Stemmer handler ==>> stem_tokens:['jaipur'] and stem_without_stop_words:[]
2019-03-14 17:48:47	DEBUG	lemmatization handler ==>> lemma_tokens:['jaipur'] and lemma_without_stop_words:[]
2019-03-14 17:48:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 17:48:47	DEBUG	Ngram handler ==>> unigram:['jaipur'] == bigram:[] == trigram:[]
2019-03-14 17:48:51	DEBUG	Punctuation handler ==>> text to process:delhi
2019-03-14 17:48:51	DEBUG	Tokenization handler ==>> takens:['delhi'] and tokenize_without_stop_words:[]
2019-03-14 17:48:51	DEBUG	Stemmer handler ==>> stem_tokens:['delhi'] and stem_without_stop_words:[]
2019-03-14 17:48:51	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-03-14 17:48:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 17:48:51	DEBUG	Ngram handler ==>> unigram:['delhi'] == bigram:[] == trigram:[]
2019-03-14 17:48:51	DEBUG	Punctuation handler ==>> text to process:delhi
2019-03-14 17:48:51	DEBUG	Tokenization handler ==>> takens:['delhi'] and tokenize_without_stop_words:[]
2019-03-14 17:48:51	DEBUG	Stemmer handler ==>> stem_tokens:['delhi'] and stem_without_stop_words:[]
2019-03-14 17:48:51	DEBUG	lemmatization handler ==>> lemma_tokens:['delhi'] and lemma_without_stop_words:[]
2019-03-14 17:48:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-03-14 17:48:51	DEBUG	Ngram handler ==>> unigram:['delhi'] == bigram:[] == trigram:[]
2019-04-04 14:41:36	DEBUG	Punctuation handler ==>> text to process:hi
2019-04-04 14:41:36	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-04-04 14:41:36	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-04-04 14:41:49	DEBUG	lemmatization handler ==>> lemma_tokens:['hi'] and lemma_without_stop_words:[]
2019-04-04 14:41:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 14:41:49	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-04-04 14:45:34	DEBUG	Punctuation handler ==>> text to process:hi
2019-04-04 14:45:34	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-04-04 14:45:34	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-04-04 14:45:34	DEBUG	lemmatization handler ==>> lemma_tokens:['hi'] and lemma_without_stop_words:[]
2019-04-04 14:45:34	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 14:45:34	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-04-04 15:46:18	DEBUG	Punctuation handler ==>> text to process:hello
2019-04-04 15:46:18	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-04-04 15:46:18	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-04-04 15:46:20	DEBUG	lemmatization handler ==>> lemma_tokens:['hello'] and lemma_without_stop_words:[]
2019-04-04 15:46:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 15:46:20	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-04-04 15:46:20	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-04 15:46:20	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-04 15:46:20	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-04 15:46:20	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-04 15:46:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 15:46:20	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-04 15:46:20	DEBUG	Punctuation handler ==>> text to process:good evening
2019-04-04 15:46:20	DEBUG	Tokenization handler ==>> takens:['good', 'evening'] and tokenize_without_stop_words:[]
2019-04-04 15:46:20	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'even'] and stem_without_stop_words:[]
2019-04-04 15:46:20	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'evening'] and lemma_without_stop_words:[]
2019-04-04 15:46:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 15:46:20	DEBUG	Ngram handler ==>> unigram:['good', 'evening'] == bigram:['good evening'] == trigram:[]
2019-04-04 15:46:20	DEBUG	Punctuation handler ==>> text to process:good morning
2019-04-04 15:46:20	DEBUG	Tokenization handler ==>> takens:['good', 'morning'] and tokenize_without_stop_words:[]
2019-04-04 15:46:20	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'morn'] and stem_without_stop_words:[]
2019-04-04 15:46:20	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'morning'] and lemma_without_stop_words:[]
2019-04-04 15:46:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 15:46:20	DEBUG	Ngram handler ==>> unigram:['good', 'morning'] == bigram:['good morning'] == trigram:[]
2019-04-04 15:50:18	DEBUG	Punctuation handler ==>> text to process:hello
2019-04-04 15:50:18	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-04-04 15:50:18	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-04-04 15:50:20	DEBUG	lemmatization handler ==>> lemma_tokens:['hello'] and lemma_without_stop_words:[]
2019-04-04 15:50:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 15:50:20	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-04-04 15:50:20	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-04 15:50:20	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-04 15:50:20	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-04 15:50:20	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-04 15:50:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 15:50:20	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-04 15:50:20	DEBUG	Punctuation handler ==>> text to process:good evening
2019-04-04 15:50:20	DEBUG	Tokenization handler ==>> takens:['good', 'evening'] and tokenize_without_stop_words:[]
2019-04-04 15:50:20	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'even'] and stem_without_stop_words:[]
2019-04-04 15:50:20	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'evening'] and lemma_without_stop_words:[]
2019-04-04 15:50:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 15:50:20	DEBUG	Ngram handler ==>> unigram:['good', 'evening'] == bigram:['good evening'] == trigram:[]
2019-04-04 15:50:20	DEBUG	Punctuation handler ==>> text to process:good morning
2019-04-04 15:50:20	DEBUG	Tokenization handler ==>> takens:['good', 'morning'] and tokenize_without_stop_words:[]
2019-04-04 15:50:20	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'morn'] and stem_without_stop_words:[]
2019-04-04 15:50:20	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'morning'] and lemma_without_stop_words:[]
2019-04-04 15:50:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 15:50:20	DEBUG	Ngram handler ==>> unigram:['good', 'morning'] == bigram:['good morning'] == trigram:[]
2019-04-04 15:51:00	DEBUG	Punctuation handler ==>> text to process:hello
2019-04-04 15:51:00	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-04-04 15:51:00	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-04-04 15:51:02	DEBUG	lemmatization handler ==>> lemma_tokens:['hello'] and lemma_without_stop_words:[]
2019-04-04 15:51:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 15:51:02	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-04-04 15:51:02	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-04 15:51:02	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-04 15:51:02	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-04 15:51:02	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-04 15:51:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 15:51:02	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-04 15:51:02	DEBUG	Punctuation handler ==>> text to process:good evening
2019-04-04 15:51:02	DEBUG	Tokenization handler ==>> takens:['good', 'evening'] and tokenize_without_stop_words:[]
2019-04-04 15:51:02	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'even'] and stem_without_stop_words:[]
2019-04-04 15:51:02	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'evening'] and lemma_without_stop_words:[]
2019-04-04 15:51:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 15:51:02	DEBUG	Ngram handler ==>> unigram:['good', 'evening'] == bigram:['good evening'] == trigram:[]
2019-04-04 15:51:02	DEBUG	Punctuation handler ==>> text to process:good morning
2019-04-04 15:51:02	DEBUG	Tokenization handler ==>> takens:['good', 'morning'] and tokenize_without_stop_words:[]
2019-04-04 15:51:02	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'morn'] and stem_without_stop_words:[]
2019-04-04 15:51:02	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'morning'] and lemma_without_stop_words:[]
2019-04-04 15:51:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 15:51:02	DEBUG	Ngram handler ==>> unigram:['good', 'morning'] == bigram:['good morning'] == trigram:[]
2019-04-04 16:03:53	DEBUG	Punctuation handler ==>> text to process:hello
2019-04-04 16:03:53	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-04-04 16:03:53	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-04-04 16:03:55	DEBUG	lemmatization handler ==>> lemma_tokens:['hello'] and lemma_without_stop_words:[]
2019-04-04 16:03:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:03:55	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-04-04 16:03:55	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-04 16:03:55	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-04 16:03:55	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-04 16:03:55	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-04 16:03:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:03:55	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-04 16:03:55	DEBUG	Punctuation handler ==>> text to process:can you tell me how are you
2019-04-04 16:03:55	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'tell', 'me', 'how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-04 16:03:55	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'tell', 'me', 'how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-04 16:03:55	DEBUG	lemmatization handler ==>> lemma_tokens:['can', 'you', 'tell', 'me', 'how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-04 16:03:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:03:55	DEBUG	Ngram handler ==>> unigram:['can', 'you', 'tell', 'me', 'how', 'are', 'you'] == bigram:['can you', 'you tell', 'tell me', 'me how', 'how are', 'are you'] == trigram:['can you tell', 'you tell me', 'tell me how', 'me how are', 'how are you']
2019-04-04 16:03:55	DEBUG	Punctuation handler ==>> text to process:good evening
2019-04-04 16:03:55	DEBUG	Tokenization handler ==>> takens:['good', 'evening'] and tokenize_without_stop_words:[]
2019-04-04 16:03:55	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'even'] and stem_without_stop_words:[]
2019-04-04 16:03:55	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'evening'] and lemma_without_stop_words:[]
2019-04-04 16:03:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:03:55	DEBUG	Ngram handler ==>> unigram:['good', 'evening'] == bigram:['good evening'] == trigram:[]
2019-04-04 16:03:55	DEBUG	Punctuation handler ==>> text to process:good morning
2019-04-04 16:03:55	DEBUG	Tokenization handler ==>> takens:['good', 'morning'] and tokenize_without_stop_words:[]
2019-04-04 16:03:55	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'morn'] and stem_without_stop_words:[]
2019-04-04 16:03:55	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'morning'] and lemma_without_stop_words:[]
2019-04-04 16:03:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:03:55	DEBUG	Ngram handler ==>> unigram:['good', 'morning'] == bigram:['good morning'] == trigram:[]
2019-04-04 16:08:24	DEBUG	Punctuation handler ==>> text to process:hi
2019-04-04 16:08:24	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-04-04 16:08:24	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-04-04 16:08:28	DEBUG	lemmatization handler ==>> lemma_tokens:['hi'] and lemma_without_stop_words:[]
2019-04-04 16:08:28	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:08:28	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-04-04 16:08:58	DEBUG	Punctuation handler ==>> text to process:hi
2019-04-04 16:08:58	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-04-04 16:08:58	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-04-04 16:09:02	DEBUG	lemmatization handler ==>> lemma_tokens:['hi'] and lemma_without_stop_words:[]
2019-04-04 16:09:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:09:02	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-04-04 16:09:35	DEBUG	Punctuation handler ==>> text to process:hi
2019-04-04 16:09:35	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-04-04 16:09:35	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-04-04 16:09:38	DEBUG	lemmatization handler ==>> lemma_tokens:['hi'] and lemma_without_stop_words:[]
2019-04-04 16:09:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:09:38	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-04-04 16:10:14	DEBUG	Punctuation handler ==>> text to process:hi
2019-04-04 16:10:15	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-04-04 16:10:15	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-04-04 16:10:18	DEBUG	lemmatization handler ==>> lemma_tokens:['hi'] and lemma_without_stop_words:[]
2019-04-04 16:10:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:10:18	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-04-04 16:10:54	DEBUG	Punctuation handler ==>> text to process:hi
2019-04-04 16:10:54	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-04-04 16:10:54	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-04-04 16:11:09	DEBUG	lemmatization handler ==>> lemma_tokens:['hi'] and lemma_without_stop_words:[]
2019-04-04 16:11:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:11:09	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-04-04 16:12:39	DEBUG	Punctuation handler ==>> text to process:hi
2019-04-04 16:12:39	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-04-04 16:12:39	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-04-04 16:12:43	DEBUG	lemmatization handler ==>> lemma_tokens:['hi'] and lemma_without_stop_words:[]
2019-04-04 16:12:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:12:43	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-04-04 16:13:29	DEBUG	Punctuation handler ==>> text to process:hi
2019-04-04 16:13:29	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-04-04 16:13:29	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-04-04 16:13:33	DEBUG	lemmatization handler ==>> lemma_tokens:['hi'] and lemma_without_stop_words:[]
2019-04-04 16:13:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:13:33	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-04-04 16:15:30	DEBUG	Punctuation handler ==>> text to process:hi
2019-04-04 16:15:30	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-04-04 16:15:30	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-04-04 16:15:34	DEBUG	lemmatization handler ==>> lemma_tokens:['hi'] and lemma_without_stop_words:[]
2019-04-04 16:15:34	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:15:34	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-04-04 16:16:17	DEBUG	Punctuation handler ==>> text to process:hi
2019-04-04 16:16:17	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-04-04 16:16:17	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-04-04 16:16:20	DEBUG	lemmatization handler ==>> lemma_tokens:['hi'] and lemma_without_stop_words:[]
2019-04-04 16:16:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:16:20	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-04-04 16:17:02	DEBUG	Punctuation handler ==>> text to process:hi
2019-04-04 16:17:02	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-04-04 16:17:02	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-04-04 16:17:07	DEBUG	lemmatization handler ==>> lemma_tokens:['hi'] and lemma_without_stop_words:[]
2019-04-04 16:17:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:17:07	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-04-04 16:17:41	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-04 16:17:41	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-04 16:17:41	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-04 16:17:45	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-04 16:17:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:17:45	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-04 16:19:06	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-04 16:19:06	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-04 16:19:06	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-04 16:19:10	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-04 16:19:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:19:10	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-04 16:20:07	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-04 16:20:07	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-04 16:20:07	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-04 16:20:11	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-04 16:20:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:20:11	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-04 16:20:34	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-04 16:20:34	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-04 16:20:34	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-04 16:20:37	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-04 16:20:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:20:37	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-04 16:21:05	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-04 16:21:05	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-04 16:21:05	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-04 16:21:05	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-04 16:21:05	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:21:05	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-04 16:21:07	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-04 16:21:07	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-04 16:21:07	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-04 16:21:07	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-04 16:21:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:21:07	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-04 16:21:13	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-04 16:21:13	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-04 16:21:13	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-04 16:21:13	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-04 16:21:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:21:13	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-04 16:21:14	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-04 16:21:14	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-04 16:21:14	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-04 16:21:14	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-04 16:21:14	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:21:14	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-04 16:21:15	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-04 16:21:15	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-04 16:21:15	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-04 16:21:15	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-04 16:21:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:21:15	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-04 16:21:15	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-04 16:21:15	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-04 16:21:15	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-04 16:21:15	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-04 16:21:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:21:15	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-04 16:21:16	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-04 16:21:16	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-04 16:21:16	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-04 16:21:16	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-04 16:21:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:21:16	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-04 16:21:16	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-04 16:21:16	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-04 16:21:16	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-04 16:21:16	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-04 16:21:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:21:16	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-04 16:21:16	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-04 16:21:16	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-04 16:21:16	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-04 16:21:16	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-04 16:21:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:21:16	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-04 16:21:17	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-04 16:21:17	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-04 16:21:17	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-04 16:21:17	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-04 16:21:17	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:21:17	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-04 16:21:17	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-04 16:21:17	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-04 16:21:17	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-04 16:21:17	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-04 16:21:17	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:21:17	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-04 16:21:36	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-04 16:21:36	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-04 16:21:36	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-04 16:21:40	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-04 16:21:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:21:40	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-04 16:21:43	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-04 16:21:43	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-04 16:21:43	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-04 16:21:43	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-04 16:21:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:21:43	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-04 16:21:44	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-04 16:21:44	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-04 16:21:44	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-04 16:21:44	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-04 16:21:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:21:44	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-04 16:21:45	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-04 16:21:45	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-04 16:21:45	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-04 16:21:45	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-04 16:21:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:21:45	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-04 16:21:46	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-04 16:21:46	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-04 16:21:46	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-04 16:21:46	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-04 16:21:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:21:46	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-04 16:21:46	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-04 16:21:46	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-04 16:21:46	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-04 16:21:46	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-04 16:21:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:21:46	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-04 16:21:46	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-04 16:21:46	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-04 16:21:46	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-04 16:21:46	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-04 16:21:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:21:46	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-04 16:21:47	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-04 16:21:47	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-04 16:21:47	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-04 16:21:47	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-04 16:21:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:21:47	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-04 16:21:48	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-04 16:21:48	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-04 16:21:48	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-04 16:21:48	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-04 16:21:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:21:48	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-04 16:21:48	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-04 16:21:48	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-04 16:21:48	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-04 16:21:48	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-04 16:21:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:21:48	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-04 16:22:53	DEBUG	Punctuation handler ==>> text to process:hi
2019-04-04 16:22:53	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-04-04 16:22:53	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-04-04 16:22:53	DEBUG	lemmatization handler ==>> lemma_tokens:['hi'] and lemma_without_stop_words:[]
2019-04-04 16:22:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:22:53	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-04-04 16:25:16	DEBUG	Punctuation handler ==>> text to process:hi
2019-04-04 16:25:16	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-04-04 16:25:16	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-04-04 16:25:16	DEBUG	lemmatization handler ==>> lemma_tokens:['hi'] and lemma_without_stop_words:[]
2019-04-04 16:25:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:25:16	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-04-04 16:25:20	DEBUG	Punctuation handler ==>> text to process:hi
2019-04-04 16:25:20	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-04-04 16:25:20	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-04-04 16:25:20	DEBUG	lemmatization handler ==>> lemma_tokens:['hi'] and lemma_without_stop_words:[]
2019-04-04 16:25:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 16:25:20	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-04-04 17:00:38	DEBUG	Punctuation handler ==>> text to process:hi
2019-04-04 17:00:38	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-04-04 17:00:38	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-04-04 17:00:42	DEBUG	lemmatization handler ==>> lemma_tokens:['hi'] and lemma_without_stop_words:[]
2019-04-04 17:00:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-04 17:00:42	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-04-09 10:22:48	DEBUG	Punctuation handler ==>> text to process:whats your name ok data last test
2019-04-09 10:22:48	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] and tokenize_without_stop_words:[]
2019-04-09 10:22:48	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', 'ok', 'data', 'last', 'test'] and stem_without_stop_words:[]
2019-04-09 10:22:50	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] and lemma_without_stop_words:[]
2019-04-09 10:22:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:22:50	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] == bigram:['whats your', 'your name', 'name ok', 'ok data', 'data last', 'last test'] == trigram:['whats your name', 'your name ok', 'name ok data', 'ok data last', 'data last test']
2019-04-09 10:22:50	DEBUG	Punctuation handler ==>> text to process:what can i call you
2019-04-09 10:22:50	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 10:22:50	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 10:22:50	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 10:22:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:22:50	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you'] == bigram:['what can', 'can i', 'i call', 'call you'] == trigram:['what can i', 'can i call', 'i call you']
2019-04-09 10:22:50	DEBUG	Punctuation handler ==>> text to process:may i know what your name is
2019-04-09 10:22:50	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and tokenize_without_stop_words:[]
2019-04-09 10:22:50	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and stem_without_stop_words:[]
2019-04-09 10:22:50	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and lemma_without_stop_words:[]
2019-04-09 10:22:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:22:50	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is']
2019-04-09 10:22:50	DEBUG	Punctuation handler ==>> text to process:how can i call you
2019-04-09 10:22:50	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 10:22:50	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 10:22:50	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 10:22:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:22:50	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you'] == bigram:['how can', 'can i', 'i call', 'call you'] == trigram:['how can i', 'can i call', 'i call you']
2019-04-09 10:22:50	DEBUG	Punctuation handler ==>> text to process:what is your good name
2019-04-09 10:22:50	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name'] and tokenize_without_stop_words:[]
2019-04-09 10:22:50	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name'] and stem_without_stop_words:[]
2019-04-09 10:22:50	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name'] and lemma_without_stop_words:[]
2019-04-09 10:22:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:22:50	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name'] == bigram:['what is', 'is your', 'your good', 'good name'] == trigram:['what is your', 'is your good', 'your good name']
2019-04-09 10:22:50	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called
2019-04-09 10:22:50	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and tokenize_without_stop_words:[]
2019-04-09 10:22:50	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call'] and stem_without_stop_words:[]
2019-04-09 10:22:50	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and lemma_without_stop_words:[]
2019-04-09 10:22:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:22:50	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called']
2019-04-09 10:24:05	DEBUG	Punctuation handler ==>> text to process:whats your name ok data last test
2019-04-09 10:24:05	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] and tokenize_without_stop_words:[]
2019-04-09 10:24:05	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', 'ok', 'data', 'last', 'test'] and stem_without_stop_words:[]
2019-04-09 10:24:09	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] and lemma_without_stop_words:[]
2019-04-09 10:24:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:24:09	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] == bigram:['whats your', 'your name', 'name ok', 'ok data', 'data last', 'last test'] == trigram:['whats your name', 'your name ok', 'name ok data', 'ok data last', 'data last test']
2019-04-09 10:24:09	DEBUG	Punctuation handler ==>> text to process:what can i call you
2019-04-09 10:24:09	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 10:24:09	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 10:24:09	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 10:24:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:24:09	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you'] == bigram:['what can', 'can i', 'i call', 'call you'] == trigram:['what can i', 'can i call', 'i call you']
2019-04-09 10:24:09	DEBUG	Punctuation handler ==>> text to process:may i know what your name is
2019-04-09 10:24:09	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and tokenize_without_stop_words:[]
2019-04-09 10:24:09	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and stem_without_stop_words:[]
2019-04-09 10:24:09	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and lemma_without_stop_words:[]
2019-04-09 10:24:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:24:09	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is']
2019-04-09 10:24:09	DEBUG	Punctuation handler ==>> text to process:how can i call you
2019-04-09 10:24:09	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 10:24:09	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 10:24:09	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 10:24:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:24:09	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you'] == bigram:['how can', 'can i', 'i call', 'call you'] == trigram:['how can i', 'can i call', 'i call you']
2019-04-09 10:24:09	DEBUG	Punctuation handler ==>> text to process:what is your good name
2019-04-09 10:24:09	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name'] and tokenize_without_stop_words:[]
2019-04-09 10:24:09	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name'] and stem_without_stop_words:[]
2019-04-09 10:24:09	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name'] and lemma_without_stop_words:[]
2019-04-09 10:24:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:24:09	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name'] == bigram:['what is', 'is your', 'your good', 'good name'] == trigram:['what is your', 'is your good', 'your good name']
2019-04-09 10:24:09	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called
2019-04-09 10:24:09	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and tokenize_without_stop_words:[]
2019-04-09 10:24:09	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call'] and stem_without_stop_words:[]
2019-04-09 10:24:09	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and lemma_without_stop_words:[]
2019-04-09 10:24:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:24:09	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called']
2019-04-09 10:25:14	DEBUG	Punctuation handler ==>> text to process:whats your name ok data last test
2019-04-09 10:25:14	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] and tokenize_without_stop_words:[]
2019-04-09 10:25:14	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', 'ok', 'data', 'last', 'test'] and stem_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] and lemma_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:25:16	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] == bigram:['whats your', 'your name', 'name ok', 'ok data', 'data last', 'last test'] == trigram:['whats your name', 'your name ok', 'name ok data', 'ok data last', 'data last test']
2019-04-09 10:25:16	DEBUG	Punctuation handler ==>> text to process:what can i call you
2019-04-09 10:25:16	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:25:16	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you'] == bigram:['what can', 'can i', 'i call', 'call you'] == trigram:['what can i', 'can i call', 'i call you']
2019-04-09 10:25:16	DEBUG	Punctuation handler ==>> text to process:may i know what your name is
2019-04-09 10:25:16	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and tokenize_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and stem_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and lemma_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:25:16	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is']
2019-04-09 10:25:16	DEBUG	Punctuation handler ==>> text to process:how can i call you
2019-04-09 10:25:16	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:25:16	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you'] == bigram:['how can', 'can i', 'i call', 'call you'] == trigram:['how can i', 'can i call', 'i call you']
2019-04-09 10:25:16	DEBUG	Punctuation handler ==>> text to process:what is your good name
2019-04-09 10:25:16	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name'] and tokenize_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name'] and stem_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name'] and lemma_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:25:16	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name'] == bigram:['what is', 'is your', 'your good', 'good name'] == trigram:['what is your', 'is your good', 'your good name']
2019-04-09 10:25:16	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called
2019-04-09 10:25:16	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and tokenize_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call'] and stem_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and lemma_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:25:16	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called']
2019-04-09 10:25:16	DEBUG	Punctuation handler ==>> text to process:what is the purpose of life
2019-04-09 10:25:16	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:25:16	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:25:16	DEBUG	Punctuation handler ==>> text to process:can you please tell what is the purpose of life
2019-04-09 10:25:16	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'please', 'tell', 'what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'pleas', 'tell', 'what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	lemmatization handler ==>> lemma_tokens:['can', 'you', 'please', 'tell', 'what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:25:16	DEBUG	Ngram handler ==>> unigram:['can', 'you', 'please', 'tell', 'what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['can you', 'you please', 'please tell', 'tell what', 'what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['can you please', 'you please tell', 'please tell what', 'tell what is', 'what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:25:16	DEBUG	Punctuation handler ==>> text to process:what do you think is the purpose of life
2019-04-09 10:25:16	DEBUG	Tokenization handler ==>> takens:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'do', 'you', 'think', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:25:16	DEBUG	Ngram handler ==>> unigram:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['what do', 'do you', 'you think', 'think is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['what do you', 'do you think', 'you think is', 'think is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:25:16	DEBUG	Punctuation handler ==>> text to process:please tell me what is the purpose of life
2019-04-09 10:25:16	DEBUG	Tokenization handler ==>> takens:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	Stemmer handler ==>> stem_tokens:['pleas', 'tell', 'me', 'what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	lemmatization handler ==>> lemma_tokens:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:25:16	DEBUG	Ngram handler ==>> unigram:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['please tell', 'tell me', 'me what', 'what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['please tell me', 'tell me what', 'me what is', 'what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:25:16	DEBUG	Punctuation handler ==>> text to process:will you please tell me what is the purpose of life
2019-04-09 10:25:16	DEBUG	Tokenization handler ==>> takens:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	Stemmer handler ==>> stem_tokens:['will', 'you', 'pleas', 'tell', 'me', 'what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	lemmatization handler ==>> lemma_tokens:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:25:16	DEBUG	Ngram handler ==>> unigram:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['will you', 'you please', 'please tell', 'tell me', 'me what', 'what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['will you please', 'you please tell', 'please tell me', 'tell me what', 'me what is', 'what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:25:16	DEBUG	Punctuation handler ==>> text to process:living
2019-04-09 10:25:16	DEBUG	Tokenization handler ==>> takens:['living'] and tokenize_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	Stemmer handler ==>> stem_tokens:['live'] and stem_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	lemmatization handler ==>> lemma_tokens:['living'] and lemma_without_stop_words:[]
2019-04-09 10:25:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:25:16	DEBUG	Ngram handler ==>> unigram:['living'] == bigram:[] == trigram:[]
2019-04-09 10:26:08	DEBUG	Punctuation handler ==>> text to process:whats your name ok data last test
2019-04-09 10:26:08	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] and tokenize_without_stop_words:[]
2019-04-09 10:26:08	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', 'ok', 'data', 'last', 'test'] and stem_without_stop_words:[]
2019-04-09 10:26:10	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] and lemma_without_stop_words:[]
2019-04-09 10:26:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:26:10	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] == bigram:['whats your', 'your name', 'name ok', 'ok data', 'data last', 'last test'] == trigram:['whats your name', 'your name ok', 'name ok data', 'ok data last', 'data last test']
2019-04-09 10:26:10	DEBUG	Punctuation handler ==>> text to process:what can i call you
2019-04-09 10:26:10	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 10:26:10	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 10:26:10	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 10:26:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:26:10	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you'] == bigram:['what can', 'can i', 'i call', 'call you'] == trigram:['what can i', 'can i call', 'i call you']
2019-04-09 10:26:10	DEBUG	Punctuation handler ==>> text to process:may i know what your name is
2019-04-09 10:26:10	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and tokenize_without_stop_words:[]
2019-04-09 10:26:10	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and stem_without_stop_words:[]
2019-04-09 10:26:10	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and lemma_without_stop_words:[]
2019-04-09 10:26:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:26:10	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is']
2019-04-09 10:26:10	DEBUG	Punctuation handler ==>> text to process:how can i call you
2019-04-09 10:26:10	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 10:26:10	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 10:26:10	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 10:26:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:26:10	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you'] == bigram:['how can', 'can i', 'i call', 'call you'] == trigram:['how can i', 'can i call', 'i call you']
2019-04-09 10:26:10	DEBUG	Punctuation handler ==>> text to process:what is your good name
2019-04-09 10:26:10	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name'] and tokenize_without_stop_words:[]
2019-04-09 10:26:10	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name'] and stem_without_stop_words:[]
2019-04-09 10:26:10	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name'] and lemma_without_stop_words:[]
2019-04-09 10:26:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:26:10	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name'] == bigram:['what is', 'is your', 'your good', 'good name'] == trigram:['what is your', 'is your good', 'your good name']
2019-04-09 10:26:10	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called
2019-04-09 10:26:10	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and tokenize_without_stop_words:[]
2019-04-09 10:26:10	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call'] and stem_without_stop_words:[]
2019-04-09 10:26:10	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and lemma_without_stop_words:[]
2019-04-09 10:26:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:26:10	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called']
2019-04-09 10:31:02	DEBUG	Punctuation handler ==>> text to process:whats your name ok data last test
2019-04-09 10:31:03	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] and tokenize_without_stop_words:[]
2019-04-09 10:31:03	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', 'ok', 'data', 'last', 'test'] and stem_without_stop_words:[]
2019-04-09 10:31:05	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] and lemma_without_stop_words:[]
2019-04-09 10:31:05	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:31:05	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] == bigram:['whats your', 'your name', 'name ok', 'ok data', 'data last', 'last test'] == trigram:['whats your name', 'your name ok', 'name ok data', 'ok data last', 'data last test']
2019-04-09 10:31:05	DEBUG	Punctuation handler ==>> text to process:what can i call you
2019-04-09 10:31:05	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 10:31:05	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 10:31:05	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 10:31:05	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:31:05	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you'] == bigram:['what can', 'can i', 'i call', 'call you'] == trigram:['what can i', 'can i call', 'i call you']
2019-04-09 10:31:05	DEBUG	Punctuation handler ==>> text to process:may i know what your name is
2019-04-09 10:31:05	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and tokenize_without_stop_words:[]
2019-04-09 10:31:05	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and stem_without_stop_words:[]
2019-04-09 10:31:05	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and lemma_without_stop_words:[]
2019-04-09 10:31:05	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:31:05	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is']
2019-04-09 10:31:05	DEBUG	Punctuation handler ==>> text to process:how can i call you
2019-04-09 10:31:05	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 10:31:05	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 10:31:05	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 10:31:05	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:31:05	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you'] == bigram:['how can', 'can i', 'i call', 'call you'] == trigram:['how can i', 'can i call', 'i call you']
2019-04-09 10:31:05	DEBUG	Punctuation handler ==>> text to process:what is your good name
2019-04-09 10:31:05	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name'] and tokenize_without_stop_words:[]
2019-04-09 10:31:05	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name'] and stem_without_stop_words:[]
2019-04-09 10:31:05	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name'] and lemma_without_stop_words:[]
2019-04-09 10:31:05	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:31:05	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name'] == bigram:['what is', 'is your', 'your good', 'good name'] == trigram:['what is your', 'is your good', 'your good name']
2019-04-09 10:31:05	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called
2019-04-09 10:31:05	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and tokenize_without_stop_words:[]
2019-04-09 10:31:05	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call'] and stem_without_stop_words:[]
2019-04-09 10:31:05	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and lemma_without_stop_words:[]
2019-04-09 10:31:05	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:31:05	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called']
2019-04-09 10:31:18	DEBUG	Punctuation handler ==>> text to process:whats your name ok data last test
2019-04-09 10:31:18	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] and tokenize_without_stop_words:[]
2019-04-09 10:31:18	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', 'ok', 'data', 'last', 'test'] and stem_without_stop_words:[]
2019-04-09 10:31:20	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] and lemma_without_stop_words:[]
2019-04-09 10:31:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:31:20	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] == bigram:['whats your', 'your name', 'name ok', 'ok data', 'data last', 'last test'] == trigram:['whats your name', 'your name ok', 'name ok data', 'ok data last', 'data last test']
2019-04-09 10:31:20	DEBUG	Punctuation handler ==>> text to process:what can i call you
2019-04-09 10:31:20	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 10:31:20	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 10:31:20	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 10:31:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:31:20	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you'] == bigram:['what can', 'can i', 'i call', 'call you'] == trigram:['what can i', 'can i call', 'i call you']
2019-04-09 10:31:20	DEBUG	Punctuation handler ==>> text to process:may i know what your name is
2019-04-09 10:31:20	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and tokenize_without_stop_words:[]
2019-04-09 10:31:20	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and stem_without_stop_words:[]
2019-04-09 10:31:20	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and lemma_without_stop_words:[]
2019-04-09 10:31:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:31:20	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is']
2019-04-09 10:31:20	DEBUG	Punctuation handler ==>> text to process:how can i call you
2019-04-09 10:31:20	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 10:31:20	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 10:31:20	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 10:31:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:31:20	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you'] == bigram:['how can', 'can i', 'i call', 'call you'] == trigram:['how can i', 'can i call', 'i call you']
2019-04-09 10:31:20	DEBUG	Punctuation handler ==>> text to process:what is your good name
2019-04-09 10:31:20	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name'] and tokenize_without_stop_words:[]
2019-04-09 10:31:20	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name'] and stem_without_stop_words:[]
2019-04-09 10:31:20	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name'] and lemma_without_stop_words:[]
2019-04-09 10:31:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:31:20	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name'] == bigram:['what is', 'is your', 'your good', 'good name'] == trigram:['what is your', 'is your good', 'your good name']
2019-04-09 10:31:20	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called
2019-04-09 10:31:20	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and tokenize_without_stop_words:[]
2019-04-09 10:31:20	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call'] and stem_without_stop_words:[]
2019-04-09 10:31:20	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and lemma_without_stop_words:[]
2019-04-09 10:31:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:31:20	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called']
2019-04-09 10:31:29	DEBUG	Punctuation handler ==>> text to process:whats your name ok data last test
2019-04-09 10:31:29	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] and tokenize_without_stop_words:[]
2019-04-09 10:31:29	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', 'ok', 'data', 'last', 'test'] and stem_without_stop_words:[]
2019-04-09 10:31:31	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] and lemma_without_stop_words:[]
2019-04-09 10:31:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:31:31	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] == bigram:['whats your', 'your name', 'name ok', 'ok data', 'data last', 'last test'] == trigram:['whats your name', 'your name ok', 'name ok data', 'ok data last', 'data last test']
2019-04-09 10:31:31	DEBUG	Punctuation handler ==>> text to process:what can i call you
2019-04-09 10:31:31	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 10:31:31	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 10:31:31	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 10:31:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:31:31	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you'] == bigram:['what can', 'can i', 'i call', 'call you'] == trigram:['what can i', 'can i call', 'i call you']
2019-04-09 10:31:31	DEBUG	Punctuation handler ==>> text to process:may i know what your name is
2019-04-09 10:31:31	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and tokenize_without_stop_words:[]
2019-04-09 10:31:31	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and stem_without_stop_words:[]
2019-04-09 10:31:31	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and lemma_without_stop_words:[]
2019-04-09 10:31:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:31:31	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is']
2019-04-09 10:31:31	DEBUG	Punctuation handler ==>> text to process:how can i call you
2019-04-09 10:31:31	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 10:31:31	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 10:31:31	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 10:31:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:31:31	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you'] == bigram:['how can', 'can i', 'i call', 'call you'] == trigram:['how can i', 'can i call', 'i call you']
2019-04-09 10:31:31	DEBUG	Punctuation handler ==>> text to process:what is your good name
2019-04-09 10:31:31	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name'] and tokenize_without_stop_words:[]
2019-04-09 10:31:31	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name'] and stem_without_stop_words:[]
2019-04-09 10:31:31	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name'] and lemma_without_stop_words:[]
2019-04-09 10:31:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:31:31	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name'] == bigram:['what is', 'is your', 'your good', 'good name'] == trigram:['what is your', 'is your good', 'your good name']
2019-04-09 10:31:31	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called
2019-04-09 10:31:31	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and tokenize_without_stop_words:[]
2019-04-09 10:31:31	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call'] and stem_without_stop_words:[]
2019-04-09 10:31:31	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and lemma_without_stop_words:[]
2019-04-09 10:31:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:31:31	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called']
2019-04-09 10:31:51	DEBUG	Punctuation handler ==>> text to process:whats your name ok data last test
2019-04-09 10:31:51	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] and tokenize_without_stop_words:[]
2019-04-09 10:31:51	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', 'ok', 'data', 'last', 'test'] and stem_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] and lemma_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:31:53	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] == bigram:['whats your', 'your name', 'name ok', 'ok data', 'data last', 'last test'] == trigram:['whats your name', 'your name ok', 'name ok data', 'ok data last', 'data last test']
2019-04-09 10:31:53	DEBUG	Punctuation handler ==>> text to process:what can i call you
2019-04-09 10:31:53	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:31:53	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you'] == bigram:['what can', 'can i', 'i call', 'call you'] == trigram:['what can i', 'can i call', 'i call you']
2019-04-09 10:31:53	DEBUG	Punctuation handler ==>> text to process:may i know what your name is
2019-04-09 10:31:53	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and tokenize_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and stem_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and lemma_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:31:53	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is']
2019-04-09 10:31:53	DEBUG	Punctuation handler ==>> text to process:how can i call you
2019-04-09 10:31:53	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:31:53	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you'] == bigram:['how can', 'can i', 'i call', 'call you'] == trigram:['how can i', 'can i call', 'i call you']
2019-04-09 10:31:53	DEBUG	Punctuation handler ==>> text to process:what is your good name
2019-04-09 10:31:53	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name'] and tokenize_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name'] and stem_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name'] and lemma_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:31:53	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name'] == bigram:['what is', 'is your', 'your good', 'good name'] == trigram:['what is your', 'is your good', 'your good name']
2019-04-09 10:31:53	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called
2019-04-09 10:31:53	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and tokenize_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call'] and stem_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and lemma_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:31:53	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called']
2019-04-09 10:31:53	DEBUG	Punctuation handler ==>> text to process:what is the purpose of life
2019-04-09 10:31:53	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:31:53	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:31:53	DEBUG	Punctuation handler ==>> text to process:can you please tell what is the purpose of life
2019-04-09 10:31:53	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'please', 'tell', 'what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'pleas', 'tell', 'what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	lemmatization handler ==>> lemma_tokens:['can', 'you', 'please', 'tell', 'what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:31:53	DEBUG	Ngram handler ==>> unigram:['can', 'you', 'please', 'tell', 'what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['can you', 'you please', 'please tell', 'tell what', 'what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['can you please', 'you please tell', 'please tell what', 'tell what is', 'what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:31:53	DEBUG	Punctuation handler ==>> text to process:what do you think is the purpose of life
2019-04-09 10:31:53	DEBUG	Tokenization handler ==>> takens:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'do', 'you', 'think', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:31:53	DEBUG	Ngram handler ==>> unigram:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['what do', 'do you', 'you think', 'think is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['what do you', 'do you think', 'you think is', 'think is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:31:53	DEBUG	Punctuation handler ==>> text to process:please tell me what is the purpose of life
2019-04-09 10:31:53	DEBUG	Tokenization handler ==>> takens:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	Stemmer handler ==>> stem_tokens:['pleas', 'tell', 'me', 'what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	lemmatization handler ==>> lemma_tokens:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:31:53	DEBUG	Ngram handler ==>> unigram:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['please tell', 'tell me', 'me what', 'what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['please tell me', 'tell me what', 'me what is', 'what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:31:53	DEBUG	Punctuation handler ==>> text to process:will you please tell me what is the purpose of life
2019-04-09 10:31:53	DEBUG	Tokenization handler ==>> takens:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	Stemmer handler ==>> stem_tokens:['will', 'you', 'pleas', 'tell', 'me', 'what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	lemmatization handler ==>> lemma_tokens:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:31:53	DEBUG	Ngram handler ==>> unigram:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['will you', 'you please', 'please tell', 'tell me', 'me what', 'what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['will you please', 'you please tell', 'please tell me', 'tell me what', 'me what is', 'what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:31:53	DEBUG	Punctuation handler ==>> text to process:living
2019-04-09 10:31:53	DEBUG	Tokenization handler ==>> takens:['living'] and tokenize_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	Stemmer handler ==>> stem_tokens:['live'] and stem_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	lemmatization handler ==>> lemma_tokens:['living'] and lemma_without_stop_words:[]
2019-04-09 10:31:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:31:53	DEBUG	Ngram handler ==>> unigram:['living'] == bigram:[] == trigram:[]
2019-04-09 10:32:17	DEBUG	Punctuation handler ==>> text to process:whats your name ok data last test
2019-04-09 10:32:17	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] and tokenize_without_stop_words:[]
2019-04-09 10:32:17	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', 'ok', 'data', 'last', 'test'] and stem_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] and lemma_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:32:19	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] == bigram:['whats your', 'your name', 'name ok', 'ok data', 'data last', 'last test'] == trigram:['whats your name', 'your name ok', 'name ok data', 'ok data last', 'data last test']
2019-04-09 10:32:19	DEBUG	Punctuation handler ==>> text to process:what can i call you
2019-04-09 10:32:19	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:32:19	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you'] == bigram:['what can', 'can i', 'i call', 'call you'] == trigram:['what can i', 'can i call', 'i call you']
2019-04-09 10:32:19	DEBUG	Punctuation handler ==>> text to process:may i know what your name is
2019-04-09 10:32:19	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and tokenize_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and stem_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and lemma_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:32:19	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is']
2019-04-09 10:32:19	DEBUG	Punctuation handler ==>> text to process:how can i call you
2019-04-09 10:32:19	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:32:19	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you'] == bigram:['how can', 'can i', 'i call', 'call you'] == trigram:['how can i', 'can i call', 'i call you']
2019-04-09 10:32:19	DEBUG	Punctuation handler ==>> text to process:what is your good name
2019-04-09 10:32:19	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name'] and tokenize_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name'] and stem_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name'] and lemma_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:32:19	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name'] == bigram:['what is', 'is your', 'your good', 'good name'] == trigram:['what is your', 'is your good', 'your good name']
2019-04-09 10:32:19	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called
2019-04-09 10:32:19	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and tokenize_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call'] and stem_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and lemma_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:32:19	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called']
2019-04-09 10:32:19	DEBUG	Punctuation handler ==>> text to process:what is the purpose of life
2019-04-09 10:32:19	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:32:19	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:32:19	DEBUG	Punctuation handler ==>> text to process:can you please tell what is the purpose of life
2019-04-09 10:32:19	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'please', 'tell', 'what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'pleas', 'tell', 'what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	lemmatization handler ==>> lemma_tokens:['can', 'you', 'please', 'tell', 'what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:32:19	DEBUG	Ngram handler ==>> unigram:['can', 'you', 'please', 'tell', 'what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['can you', 'you please', 'please tell', 'tell what', 'what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['can you please', 'you please tell', 'please tell what', 'tell what is', 'what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:32:19	DEBUG	Punctuation handler ==>> text to process:what do you think is the purpose of life
2019-04-09 10:32:19	DEBUG	Tokenization handler ==>> takens:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'do', 'you', 'think', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:32:19	DEBUG	Ngram handler ==>> unigram:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['what do', 'do you', 'you think', 'think is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['what do you', 'do you think', 'you think is', 'think is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:32:19	DEBUG	Punctuation handler ==>> text to process:please tell me what is the purpose of life
2019-04-09 10:32:19	DEBUG	Tokenization handler ==>> takens:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	Stemmer handler ==>> stem_tokens:['pleas', 'tell', 'me', 'what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	lemmatization handler ==>> lemma_tokens:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:32:19	DEBUG	Ngram handler ==>> unigram:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['please tell', 'tell me', 'me what', 'what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['please tell me', 'tell me what', 'me what is', 'what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:32:19	DEBUG	Punctuation handler ==>> text to process:will you please tell me what is the purpose of life
2019-04-09 10:32:19	DEBUG	Tokenization handler ==>> takens:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	Stemmer handler ==>> stem_tokens:['will', 'you', 'pleas', 'tell', 'me', 'what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	lemmatization handler ==>> lemma_tokens:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:32:19	DEBUG	Ngram handler ==>> unigram:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['will you', 'you please', 'please tell', 'tell me', 'me what', 'what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['will you please', 'you please tell', 'please tell me', 'tell me what', 'me what is', 'what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:32:19	DEBUG	Punctuation handler ==>> text to process:living
2019-04-09 10:32:19	DEBUG	Tokenization handler ==>> takens:['living'] and tokenize_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	Stemmer handler ==>> stem_tokens:['live'] and stem_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	lemmatization handler ==>> lemma_tokens:['living'] and lemma_without_stop_words:[]
2019-04-09 10:32:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:32:19	DEBUG	Ngram handler ==>> unigram:['living'] == bigram:[] == trigram:[]
2019-04-09 10:32:52	DEBUG	Punctuation handler ==>> text to process:the purpose of life
2019-04-09 10:32:52	DEBUG	Tokenization handler ==>> takens:['the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:32:52	DEBUG	Stemmer handler ==>> stem_tokens:['the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:32:56	DEBUG	lemmatization handler ==>> lemma_tokens:['the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:32:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:32:56	DEBUG	Ngram handler ==>> unigram:['the', 'purpose', 'of', 'life'] == bigram:['the purpose', 'purpose of', 'of life'] == trigram:['the purpose of', 'purpose of life']
2019-04-09 10:44:32	DEBUG	Punctuation handler ==>> text to process:whats your name ok data last test
2019-04-09 10:44:32	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] and tokenize_without_stop_words:[]
2019-04-09 10:44:32	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', 'ok', 'data', 'last', 'test'] and stem_without_stop_words:[]
2019-04-09 10:44:33	DEBUG	Punctuation handler ==>> text to process:whats your name ok data last test
2019-04-09 10:44:33	DEBUG	Punctuation handler ==>> text to process:whats your name ok data last test
2019-04-09 10:44:33	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] and tokenize_without_stop_words:[]
2019-04-09 10:44:33	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] and tokenize_without_stop_words:[]
2019-04-09 10:44:33	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', 'ok', 'data', 'last', 'test'] and stem_without_stop_words:[]
2019-04-09 10:44:33	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', 'ok', 'data', 'last', 'test'] and stem_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] and lemma_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:36	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] == bigram:['whats your', 'your name', 'name ok', 'ok data', 'data last', 'last test'] == trigram:['whats your name', 'your name ok', 'name ok data', 'ok data last', 'data last test']
2019-04-09 10:44:36	DEBUG	Punctuation handler ==>> text to process:what can i call you
2019-04-09 10:44:36	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:36	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you'] == bigram:['what can', 'can i', 'i call', 'call you'] == trigram:['what can i', 'can i call', 'i call you']
2019-04-09 10:44:36	DEBUG	Punctuation handler ==>> text to process:may i know what your name is
2019-04-09 10:44:36	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and tokenize_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and stem_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and lemma_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:36	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is']
2019-04-09 10:44:36	DEBUG	Punctuation handler ==>> text to process:how can i call you
2019-04-09 10:44:36	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:36	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you'] == bigram:['how can', 'can i', 'i call', 'call you'] == trigram:['how can i', 'can i call', 'i call you']
2019-04-09 10:44:36	DEBUG	Punctuation handler ==>> text to process:what is your good name
2019-04-09 10:44:36	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name'] and tokenize_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name'] and stem_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name'] and lemma_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:36	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name'] == bigram:['what is', 'is your', 'your good', 'good name'] == trigram:['what is your', 'is your good', 'your good name']
2019-04-09 10:44:36	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called
2019-04-09 10:44:36	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and tokenize_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call'] and stem_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and lemma_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:36	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called']
2019-04-09 10:44:36	DEBUG	Punctuation handler ==>> text to process:what is the purpose of life
2019-04-09 10:44:36	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:36	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:44:36	DEBUG	Punctuation handler ==>> text to process:can you please tell what is the purpose of life
2019-04-09 10:44:36	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'please', 'tell', 'what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'pleas', 'tell', 'what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	lemmatization handler ==>> lemma_tokens:['can', 'you', 'please', 'tell', 'what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:36	DEBUG	Ngram handler ==>> unigram:['can', 'you', 'please', 'tell', 'what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['can you', 'you please', 'please tell', 'tell what', 'what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['can you please', 'you please tell', 'please tell what', 'tell what is', 'what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:44:36	DEBUG	Punctuation handler ==>> text to process:what do you think is the purpose of life
2019-04-09 10:44:36	DEBUG	Tokenization handler ==>> takens:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'do', 'you', 'think', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:36	DEBUG	Ngram handler ==>> unigram:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['what do', 'do you', 'you think', 'think is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['what do you', 'do you think', 'you think is', 'think is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:44:36	DEBUG	Punctuation handler ==>> text to process:please tell me what is the purpose of life
2019-04-09 10:44:36	DEBUG	Tokenization handler ==>> takens:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	Stemmer handler ==>> stem_tokens:['pleas', 'tell', 'me', 'what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	lemmatization handler ==>> lemma_tokens:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:36	DEBUG	Ngram handler ==>> unigram:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['please tell', 'tell me', 'me what', 'what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['please tell me', 'tell me what', 'me what is', 'what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:44:36	DEBUG	Punctuation handler ==>> text to process:will you please tell me what is the purpose of life
2019-04-09 10:44:36	DEBUG	Tokenization handler ==>> takens:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	Stemmer handler ==>> stem_tokens:['will', 'you', 'pleas', 'tell', 'me', 'what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	lemmatization handler ==>> lemma_tokens:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:36	DEBUG	Ngram handler ==>> unigram:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['will you', 'you please', 'please tell', 'tell me', 'me what', 'what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['will you please', 'you please tell', 'please tell me', 'tell me what', 'me what is', 'what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:44:36	DEBUG	Punctuation handler ==>> text to process:living
2019-04-09 10:44:36	DEBUG	Tokenization handler ==>> takens:['living'] and tokenize_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	Stemmer handler ==>> stem_tokens:['live'] and stem_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	lemmatization handler ==>> lemma_tokens:['living'] and lemma_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:36	DEBUG	Ngram handler ==>> unigram:['living'] == bigram:[] == trigram:[]
2019-04-09 10:44:36	DEBUG	Punctuation handler ==>> text to process:what is the purpose of living
2019-04-09 10:44:36	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'the', 'purpose', 'of', 'living'] and tokenize_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'the', 'purpos', 'of', 'live'] and stem_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'the', 'purpose', 'of', 'living'] and lemma_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:36	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'the', 'purpose', 'of', 'living'] == bigram:['what is', 'is the', 'the purpose', 'purpose of', 'of living'] == trigram:['what is the', 'is the purpose', 'the purpose of', 'purpose of living']
2019-04-09 10:44:36	DEBUG	Punctuation handler ==>> text to process:can you please tell me the purpose of living
2019-04-09 10:44:36	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'please', 'tell', 'me', 'the', 'purpose', 'of', 'living'] and tokenize_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'pleas', 'tell', 'me', 'the', 'purpos', 'of', 'live'] and stem_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	lemmatization handler ==>> lemma_tokens:['can', 'you', 'please', 'tell', 'me', 'the', 'purpose', 'of', 'living'] and lemma_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:36	DEBUG	Ngram handler ==>> unigram:['can', 'you', 'please', 'tell', 'me', 'the', 'purpose', 'of', 'living'] == bigram:['can you', 'you please', 'please tell', 'tell me', 'me the', 'the purpose', 'purpose of', 'of living'] == trigram:['can you please', 'you please tell', 'please tell me', 'tell me the', 'me the purpose', 'the purpose of', 'purpose of living']
2019-04-09 10:44:36	DEBUG	Punctuation handler ==>> text to process:what do you think is the purpose of living
2019-04-09 10:44:36	DEBUG	Tokenization handler ==>> takens:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'living'] and tokenize_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'do', 'you', 'think', 'is', 'the', 'purpos', 'of', 'live'] and stem_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'living'] and lemma_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:36	DEBUG	Ngram handler ==>> unigram:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'living'] == bigram:['what do', 'do you', 'you think', 'think is', 'is the', 'the purpose', 'purpose of', 'of living'] == trigram:['what do you', 'do you think', 'you think is', 'think is the', 'is the purpose', 'the purpose of', 'purpose of living']
2019-04-09 10:44:36	DEBUG	Punctuation handler ==>> text to process:please tell me what is the purpose of living
2019-04-09 10:44:36	DEBUG	Tokenization handler ==>> takens:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'living'] and tokenize_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	Stemmer handler ==>> stem_tokens:['pleas', 'tell', 'me', 'what', 'is', 'the', 'purpos', 'of', 'live'] and stem_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	lemmatization handler ==>> lemma_tokens:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'living'] and lemma_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:36	DEBUG	Ngram handler ==>> unigram:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'living'] == bigram:['please tell', 'tell me', 'me what', 'what is', 'is the', 'the purpose', 'purpose of', 'of living'] == trigram:['please tell me', 'tell me what', 'me what is', 'what is the', 'is the purpose', 'the purpose of', 'purpose of living']
2019-04-09 10:44:36	DEBUG	Punctuation handler ==>> text to process:will you please tell me what is the purpose of living
2019-04-09 10:44:36	DEBUG	Tokenization handler ==>> takens:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'living'] and tokenize_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	Stemmer handler ==>> stem_tokens:['will', 'you', 'pleas', 'tell', 'me', 'what', 'is', 'the', 'purpos', 'of', 'live'] and stem_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	lemmatization handler ==>> lemma_tokens:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'living'] and lemma_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:36	DEBUG	Ngram handler ==>> unigram:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'living'] == bigram:['will you', 'you please', 'please tell', 'tell me', 'me what', 'what is', 'is the', 'the purpose', 'purpose of', 'of living'] == trigram:['will you please', 'you please tell', 'please tell me', 'tell me what', 'me what is', 'what is the', 'is the purpose', 'the purpose of', 'purpose of living']
2019-04-09 10:44:36	DEBUG	Punctuation handler ==>> text to process:tell me what is the purpsoe of living
2019-04-09 10:44:36	DEBUG	Tokenization handler ==>> takens:['tell', 'me', 'what', 'is', 'the', 'purpsoe', 'of', 'living'] and tokenize_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	Stemmer handler ==>> stem_tokens:['tell', 'me', 'what', 'is', 'the', 'purpso', 'of', 'live'] and stem_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	lemmatization handler ==>> lemma_tokens:['tell', 'me', 'what', 'is', 'the', 'purpsoe', 'of', 'living'] and lemma_without_stop_words:[]
2019-04-09 10:44:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:36	DEBUG	Ngram handler ==>> unigram:['tell', 'me', 'what', 'is', 'the', 'purpsoe', 'of', 'living'] == bigram:['tell me', 'me what', 'what is', 'is the', 'the purpsoe', 'purpsoe of', 'of living'] == trigram:['tell me what', 'me what is', 'what is the', 'is the purpsoe', 'the purpsoe of', 'purpsoe of living']
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] == bigram:['whats your', 'your name', 'name ok', 'ok data', 'data last', 'last test'] == trigram:['whats your name', 'your name ok', 'name ok data', 'ok data last', 'data last test']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:what can i call you
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you'] == bigram:['what can', 'can i', 'i call', 'call you'] == trigram:['what can i', 'can i call', 'i call you']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:may i know what your name is
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:how can i call you
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you'] == bigram:['how can', 'can i', 'i call', 'call you'] == trigram:['how can i', 'can i call', 'i call you']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:what is your good name
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name'] == bigram:['what is', 'is your', 'your good', 'good name'] == trigram:['what is your', 'is your good', 'your good name']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:what is the purpose of life
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:can you please tell what is the purpose of life
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'please', 'tell', 'what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'pleas', 'tell', 'what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['can', 'you', 'please', 'tell', 'what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['can', 'you', 'please', 'tell', 'what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['can you', 'you please', 'please tell', 'tell what', 'what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['can you please', 'you please tell', 'please tell what', 'tell what is', 'what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:what do you think is the purpose of life
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'do', 'you', 'think', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['what do', 'do you', 'you think', 'think is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['what do you', 'do you think', 'you think is', 'think is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:please tell me what is the purpose of life
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['pleas', 'tell', 'me', 'what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['please tell', 'tell me', 'me what', 'what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['please tell me', 'tell me what', 'me what is', 'what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:will you please tell me what is the purpose of life
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['will', 'you', 'pleas', 'tell', 'me', 'what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['will you', 'you please', 'please tell', 'tell me', 'me what', 'what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['will you please', 'you please tell', 'please tell me', 'tell me what', 'me what is', 'what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:living
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['living'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['live'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['living'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['living'] == bigram:[] == trigram:[]
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:what is the purpose of living
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'the', 'purpose', 'of', 'living'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'the', 'purpos', 'of', 'live'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'the', 'purpose', 'of', 'living'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'the', 'purpose', 'of', 'living'] == bigram:['what is', 'is the', 'the purpose', 'purpose of', 'of living'] == trigram:['what is the', 'is the purpose', 'the purpose of', 'purpose of living']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:can you please tell me the purpose of living
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'please', 'tell', 'me', 'the', 'purpose', 'of', 'living'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'pleas', 'tell', 'me', 'the', 'purpos', 'of', 'live'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['can', 'you', 'please', 'tell', 'me', 'the', 'purpose', 'of', 'living'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['can', 'you', 'please', 'tell', 'me', 'the', 'purpose', 'of', 'living'] == bigram:['can you', 'you please', 'please tell', 'tell me', 'me the', 'the purpose', 'purpose of', 'of living'] == trigram:['can you please', 'you please tell', 'please tell me', 'tell me the', 'me the purpose', 'the purpose of', 'purpose of living']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:what do you think is the purpose of living
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'living'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'do', 'you', 'think', 'is', 'the', 'purpos', 'of', 'live'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'living'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'living'] == bigram:['what do', 'do you', 'you think', 'think is', 'is the', 'the purpose', 'purpose of', 'of living'] == trigram:['what do you', 'do you think', 'you think is', 'think is the', 'is the purpose', 'the purpose of', 'purpose of living']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:please tell me what is the purpose of living
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'living'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['pleas', 'tell', 'me', 'what', 'is', 'the', 'purpos', 'of', 'live'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'living'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'living'] == bigram:['please tell', 'tell me', 'me what', 'what is', 'is the', 'the purpose', 'purpose of', 'of living'] == trigram:['please tell me', 'tell me what', 'me what is', 'what is the', 'is the purpose', 'the purpose of', 'purpose of living']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:will you please tell me what is the purpose of living
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'living'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['will', 'you', 'pleas', 'tell', 'me', 'what', 'is', 'the', 'purpos', 'of', 'live'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'living'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'living'] == bigram:['will you', 'you please', 'please tell', 'tell me', 'me what', 'what is', 'is the', 'the purpose', 'purpose of', 'of living'] == trigram:['will you please', 'you please tell', 'please tell me', 'tell me what', 'me what is', 'what is the', 'is the purpose', 'the purpose of', 'purpose of living']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:tell me what is the purpsoe of living
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['tell', 'me', 'what', 'is', 'the', 'purpsoe', 'of', 'living'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['tell', 'me', 'what', 'is', 'the', 'purpso', 'of', 'live'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['tell', 'me', 'what', 'is', 'the', 'purpsoe', 'of', 'living'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['tell', 'me', 'what', 'is', 'the', 'purpsoe', 'of', 'living'] == bigram:['tell me', 'me what', 'what is', 'is the', 'the purpsoe', 'purpsoe of', 'of living'] == trigram:['tell me what', 'me what is', 'what is the', 'is the purpsoe', 'the purpsoe of', 'purpsoe of living']
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] == bigram:['whats your', 'your name', 'name ok', 'ok data', 'data last', 'last test'] == trigram:['whats your name', 'your name ok', 'name ok data', 'ok data last', 'data last test']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:what can i call you
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you'] == bigram:['what can', 'can i', 'i call', 'call you'] == trigram:['what can i', 'can i call', 'i call you']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:may i know what your name is
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:how can i call you
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you'] == bigram:['how can', 'can i', 'i call', 'call you'] == trigram:['how can i', 'can i call', 'i call you']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:what is your good name
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name'] == bigram:['what is', 'is your', 'your good', 'good name'] == trigram:['what is your', 'is your good', 'your good name']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:what is the purpose of life
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:can you please tell what is the purpose of life
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'please', 'tell', 'what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'pleas', 'tell', 'what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['can', 'you', 'please', 'tell', 'what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['can', 'you', 'please', 'tell', 'what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['can you', 'you please', 'please tell', 'tell what', 'what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['can you please', 'you please tell', 'please tell what', 'tell what is', 'what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:what do you think is the purpose of life
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'do', 'you', 'think', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['what do', 'do you', 'you think', 'think is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['what do you', 'do you think', 'you think is', 'think is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:please tell me what is the purpose of life
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['pleas', 'tell', 'me', 'what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['please tell', 'tell me', 'me what', 'what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['please tell me', 'tell me what', 'me what is', 'what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:will you please tell me what is the purpose of life
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['will', 'you', 'pleas', 'tell', 'me', 'what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['will you', 'you please', 'please tell', 'tell me', 'me what', 'what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['will you please', 'you please tell', 'please tell me', 'tell me what', 'me what is', 'what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:living
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['living'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['live'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['living'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['living'] == bigram:[] == trigram:[]
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:what is the purpose of living
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'the', 'purpose', 'of', 'living'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'the', 'purpos', 'of', 'live'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'the', 'purpose', 'of', 'living'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'the', 'purpose', 'of', 'living'] == bigram:['what is', 'is the', 'the purpose', 'purpose of', 'of living'] == trigram:['what is the', 'is the purpose', 'the purpose of', 'purpose of living']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:can you please tell me the purpose of living
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'please', 'tell', 'me', 'the', 'purpose', 'of', 'living'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'pleas', 'tell', 'me', 'the', 'purpos', 'of', 'live'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['can', 'you', 'please', 'tell', 'me', 'the', 'purpose', 'of', 'living'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['can', 'you', 'please', 'tell', 'me', 'the', 'purpose', 'of', 'living'] == bigram:['can you', 'you please', 'please tell', 'tell me', 'me the', 'the purpose', 'purpose of', 'of living'] == trigram:['can you please', 'you please tell', 'please tell me', 'tell me the', 'me the purpose', 'the purpose of', 'purpose of living']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:what do you think is the purpose of living
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'living'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'do', 'you', 'think', 'is', 'the', 'purpos', 'of', 'live'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'living'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'living'] == bigram:['what do', 'do you', 'you think', 'think is', 'is the', 'the purpose', 'purpose of', 'of living'] == trigram:['what do you', 'do you think', 'you think is', 'think is the', 'is the purpose', 'the purpose of', 'purpose of living']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:please tell me what is the purpose of living
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'living'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['pleas', 'tell', 'me', 'what', 'is', 'the', 'purpos', 'of', 'live'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'living'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'living'] == bigram:['please tell', 'tell me', 'me what', 'what is', 'is the', 'the purpose', 'purpose of', 'of living'] == trigram:['please tell me', 'tell me what', 'me what is', 'what is the', 'is the purpose', 'the purpose of', 'purpose of living']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:will you please tell me what is the purpose of living
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'living'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['will', 'you', 'pleas', 'tell', 'me', 'what', 'is', 'the', 'purpos', 'of', 'live'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'living'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'living'] == bigram:['will you', 'you please', 'please tell', 'tell me', 'me what', 'what is', 'is the', 'the purpose', 'purpose of', 'of living'] == trigram:['will you please', 'you please tell', 'please tell me', 'tell me what', 'me what is', 'what is the', 'is the purpose', 'the purpose of', 'purpose of living']
2019-04-09 10:44:37	DEBUG	Punctuation handler ==>> text to process:tell me what is the purpsoe of living
2019-04-09 10:44:37	DEBUG	Tokenization handler ==>> takens:['tell', 'me', 'what', 'is', 'the', 'purpsoe', 'of', 'living'] and tokenize_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	Stemmer handler ==>> stem_tokens:['tell', 'me', 'what', 'is', 'the', 'purpso', 'of', 'live'] and stem_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	lemmatization handler ==>> lemma_tokens:['tell', 'me', 'what', 'is', 'the', 'purpsoe', 'of', 'living'] and lemma_without_stop_words:[]
2019-04-09 10:44:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:37	DEBUG	Ngram handler ==>> unigram:['tell', 'me', 'what', 'is', 'the', 'purpsoe', 'of', 'living'] == bigram:['tell me', 'me what', 'what is', 'is the', 'the purpsoe', 'purpsoe of', 'of living'] == trigram:['tell me what', 'me what is', 'what is the', 'is the purpsoe', 'the purpsoe of', 'purpsoe of living']
2019-04-09 10:44:51	DEBUG	Punctuation handler ==>> text to process:whats your name ok data last test
2019-04-09 10:44:51	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] and tokenize_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', 'ok', 'data', 'last', 'test'] and stem_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] and lemma_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:51	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] == bigram:['whats your', 'your name', 'name ok', 'ok data', 'data last', 'last test'] == trigram:['whats your name', 'your name ok', 'name ok data', 'ok data last', 'data last test']
2019-04-09 10:44:51	DEBUG	Punctuation handler ==>> text to process:what can i call you
2019-04-09 10:44:51	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:51	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you'] == bigram:['what can', 'can i', 'i call', 'call you'] == trigram:['what can i', 'can i call', 'i call you']
2019-04-09 10:44:51	DEBUG	Punctuation handler ==>> text to process:may i know what your name is
2019-04-09 10:44:51	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and tokenize_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and stem_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and lemma_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:51	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is']
2019-04-09 10:44:51	DEBUG	Punctuation handler ==>> text to process:how can i call you
2019-04-09 10:44:51	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:51	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you'] == bigram:['how can', 'can i', 'i call', 'call you'] == trigram:['how can i', 'can i call', 'i call you']
2019-04-09 10:44:51	DEBUG	Punctuation handler ==>> text to process:what is your good name
2019-04-09 10:44:51	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name'] and tokenize_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name'] and stem_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name'] and lemma_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:51	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name'] == bigram:['what is', 'is your', 'your good', 'good name'] == trigram:['what is your', 'is your good', 'your good name']
2019-04-09 10:44:51	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called
2019-04-09 10:44:51	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and tokenize_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call'] and stem_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and lemma_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:51	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called']
2019-04-09 10:44:51	DEBUG	Punctuation handler ==>> text to process:what is the purpose of life
2019-04-09 10:44:51	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:51	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:44:51	DEBUG	Punctuation handler ==>> text to process:can you please tell what is the purpose of life
2019-04-09 10:44:51	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'please', 'tell', 'what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'pleas', 'tell', 'what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	lemmatization handler ==>> lemma_tokens:['can', 'you', 'please', 'tell', 'what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:51	DEBUG	Ngram handler ==>> unigram:['can', 'you', 'please', 'tell', 'what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['can you', 'you please', 'please tell', 'tell what', 'what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['can you please', 'you please tell', 'please tell what', 'tell what is', 'what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:44:51	DEBUG	Punctuation handler ==>> text to process:what do you think is the purpose of life
2019-04-09 10:44:51	DEBUG	Tokenization handler ==>> takens:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'do', 'you', 'think', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:51	DEBUG	Ngram handler ==>> unigram:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['what do', 'do you', 'you think', 'think is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['what do you', 'do you think', 'you think is', 'think is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:44:51	DEBUG	Punctuation handler ==>> text to process:please tell me what is the purpose of life
2019-04-09 10:44:51	DEBUG	Tokenization handler ==>> takens:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	Stemmer handler ==>> stem_tokens:['pleas', 'tell', 'me', 'what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	lemmatization handler ==>> lemma_tokens:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:51	DEBUG	Ngram handler ==>> unigram:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['please tell', 'tell me', 'me what', 'what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['please tell me', 'tell me what', 'me what is', 'what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:44:51	DEBUG	Punctuation handler ==>> text to process:will you please tell me what is the purpose of life
2019-04-09 10:44:51	DEBUG	Tokenization handler ==>> takens:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	Stemmer handler ==>> stem_tokens:['will', 'you', 'pleas', 'tell', 'me', 'what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	lemmatization handler ==>> lemma_tokens:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:51	DEBUG	Ngram handler ==>> unigram:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['will you', 'you please', 'please tell', 'tell me', 'me what', 'what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['will you please', 'you please tell', 'please tell me', 'tell me what', 'me what is', 'what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:44:51	DEBUG	Punctuation handler ==>> text to process:living
2019-04-09 10:44:51	DEBUG	Tokenization handler ==>> takens:['living'] and tokenize_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	Stemmer handler ==>> stem_tokens:['live'] and stem_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	lemmatization handler ==>> lemma_tokens:['living'] and lemma_without_stop_words:[]
2019-04-09 10:44:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:44:51	DEBUG	Ngram handler ==>> unigram:['living'] == bigram:[] == trigram:[]
2019-04-09 10:45:13	DEBUG	Punctuation handler ==>> text to process:whats your name ok data last test
2019-04-09 10:45:13	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] and tokenize_without_stop_words:[]
2019-04-09 10:45:13	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', 'ok', 'data', 'last', 'test'] and stem_without_stop_words:[]
2019-04-09 10:45:15	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] and lemma_without_stop_words:[]
2019-04-09 10:45:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:45:15	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', 'ok', 'data', 'last', 'test'] == bigram:['whats your', 'your name', 'name ok', 'ok data', 'data last', 'last test'] == trigram:['whats your name', 'your name ok', 'name ok data', 'ok data last', 'data last test']
2019-04-09 10:45:15	DEBUG	Punctuation handler ==>> text to process:what can i call you
2019-04-09 10:45:15	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 10:45:15	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 10:45:15	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 10:45:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:45:15	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you'] == bigram:['what can', 'can i', 'i call', 'call you'] == trigram:['what can i', 'can i call', 'i call you']
2019-04-09 10:45:15	DEBUG	Punctuation handler ==>> text to process:may i know what your name is
2019-04-09 10:45:15	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and tokenize_without_stop_words:[]
2019-04-09 10:45:15	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and stem_without_stop_words:[]
2019-04-09 10:45:15	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and lemma_without_stop_words:[]
2019-04-09 10:45:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:45:15	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is']
2019-04-09 10:45:15	DEBUG	Punctuation handler ==>> text to process:how can i call you
2019-04-09 10:45:15	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 10:45:15	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 10:45:15	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 10:45:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:45:15	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you'] == bigram:['how can', 'can i', 'i call', 'call you'] == trigram:['how can i', 'can i call', 'i call you']
2019-04-09 10:45:15	DEBUG	Punctuation handler ==>> text to process:what is your good name
2019-04-09 10:45:15	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name'] and tokenize_without_stop_words:[]
2019-04-09 10:45:15	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name'] and stem_without_stop_words:[]
2019-04-09 10:45:15	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name'] and lemma_without_stop_words:[]
2019-04-09 10:45:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:45:15	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name'] == bigram:['what is', 'is your', 'your good', 'good name'] == trigram:['what is your', 'is your good', 'your good name']
2019-04-09 10:45:15	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called
2019-04-09 10:45:15	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and tokenize_without_stop_words:[]
2019-04-09 10:45:15	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call'] and stem_without_stop_words:[]
2019-04-09 10:45:15	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and lemma_without_stop_words:[]
2019-04-09 10:45:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:45:15	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called']
2019-04-09 10:45:15	DEBUG	Punctuation handler ==>> text to process:what is the purpose of life
2019-04-09 10:45:15	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:45:15	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:45:15	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:45:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:45:15	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:45:15	DEBUG	Punctuation handler ==>> text to process:can you please tell what is the purpose of life
2019-04-09 10:45:16	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'please', 'tell', 'what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'pleas', 'tell', 'what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	lemmatization handler ==>> lemma_tokens:['can', 'you', 'please', 'tell', 'what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:45:16	DEBUG	Ngram handler ==>> unigram:['can', 'you', 'please', 'tell', 'what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['can you', 'you please', 'please tell', 'tell what', 'what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['can you please', 'you please tell', 'please tell what', 'tell what is', 'what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:45:16	DEBUG	Punctuation handler ==>> text to process:what do you think is the purpose of life
2019-04-09 10:45:16	DEBUG	Tokenization handler ==>> takens:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'do', 'you', 'think', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:45:16	DEBUG	Ngram handler ==>> unigram:['what', 'do', 'you', 'think', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['what do', 'do you', 'you think', 'think is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['what do you', 'do you think', 'you think is', 'think is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:45:16	DEBUG	Punctuation handler ==>> text to process:please tell me what is the purpose of life
2019-04-09 10:45:16	DEBUG	Tokenization handler ==>> takens:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	Stemmer handler ==>> stem_tokens:['pleas', 'tell', 'me', 'what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	lemmatization handler ==>> lemma_tokens:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:45:16	DEBUG	Ngram handler ==>> unigram:['please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['please tell', 'tell me', 'me what', 'what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['please tell me', 'tell me what', 'me what is', 'what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:45:16	DEBUG	Punctuation handler ==>> text to process:will you please tell me what is the purpose of life
2019-04-09 10:45:16	DEBUG	Tokenization handler ==>> takens:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	Stemmer handler ==>> stem_tokens:['will', 'you', 'pleas', 'tell', 'me', 'what', 'is', 'the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	lemmatization handler ==>> lemma_tokens:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:45:16	DEBUG	Ngram handler ==>> unigram:['will', 'you', 'please', 'tell', 'me', 'what', 'is', 'the', 'purpose', 'of', 'life'] == bigram:['will you', 'you please', 'please tell', 'tell me', 'me what', 'what is', 'is the', 'the purpose', 'purpose of', 'of life'] == trigram:['will you please', 'you please tell', 'please tell me', 'tell me what', 'me what is', 'what is the', 'is the purpose', 'the purpose of', 'purpose of life']
2019-04-09 10:45:16	DEBUG	Punctuation handler ==>> text to process:living
2019-04-09 10:45:16	DEBUG	Tokenization handler ==>> takens:['living'] and tokenize_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	Stemmer handler ==>> stem_tokens:['live'] and stem_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	lemmatization handler ==>> lemma_tokens:['living'] and lemma_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:45:16	DEBUG	Ngram handler ==>> unigram:['living'] == bigram:[] == trigram:[]
2019-04-09 10:45:16	DEBUG	Punctuation handler ==>> text to process:where are you now
2019-04-09 10:45:16	DEBUG	Tokenization handler ==>> takens:['where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	lemmatization handler ==>> lemma_tokens:['where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:45:16	DEBUG	Ngram handler ==>> unigram:['where', 'are', 'you', 'now'] == bigram:['where are', 'are you', 'you now'] == trigram:['where are you', 'are you now']
2019-04-09 10:45:16	DEBUG	Punctuation handler ==>> text to process:tell me where are you now
2019-04-09 10:45:16	DEBUG	Tokenization handler ==>> takens:['tell', 'me', 'where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	Stemmer handler ==>> stem_tokens:['tell', 'me', 'where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	lemmatization handler ==>> lemma_tokens:['tell', 'me', 'where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:45:16	DEBUG	Ngram handler ==>> unigram:['tell', 'me', 'where', 'are', 'you', 'now'] == bigram:['tell me', 'me where', 'where are', 'are you', 'you now'] == trigram:['tell me where', 'me where are', 'where are you', 'are you now']
2019-04-09 10:45:16	DEBUG	Punctuation handler ==>> text to process:i would like to know where are you now
2019-04-09 10:45:16	DEBUG	Tokenization handler ==>> takens:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	lemmatization handler ==>> lemma_tokens:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:45:16	DEBUG	Ngram handler ==>> unigram:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] == bigram:['i would', 'would like', 'like to', 'to know', 'know where', 'where are', 'are you', 'you now'] == trigram:['i would like', 'would like to', 'like to know', 'to know where', 'know where are', 'where are you', 'are you now']
2019-04-09 10:45:16	DEBUG	Punctuation handler ==>> text to process:where are you now  please tell me
2019-04-09 10:45:16	DEBUG	Tokenization handler ==>> takens:['where', 'are', 'you', 'now', 'please', 'tell', 'me'] and tokenize_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'are', 'you', 'now', 'pleas', 'tell', 'me'] and stem_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	lemmatization handler ==>> lemma_tokens:['where', 'are', 'you', 'now', 'please', 'tell', 'me'] and lemma_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:45:16	DEBUG	Ngram handler ==>> unigram:['where', 'are', 'you', 'now', 'please', 'tell', 'me'] == bigram:['where are', 'are you', 'you now', 'now please', 'please tell', 'tell me'] == trigram:['where are you', 'are you now', 'you now please', 'now please tell', 'please tell me']
2019-04-09 10:45:16	DEBUG	Punctuation handler ==>> text to process:can you please tell me where are you now
2019-04-09 10:45:16	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'please', 'tell', 'me', 'where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'pleas', 'tell', 'me', 'where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	lemmatization handler ==>> lemma_tokens:['can', 'you', 'please', 'tell', 'me', 'where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:45:16	DEBUG	Ngram handler ==>> unigram:['can', 'you', 'please', 'tell', 'me', 'where', 'are', 'you', 'now'] == bigram:['can you', 'you please', 'please tell', 'tell me', 'me where', 'where are', 'are you', 'you now'] == trigram:['can you please', 'you please tell', 'please tell me', 'tell me where', 'me where are', 'where are you', 'are you now']
2019-04-09 10:45:16	DEBUG	Punctuation handler ==>> text to process:where can i find you
2019-04-09 10:45:16	DEBUG	Tokenization handler ==>> takens:['where', 'can', 'i', 'find', 'you'] and tokenize_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'can', 'i', 'find', 'you'] and stem_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	lemmatization handler ==>> lemma_tokens:['where', 'can', 'i', 'find', 'you'] and lemma_without_stop_words:[]
2019-04-09 10:45:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:45:16	DEBUG	Ngram handler ==>> unigram:['where', 'can', 'i', 'find', 'you'] == bigram:['where can', 'can i', 'i find', 'find you'] == trigram:['where can i', 'can i find', 'i find you']
2019-04-09 10:47:33	DEBUG	Punctuation handler ==>> text to process:the purpose of life
2019-04-09 10:47:33	DEBUG	Tokenization handler ==>> takens:['the', 'purpose', 'of', 'life'] and tokenize_without_stop_words:[]
2019-04-09 10:47:33	DEBUG	Stemmer handler ==>> stem_tokens:['the', 'purpos', 'of', 'life'] and stem_without_stop_words:[]
2019-04-09 10:47:37	DEBUG	lemmatization handler ==>> lemma_tokens:['the', 'purpose', 'of', 'life'] and lemma_without_stop_words:[]
2019-04-09 10:47:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 10:47:37	DEBUG	Ngram handler ==>> unigram:['the', 'purpose', 'of', 'life'] == bigram:['the purpose', 'purpose of', 'of life'] == trigram:['the purpose of', 'purpose of life']
2019-04-09 14:16:54	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-09 14:16:55	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:16:55	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-09 14:16:59	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:16:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:16:59	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-09 14:17:17	DEBUG	Punctuation handler ==>> text to process:whats your name
2019-04-09 14:17:17	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name'] and tokenize_without_stop_words:[]
2019-04-09 14:17:17	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name'] and stem_without_stop_words:[]
2019-04-09 14:17:17	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name'] and lemma_without_stop_words:[]
2019-04-09 14:17:17	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:17:17	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name'] == bigram:['whats your', 'your name'] == trigram:['whats your name']
2019-04-09 14:17:45	DEBUG	Punctuation handler ==>> text to process:whats your name
2019-04-09 14:17:45	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name'] and tokenize_without_stop_words:[]
2019-04-09 14:17:45	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name'] and stem_without_stop_words:[]
2019-04-09 14:17:47	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name'] and lemma_without_stop_words:[]
2019-04-09 14:17:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:17:47	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name'] == bigram:['whats your', 'your name'] == trigram:['whats your name']
2019-04-09 14:17:47	DEBUG	Punctuation handler ==>> text to process:what can i call you
2019-04-09 14:17:47	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:17:47	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 14:17:47	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:17:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:17:47	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you'] == bigram:['what can', 'can i', 'i call', 'call you'] == trigram:['what can i', 'can i call', 'i call you']
2019-04-09 14:17:47	DEBUG	Punctuation handler ==>> text to process:may i know what your name is
2019-04-09 14:17:47	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and tokenize_without_stop_words:[]
2019-04-09 14:17:47	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and stem_without_stop_words:[]
2019-04-09 14:17:47	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and lemma_without_stop_words:[]
2019-04-09 14:17:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:17:47	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is']
2019-04-09 14:17:47	DEBUG	Punctuation handler ==>> text to process:how can i call you
2019-04-09 14:17:47	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:17:47	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 14:17:47	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:17:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:17:47	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you'] == bigram:['how can', 'can i', 'i call', 'call you'] == trigram:['how can i', 'can i call', 'i call you']
2019-04-09 14:17:47	DEBUG	Punctuation handler ==>> text to process:what is your good name
2019-04-09 14:17:47	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name'] and tokenize_without_stop_words:[]
2019-04-09 14:17:47	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name'] and stem_without_stop_words:[]
2019-04-09 14:17:47	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name'] and lemma_without_stop_words:[]
2019-04-09 14:17:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:17:47	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name'] == bigram:['what is', 'is your', 'your good', 'good name'] == trigram:['what is your', 'is your good', 'your good name']
2019-04-09 14:17:47	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called
2019-04-09 14:17:47	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and tokenize_without_stop_words:[]
2019-04-09 14:17:47	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call'] and stem_without_stop_words:[]
2019-04-09 14:17:47	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and lemma_without_stop_words:[]
2019-04-09 14:17:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:17:47	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called']
2019-04-09 14:17:50	DEBUG	Punctuation handler ==>> text to process:whats your name
2019-04-09 14:17:50	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name'] and tokenize_without_stop_words:[]
2019-04-09 14:17:50	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name'] and stem_without_stop_words:[]
2019-04-09 14:17:50	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name'] and lemma_without_stop_words:[]
2019-04-09 14:17:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:17:50	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name'] == bigram:['whats your', 'your name'] == trigram:['whats your name']
2019-04-09 14:18:18	DEBUG	Punctuation handler ==>> text to process:whats your name
2019-04-09 14:18:18	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name'] and tokenize_without_stop_words:[]
2019-04-09 14:18:18	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name'] and stem_without_stop_words:[]
2019-04-09 14:18:18	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name'] and lemma_without_stop_words:[]
2019-04-09 14:18:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:18:18	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name'] == bigram:['whats your', 'your name'] == trigram:['whats your name']
2019-04-09 14:18:56	DEBUG	Punctuation handler ==>> text to process:whats your name
2019-04-09 14:18:56	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name'] and tokenize_without_stop_words:[]
2019-04-09 14:18:56	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name'] and stem_without_stop_words:[]
2019-04-09 14:18:58	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name'] and lemma_without_stop_words:[]
2019-04-09 14:18:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:18:58	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name'] == bigram:['whats your', 'your name'] == trigram:['whats your name']
2019-04-09 14:18:58	DEBUG	Punctuation handler ==>> text to process:what can i call you
2019-04-09 14:18:58	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:18:58	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 14:18:58	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:18:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:18:58	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you'] == bigram:['what can', 'can i', 'i call', 'call you'] == trigram:['what can i', 'can i call', 'i call you']
2019-04-09 14:18:58	DEBUG	Punctuation handler ==>> text to process:may i know what your name is
2019-04-09 14:18:58	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and tokenize_without_stop_words:[]
2019-04-09 14:18:58	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and stem_without_stop_words:[]
2019-04-09 14:18:58	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and lemma_without_stop_words:[]
2019-04-09 14:18:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:18:58	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is']
2019-04-09 14:18:58	DEBUG	Punctuation handler ==>> text to process:how can i call you
2019-04-09 14:18:58	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:18:58	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 14:18:58	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:18:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:18:58	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you'] == bigram:['how can', 'can i', 'i call', 'call you'] == trigram:['how can i', 'can i call', 'i call you']
2019-04-09 14:18:58	DEBUG	Punctuation handler ==>> text to process:what is your good name
2019-04-09 14:18:58	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name'] and tokenize_without_stop_words:[]
2019-04-09 14:18:58	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name'] and stem_without_stop_words:[]
2019-04-09 14:18:58	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name'] and lemma_without_stop_words:[]
2019-04-09 14:18:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:18:58	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name'] == bigram:['what is', 'is your', 'your good', 'good name'] == trigram:['what is your', 'is your good', 'your good name']
2019-04-09 14:18:58	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called
2019-04-09 14:18:58	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and tokenize_without_stop_words:[]
2019-04-09 14:18:58	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call'] and stem_without_stop_words:[]
2019-04-09 14:18:58	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and lemma_without_stop_words:[]
2019-04-09 14:18:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:18:58	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called']
2019-04-09 14:18:58	DEBUG	Punctuation handler ==>> text to process:where are you now
2019-04-09 14:18:58	DEBUG	Tokenization handler ==>> takens:['where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:18:58	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:18:58	DEBUG	lemmatization handler ==>> lemma_tokens:['where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:18:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:18:59	DEBUG	Ngram handler ==>> unigram:['where', 'are', 'you', 'now'] == bigram:['where are', 'are you', 'you now'] == trigram:['where are you', 'are you now']
2019-04-09 14:18:59	DEBUG	Punctuation handler ==>> text to process:tell me where are you now
2019-04-09 14:18:59	DEBUG	Tokenization handler ==>> takens:['tell', 'me', 'where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:18:59	DEBUG	Stemmer handler ==>> stem_tokens:['tell', 'me', 'where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:18:59	DEBUG	lemmatization handler ==>> lemma_tokens:['tell', 'me', 'where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:18:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:18:59	DEBUG	Ngram handler ==>> unigram:['tell', 'me', 'where', 'are', 'you', 'now'] == bigram:['tell me', 'me where', 'where are', 'are you', 'you now'] == trigram:['tell me where', 'me where are', 'where are you', 'are you now']
2019-04-09 14:18:59	DEBUG	Punctuation handler ==>> text to process:i would like to know where are you now
2019-04-09 14:18:59	DEBUG	Tokenization handler ==>> takens:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:18:59	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:18:59	DEBUG	lemmatization handler ==>> lemma_tokens:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:18:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:18:59	DEBUG	Ngram handler ==>> unigram:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] == bigram:['i would', 'would like', 'like to', 'to know', 'know where', 'where are', 'are you', 'you now'] == trigram:['i would like', 'would like to', 'like to know', 'to know where', 'know where are', 'where are you', 'are you now']
2019-04-09 14:18:59	DEBUG	Punctuation handler ==>> text to process:where are you now  please tell me
2019-04-09 14:18:59	DEBUG	Tokenization handler ==>> takens:['where', 'are', 'you', 'now', 'please', 'tell', 'me'] and tokenize_without_stop_words:[]
2019-04-09 14:18:59	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'are', 'you', 'now', 'pleas', 'tell', 'me'] and stem_without_stop_words:[]
2019-04-09 14:18:59	DEBUG	lemmatization handler ==>> lemma_tokens:['where', 'are', 'you', 'now', 'please', 'tell', 'me'] and lemma_without_stop_words:[]
2019-04-09 14:18:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:18:59	DEBUG	Ngram handler ==>> unigram:['where', 'are', 'you', 'now', 'please', 'tell', 'me'] == bigram:['where are', 'are you', 'you now', 'now please', 'please tell', 'tell me'] == trigram:['where are you', 'are you now', 'you now please', 'now please tell', 'please tell me']
2019-04-09 14:18:59	DEBUG	Punctuation handler ==>> text to process:can you please tell me where are you now
2019-04-09 14:18:59	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'please', 'tell', 'me', 'where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:18:59	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'pleas', 'tell', 'me', 'where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:18:59	DEBUG	lemmatization handler ==>> lemma_tokens:['can', 'you', 'please', 'tell', 'me', 'where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:18:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:18:59	DEBUG	Ngram handler ==>> unigram:['can', 'you', 'please', 'tell', 'me', 'where', 'are', 'you', 'now'] == bigram:['can you', 'you please', 'please tell', 'tell me', 'me where', 'where are', 'are you', 'you now'] == trigram:['can you please', 'you please tell', 'please tell me', 'tell me where', 'me where are', 'where are you', 'are you now']
2019-04-09 14:18:59	DEBUG	Punctuation handler ==>> text to process:where can i find you
2019-04-09 14:18:59	DEBUG	Tokenization handler ==>> takens:['where', 'can', 'i', 'find', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:18:59	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'can', 'i', 'find', 'you'] and stem_without_stop_words:[]
2019-04-09 14:18:59	DEBUG	lemmatization handler ==>> lemma_tokens:['where', 'can', 'i', 'find', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:18:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:18:59	DEBUG	Ngram handler ==>> unigram:['where', 'can', 'i', 'find', 'you'] == bigram:['where can', 'can i', 'i find', 'find you'] == trigram:['where can i', 'can i find', 'i find you']
2019-04-09 14:19:07	DEBUG	Punctuation handler ==>> text to process:whats your name
2019-04-09 14:19:07	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name'] and tokenize_without_stop_words:[]
2019-04-09 14:19:07	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name'] and stem_without_stop_words:[]
2019-04-09 14:19:07	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name'] and lemma_without_stop_words:[]
2019-04-09 14:19:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:19:07	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name'] == bigram:['whats your', 'your name'] == trigram:['whats your name']
2019-04-09 14:19:32	DEBUG	Punctuation handler ==>> text to process:20your name
2019-04-09 14:19:32	DEBUG	Tokenization handler ==>> takens:['20your', 'name'] and tokenize_without_stop_words:[]
2019-04-09 14:19:32	DEBUG	Stemmer handler ==>> stem_tokens:['20your', 'name'] and stem_without_stop_words:[]
2019-04-09 14:19:32	DEBUG	lemmatization handler ==>> lemma_tokens:['20your', 'name'] and lemma_without_stop_words:[]
2019-04-09 14:19:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:19:32	DEBUG	Ngram handler ==>> unigram:['20your', 'name'] == bigram:['20your name'] == trigram:[]
2019-04-09 14:19:47	DEBUG	Punctuation handler ==>> text to process:20your name
2019-04-09 14:19:47	DEBUG	Tokenization handler ==>> takens:['20your', 'name'] and tokenize_without_stop_words:[]
2019-04-09 14:19:47	DEBUG	Stemmer handler ==>> stem_tokens:['20your', 'name'] and stem_without_stop_words:[]
2019-04-09 14:19:51	DEBUG	lemmatization handler ==>> lemma_tokens:['20your', 'name'] and lemma_without_stop_words:[]
2019-04-09 14:19:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:19:51	DEBUG	Ngram handler ==>> unigram:['20your', 'name'] == bigram:['20your name'] == trigram:[]
2019-04-09 14:20:15	DEBUG	Punctuation handler ==>> text to process:20your name
2019-04-09 14:20:15	DEBUG	Tokenization handler ==>> takens:['20your', 'name'] and tokenize_without_stop_words:[]
2019-04-09 14:20:15	DEBUG	Stemmer handler ==>> stem_tokens:['20your', 'name'] and stem_without_stop_words:[]
2019-04-09 14:20:15	DEBUG	lemmatization handler ==>> lemma_tokens:['20your', 'name'] and lemma_without_stop_words:[]
2019-04-09 14:20:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:20:15	DEBUG	Ngram handler ==>> unigram:['20your', 'name'] == bigram:['20your name'] == trigram:[]
2019-04-09 14:20:20	DEBUG	Punctuation handler ==>> text to process:are you now
2019-04-09 14:20:20	DEBUG	Tokenization handler ==>> takens:['are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:20:20	DEBUG	Stemmer handler ==>> stem_tokens:['are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:20:20	DEBUG	lemmatization handler ==>> lemma_tokens:['are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:20:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:20:20	DEBUG	Ngram handler ==>> unigram:['are', 'you', 'now'] == bigram:['are you', 'you now'] == trigram:['are you now']
2019-04-09 14:20:30	DEBUG	Punctuation handler ==>> text to process:hats your nam
2019-04-09 14:20:30	DEBUG	Tokenization handler ==>> takens:['hats', 'your', 'nam'] and tokenize_without_stop_words:[]
2019-04-09 14:20:30	DEBUG	Stemmer handler ==>> stem_tokens:['hat', 'your', 'nam'] and stem_without_stop_words:[]
2019-04-09 14:20:30	DEBUG	lemmatization handler ==>> lemma_tokens:['hat', 'your', 'nam'] and lemma_without_stop_words:[]
2019-04-09 14:20:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:20:30	DEBUG	Ngram handler ==>> unigram:['hats', 'your', 'nam'] == bigram:['hats your', 'your nam'] == trigram:['hats your nam']
2019-04-09 14:20:36	DEBUG	Punctuation handler ==>> text to process:your nam
2019-04-09 14:20:36	DEBUG	Tokenization handler ==>> takens:['your', 'nam'] and tokenize_without_stop_words:[]
2019-04-09 14:20:36	DEBUG	Stemmer handler ==>> stem_tokens:['your', 'nam'] and stem_without_stop_words:[]
2019-04-09 14:20:36	DEBUG	lemmatization handler ==>> lemma_tokens:['your', 'nam'] and lemma_without_stop_words:[]
2019-04-09 14:20:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:20:36	DEBUG	Ngram handler ==>> unigram:['your', 'nam'] == bigram:['your nam'] == trigram:[]
2019-04-09 14:20:41	DEBUG	Punctuation handler ==>> text to process:your nam
2019-04-09 14:20:41	DEBUG	Tokenization handler ==>> takens:['your', 'nam'] and tokenize_without_stop_words:[]
2019-04-09 14:20:41	DEBUG	Stemmer handler ==>> stem_tokens:['your', 'nam'] and stem_without_stop_words:[]
2019-04-09 14:20:41	DEBUG	lemmatization handler ==>> lemma_tokens:['your', 'nam'] and lemma_without_stop_words:[]
2019-04-09 14:20:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:20:41	DEBUG	Ngram handler ==>> unigram:['your', 'nam'] == bigram:['your nam'] == trigram:[]
2019-04-09 14:20:57	DEBUG	Punctuation handler ==>> text to process:your nam
2019-04-09 14:20:57	DEBUG	Tokenization handler ==>> takens:['your', 'nam'] and tokenize_without_stop_words:[]
2019-04-09 14:20:57	DEBUG	Stemmer handler ==>> stem_tokens:['your', 'nam'] and stem_without_stop_words:[]
2019-04-09 14:21:01	DEBUG	lemmatization handler ==>> lemma_tokens:['your', 'nam'] and lemma_without_stop_words:[]
2019-04-09 14:21:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:21:01	DEBUG	Ngram handler ==>> unigram:['your', 'nam'] == bigram:['your nam'] == trigram:[]
2019-04-09 14:21:13	DEBUG	Punctuation handler ==>> text to process:your nam
2019-04-09 14:21:13	DEBUG	Tokenization handler ==>> takens:['your', 'nam'] and tokenize_without_stop_words:[]
2019-04-09 14:21:13	DEBUG	Stemmer handler ==>> stem_tokens:['your', 'nam'] and stem_without_stop_words:[]
2019-04-09 14:21:17	DEBUG	lemmatization handler ==>> lemma_tokens:['your', 'nam'] and lemma_without_stop_words:[]
2019-04-09 14:21:17	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:21:17	DEBUG	Ngram handler ==>> unigram:['your', 'nam'] == bigram:['your nam'] == trigram:[]
2019-04-09 14:22:15	DEBUG	Punctuation handler ==>> text to process:your nam
2019-04-09 14:22:15	DEBUG	Tokenization handler ==>> takens:['your', 'nam'] and tokenize_without_stop_words:[]
2019-04-09 14:22:15	DEBUG	Stemmer handler ==>> stem_tokens:['your', 'nam'] and stem_without_stop_words:[]
2019-04-09 14:22:19	DEBUG	lemmatization handler ==>> lemma_tokens:['your', 'nam'] and lemma_without_stop_words:[]
2019-04-09 14:22:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:22:19	DEBUG	Ngram handler ==>> unigram:['your', 'nam'] == bigram:['your nam'] == trigram:[]
2019-04-09 14:22:38	DEBUG	Punctuation handler ==>> text to process:how can i call you
2019-04-09 14:22:38	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:22:38	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 14:22:38	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:22:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:22:38	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you'] == bigram:['how can', 'can i', 'i call', 'call you'] == trigram:['how can i', 'can i call', 'i call you']
2019-04-09 14:22:55	DEBUG	Punctuation handler ==>> text to process:whats your name
2019-04-09 14:22:55	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name'] and tokenize_without_stop_words:[]
2019-04-09 14:22:55	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name'] and stem_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name'] and lemma_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:22:57	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name'] == bigram:['whats your', 'your name'] == trigram:['whats your name']
2019-04-09 14:22:57	DEBUG	Punctuation handler ==>> text to process:what can i call you
2019-04-09 14:22:57	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:22:57	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you'] == bigram:['what can', 'can i', 'i call', 'call you'] == trigram:['what can i', 'can i call', 'i call you']
2019-04-09 14:22:57	DEBUG	Punctuation handler ==>> text to process:may i know what your name is
2019-04-09 14:22:57	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and tokenize_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and stem_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and lemma_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:22:57	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is']
2019-04-09 14:22:57	DEBUG	Punctuation handler ==>> text to process:how can i call you
2019-04-09 14:22:57	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:22:57	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you'] == bigram:['how can', 'can i', 'i call', 'call you'] == trigram:['how can i', 'can i call', 'i call you']
2019-04-09 14:22:57	DEBUG	Punctuation handler ==>> text to process:what is your good name
2019-04-09 14:22:57	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name'] and tokenize_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name'] and stem_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name'] and lemma_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:22:57	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name'] == bigram:['what is', 'is your', 'your good', 'good name'] == trigram:['what is your', 'is your good', 'your good name']
2019-04-09 14:22:57	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called
2019-04-09 14:22:57	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and tokenize_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call'] and stem_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and lemma_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:22:57	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called']
2019-04-09 14:22:57	DEBUG	Punctuation handler ==>> text to process:where are you now
2019-04-09 14:22:57	DEBUG	Tokenization handler ==>> takens:['where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	lemmatization handler ==>> lemma_tokens:['where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:22:57	DEBUG	Ngram handler ==>> unigram:['where', 'are', 'you', 'now'] == bigram:['where are', 'are you', 'you now'] == trigram:['where are you', 'are you now']
2019-04-09 14:22:57	DEBUG	Punctuation handler ==>> text to process:tell me where are you now
2019-04-09 14:22:57	DEBUG	Tokenization handler ==>> takens:['tell', 'me', 'where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	Stemmer handler ==>> stem_tokens:['tell', 'me', 'where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	lemmatization handler ==>> lemma_tokens:['tell', 'me', 'where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:22:57	DEBUG	Ngram handler ==>> unigram:['tell', 'me', 'where', 'are', 'you', 'now'] == bigram:['tell me', 'me where', 'where are', 'are you', 'you now'] == trigram:['tell me where', 'me where are', 'where are you', 'are you now']
2019-04-09 14:22:57	DEBUG	Punctuation handler ==>> text to process:i would like to know where are you now
2019-04-09 14:22:57	DEBUG	Tokenization handler ==>> takens:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	lemmatization handler ==>> lemma_tokens:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:22:57	DEBUG	Ngram handler ==>> unigram:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] == bigram:['i would', 'would like', 'like to', 'to know', 'know where', 'where are', 'are you', 'you now'] == trigram:['i would like', 'would like to', 'like to know', 'to know where', 'know where are', 'where are you', 'are you now']
2019-04-09 14:22:57	DEBUG	Punctuation handler ==>> text to process:where are you now  please tell me
2019-04-09 14:22:57	DEBUG	Tokenization handler ==>> takens:['where', 'are', 'you', 'now', 'please', 'tell', 'me'] and tokenize_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'are', 'you', 'now', 'pleas', 'tell', 'me'] and stem_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	lemmatization handler ==>> lemma_tokens:['where', 'are', 'you', 'now', 'please', 'tell', 'me'] and lemma_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:22:57	DEBUG	Ngram handler ==>> unigram:['where', 'are', 'you', 'now', 'please', 'tell', 'me'] == bigram:['where are', 'are you', 'you now', 'now please', 'please tell', 'tell me'] == trigram:['where are you', 'are you now', 'you now please', 'now please tell', 'please tell me']
2019-04-09 14:22:57	DEBUG	Punctuation handler ==>> text to process:can you please tell me where are you now
2019-04-09 14:22:57	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'please', 'tell', 'me', 'where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'pleas', 'tell', 'me', 'where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	lemmatization handler ==>> lemma_tokens:['can', 'you', 'please', 'tell', 'me', 'where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:22:57	DEBUG	Ngram handler ==>> unigram:['can', 'you', 'please', 'tell', 'me', 'where', 'are', 'you', 'now'] == bigram:['can you', 'you please', 'please tell', 'tell me', 'me where', 'where are', 'are you', 'you now'] == trigram:['can you please', 'you please tell', 'please tell me', 'tell me where', 'me where are', 'where are you', 'are you now']
2019-04-09 14:22:57	DEBUG	Punctuation handler ==>> text to process:where can i find you
2019-04-09 14:22:57	DEBUG	Tokenization handler ==>> takens:['where', 'can', 'i', 'find', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'can', 'i', 'find', 'you'] and stem_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	lemmatization handler ==>> lemma_tokens:['where', 'can', 'i', 'find', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:22:57	DEBUG	Ngram handler ==>> unigram:['where', 'can', 'i', 'find', 'you'] == bigram:['where can', 'can i', 'i find', 'find you'] == trigram:['where can i', 'can i find', 'i find you']
2019-04-09 14:22:57	DEBUG	Punctuation handler ==>> text to process:siapa nama kamu
2019-04-09 14:22:57	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:22:57	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'kamu'] == bigram:['siapa nama', 'nama kamu'] == trigram:['siapa nama kamu']
2019-04-09 14:22:57	DEBUG	Punctuation handler ==>> text to process:bagaimana aku memanggilmu
2019-04-09 14:22:57	DEBUG	Tokenization handler ==>> takens:['bagaimana', 'aku', 'memanggilmu'] and tokenize_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	Stemmer handler ==>> stem_tokens:['bagaimana', 'aku', 'memanggilmu'] and stem_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	lemmatization handler ==>> lemma_tokens:['bagaimana', 'aku', 'memanggilmu'] and lemma_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:22:57	DEBUG	Ngram handler ==>> unigram:['bagaimana', 'aku', 'memanggilmu'] == bigram:['bagaimana aku', 'aku memanggilmu'] == trigram:['bagaimana aku memanggilmu']
2019-04-09 14:22:57	DEBUG	Punctuation handler ==>> text to process:boleh tahu siapa nama kamu
2019-04-09 14:22:57	DEBUG	Tokenization handler ==>> takens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	Stemmer handler ==>> stem_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	lemmatization handler ==>> lemma_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:22:57	DEBUG	Ngram handler ==>> unigram:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] == bigram:['boleh tahu', 'tahu siapa', 'siapa nama', 'nama kamu'] == trigram:['boleh tahu siapa', 'tahu siapa nama', 'siapa nama kamu']
2019-04-09 14:22:57	DEBUG	Punctuation handler ==>> text to process:siapa nama panggilan mu
2019-04-09 14:22:57	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'panggilan', 'mu'] and tokenize_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'panggilan', 'mu'] and stem_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'panggilan', 'mu'] and lemma_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:22:57	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'panggilan', 'mu'] == bigram:['siapa nama', 'nama panggilan', 'panggilan mu'] == trigram:['siapa nama panggilan', 'nama panggilan mu']
2019-04-09 14:22:57	DEBUG	Punctuation handler ==>> text to process:tolong kasih tahu nama kamu
2019-04-09 14:22:57	DEBUG	Tokenization handler ==>> takens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	Stemmer handler ==>> stem_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	lemmatization handler ==>> lemma_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:22:57	DEBUG	Ngram handler ==>> unigram:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] == bigram:['tolong kasih', 'kasih tahu', 'tahu nama', 'nama kamu'] == trigram:['tolong kasih tahu', 'kasih tahu nama', 'tahu nama kamu']
2019-04-09 14:22:57	DEBUG	Punctuation handler ==>> text to process:kamu ingin dipanggil dengan nama apa
2019-04-09 14:22:57	DEBUG	Tokenization handler ==>> takens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and tokenize_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	Stemmer handler ==>> stem_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and stem_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	lemmatization handler ==>> lemma_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and lemma_without_stop_words:[]
2019-04-09 14:22:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:22:57	DEBUG	Ngram handler ==>> unigram:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] == bigram:['kamu ingin', 'ingin dipanggil', 'dipanggil dengan', 'dengan nama', 'nama apa'] == trigram:['kamu ingin dipanggil', 'ingin dipanggil dengan', 'dipanggil dengan nama', 'dengan nama apa']
2019-04-09 14:23:08	DEBUG	Punctuation handler ==>> text to process:siapa nama kamu
2019-04-09 14:23:08	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:23:08	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:23:08	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:23:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:23:08	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'kamu'] == bigram:['siapa nama', 'nama kamu'] == trigram:['siapa nama kamu']
2019-04-09 14:23:24	DEBUG	Punctuation handler ==>> text to process:siapa nama kamu
2019-04-09 14:23:24	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:23:24	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:23:24	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:23:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:23:24	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'kamu'] == bigram:['siapa nama', 'nama kamu'] == trigram:['siapa nama kamu']
2019-04-09 14:23:52	DEBUG	Punctuation handler ==>> text to process:siapa nama kamu
2019-04-09 14:23:52	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:23:52	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:23:56	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:23:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:23:56	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'kamu'] == bigram:['siapa nama', 'nama kamu'] == trigram:['siapa nama kamu']
2019-04-09 14:24:42	DEBUG	Punctuation handler ==>> text to process:siapa nama kamu
2019-04-09 14:24:42	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:24:42	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:24:46	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:24:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:24:46	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'kamu'] == bigram:['siapa nama', 'nama kamu'] == trigram:['siapa nama kamu']
2019-04-09 14:25:02	DEBUG	Punctuation handler ==>> text to process:aimana aku memanggilmu
2019-04-09 14:25:02	DEBUG	Tokenization handler ==>> takens:['aimana', 'aku', 'memanggilmu'] and tokenize_without_stop_words:[]
2019-04-09 14:25:02	DEBUG	Stemmer handler ==>> stem_tokens:['aimana', 'aku', 'memanggilmu'] and stem_without_stop_words:[]
2019-04-09 14:25:02	DEBUG	lemmatization handler ==>> lemma_tokens:['aimana', 'aku', 'memanggilmu'] and lemma_without_stop_words:[]
2019-04-09 14:25:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:25:02	DEBUG	Ngram handler ==>> unigram:['aimana', 'aku', 'memanggilmu'] == bigram:['aimana aku', 'aku memanggilmu'] == trigram:['aimana aku memanggilmu']
2019-04-09 14:42:46	DEBUG	Punctuation handler ==>> text to process:where are you now
2019-04-09 14:42:46	DEBUG	Tokenization handler ==>> takens:['where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:42:46	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	lemmatization handler ==>> lemma_tokens:['where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:48	DEBUG	Ngram handler ==>> unigram:['where', 'are', 'you', 'now'] == bigram:['where are', 'are you', 'you now'] == trigram:['where are you', 'are you now']
2019-04-09 14:42:48	DEBUG	Punctuation handler ==>> text to process:tell me where are you now
2019-04-09 14:42:48	DEBUG	Tokenization handler ==>> takens:['tell', 'me', 'where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	Stemmer handler ==>> stem_tokens:['tell', 'me', 'where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	lemmatization handler ==>> lemma_tokens:['tell', 'me', 'where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:48	DEBUG	Ngram handler ==>> unigram:['tell', 'me', 'where', 'are', 'you', 'now'] == bigram:['tell me', 'me where', 'where are', 'are you', 'you now'] == trigram:['tell me where', 'me where are', 'where are you', 'are you now']
2019-04-09 14:42:48	DEBUG	Punctuation handler ==>> text to process:i would like to know where are you now
2019-04-09 14:42:48	DEBUG	Tokenization handler ==>> takens:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	lemmatization handler ==>> lemma_tokens:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:48	DEBUG	Ngram handler ==>> unigram:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] == bigram:['i would', 'would like', 'like to', 'to know', 'know where', 'where are', 'are you', 'you now'] == trigram:['i would like', 'would like to', 'like to know', 'to know where', 'know where are', 'where are you', 'are you now']
2019-04-09 14:42:48	DEBUG	Punctuation handler ==>> text to process:where are you now  please tell me
2019-04-09 14:42:48	DEBUG	Tokenization handler ==>> takens:['where', 'are', 'you', 'now', 'please', 'tell', 'me'] and tokenize_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'are', 'you', 'now', 'pleas', 'tell', 'me'] and stem_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	lemmatization handler ==>> lemma_tokens:['where', 'are', 'you', 'now', 'please', 'tell', 'me'] and lemma_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:48	DEBUG	Ngram handler ==>> unigram:['where', 'are', 'you', 'now', 'please', 'tell', 'me'] == bigram:['where are', 'are you', 'you now', 'now please', 'please tell', 'tell me'] == trigram:['where are you', 'are you now', 'you now please', 'now please tell', 'please tell me']
2019-04-09 14:42:48	DEBUG	Punctuation handler ==>> text to process:can you please tell me where are you now
2019-04-09 14:42:48	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'please', 'tell', 'me', 'where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'pleas', 'tell', 'me', 'where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	lemmatization handler ==>> lemma_tokens:['can', 'you', 'please', 'tell', 'me', 'where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:48	DEBUG	Ngram handler ==>> unigram:['can', 'you', 'please', 'tell', 'me', 'where', 'are', 'you', 'now'] == bigram:['can you', 'you please', 'please tell', 'tell me', 'me where', 'where are', 'are you', 'you now'] == trigram:['can you please', 'you please tell', 'please tell me', 'tell me where', 'me where are', 'where are you', 'are you now']
2019-04-09 14:42:48	DEBUG	Punctuation handler ==>> text to process:where can i find you
2019-04-09 14:42:48	DEBUG	Tokenization handler ==>> takens:['where', 'can', 'i', 'find', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'can', 'i', 'find', 'you'] and stem_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	lemmatization handler ==>> lemma_tokens:['where', 'can', 'i', 'find', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:48	DEBUG	Ngram handler ==>> unigram:['where', 'can', 'i', 'find', 'you'] == bigram:['where can', 'can i', 'i find', 'find you'] == trigram:['where can i', 'can i find', 'i find you']
2019-04-09 14:42:48	DEBUG	Punctuation handler ==>> text to process:siapa nama kamu
2019-04-09 14:42:48	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:48	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'kamu'] == bigram:['siapa nama', 'nama kamu'] == trigram:['siapa nama kamu']
2019-04-09 14:42:48	DEBUG	Punctuation handler ==>> text to process:bagaimana aku memanggilmu
2019-04-09 14:42:48	DEBUG	Tokenization handler ==>> takens:['bagaimana', 'aku', 'memanggilmu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	Stemmer handler ==>> stem_tokens:['bagaimana', 'aku', 'memanggilmu'] and stem_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	lemmatization handler ==>> lemma_tokens:['bagaimana', 'aku', 'memanggilmu'] and lemma_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:48	DEBUG	Ngram handler ==>> unigram:['bagaimana', 'aku', 'memanggilmu'] == bigram:['bagaimana aku', 'aku memanggilmu'] == trigram:['bagaimana aku memanggilmu']
2019-04-09 14:42:48	DEBUG	Punctuation handler ==>> text to process:boleh tahu siapa nama kamu
2019-04-09 14:42:48	DEBUG	Tokenization handler ==>> takens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	Stemmer handler ==>> stem_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	lemmatization handler ==>> lemma_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:48	DEBUG	Ngram handler ==>> unigram:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] == bigram:['boleh tahu', 'tahu siapa', 'siapa nama', 'nama kamu'] == trigram:['boleh tahu siapa', 'tahu siapa nama', 'siapa nama kamu']
2019-04-09 14:42:48	DEBUG	Punctuation handler ==>> text to process:siapa nama panggilan mu
2019-04-09 14:42:48	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'panggilan', 'mu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'panggilan', 'mu'] and stem_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'panggilan', 'mu'] and lemma_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:48	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'panggilan', 'mu'] == bigram:['siapa nama', 'nama panggilan', 'panggilan mu'] == trigram:['siapa nama panggilan', 'nama panggilan mu']
2019-04-09 14:42:48	DEBUG	Punctuation handler ==>> text to process:tolong kasih tahu nama kamu
2019-04-09 14:42:48	DEBUG	Tokenization handler ==>> takens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	Stemmer handler ==>> stem_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	lemmatization handler ==>> lemma_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:48	DEBUG	Ngram handler ==>> unigram:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] == bigram:['tolong kasih', 'kasih tahu', 'tahu nama', 'nama kamu'] == trigram:['tolong kasih tahu', 'kasih tahu nama', 'tahu nama kamu']
2019-04-09 14:42:48	DEBUG	Punctuation handler ==>> text to process:kamu ingin dipanggil dengan nama apa
2019-04-09 14:42:48	DEBUG	Tokenization handler ==>> takens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and tokenize_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	Stemmer handler ==>> stem_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and stem_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	lemmatization handler ==>> lemma_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and lemma_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:48	DEBUG	Ngram handler ==>> unigram:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] == bigram:['kamu ingin', 'ingin dipanggil', 'dipanggil dengan', 'dengan nama', 'nama apa'] == trigram:['kamu ingin dipanggil', 'ingin dipanggil dengan', 'dipanggil dengan nama', 'dengan nama apa']
2019-04-09 14:42:48	DEBUG	Punctuation handler ==>> text to process:hello
2019-04-09 14:42:48	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	lemmatization handler ==>> lemma_tokens:['hello'] and lemma_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:48	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-04-09 14:42:48	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-09 14:42:48	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:48	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-09 14:42:48	DEBUG	Punctuation handler ==>> text to process:ha ha ha
2019-04-09 14:42:48	DEBUG	Tokenization handler ==>> takens:['ha', 'ha', 'ha'] and tokenize_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	Stemmer handler ==>> stem_tokens:['ha', 'ha', 'ha'] and stem_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	lemmatization handler ==>> lemma_tokens:['ha', 'ha', 'ha'] and lemma_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:48	DEBUG	Ngram handler ==>> unigram:['ha', 'ha', 'ha'] == bigram:['ha ha', 'ha ha'] == trigram:['ha ha ha']
2019-04-09 14:42:48	DEBUG	Punctuation handler ==>> text to process:wow
2019-04-09 14:42:48	DEBUG	Tokenization handler ==>> takens:['wow'] and tokenize_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	Stemmer handler ==>> stem_tokens:['wow'] and stem_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	lemmatization handler ==>> lemma_tokens:['wow'] and lemma_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:48	DEBUG	Ngram handler ==>> unigram:['wow'] == bigram:[] == trigram:[]
2019-04-09 14:42:48	DEBUG	Punctuation handler ==>> text to process:good evening
2019-04-09 14:42:48	DEBUG	Tokenization handler ==>> takens:['good', 'evening'] and tokenize_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'even'] and stem_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'evening'] and lemma_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:48	DEBUG	Ngram handler ==>> unigram:['good', 'evening'] == bigram:['good evening'] == trigram:[]
2019-04-09 14:42:48	DEBUG	Punctuation handler ==>> text to process:good morning
2019-04-09 14:42:48	DEBUG	Tokenization handler ==>> takens:['good', 'morning'] and tokenize_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'morn'] and stem_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'morning'] and lemma_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:48	DEBUG	Ngram handler ==>> unigram:['good', 'morning'] == bigram:['good morning'] == trigram:[]
2019-04-09 14:42:48	DEBUG	Punctuation handler ==>> text to process:hello
2019-04-09 14:42:48	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	lemmatization handler ==>> lemma_tokens:['hello'] and lemma_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:48	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-04-09 14:42:48	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-09 14:42:48	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:48	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-09 14:42:48	DEBUG	Punctuation handler ==>> text to process:ha ha ha
2019-04-09 14:42:48	DEBUG	Tokenization handler ==>> takens:['ha', 'ha', 'ha'] and tokenize_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	Stemmer handler ==>> stem_tokens:['ha', 'ha', 'ha'] and stem_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	lemmatization handler ==>> lemma_tokens:['ha', 'ha', 'ha'] and lemma_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:48	DEBUG	Ngram handler ==>> unigram:['ha', 'ha', 'ha'] == bigram:['ha ha', 'ha ha'] == trigram:['ha ha ha']
2019-04-09 14:42:48	DEBUG	Punctuation handler ==>> text to process:wow
2019-04-09 14:42:48	DEBUG	Tokenization handler ==>> takens:['wow'] and tokenize_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	Stemmer handler ==>> stem_tokens:['wow'] and stem_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	lemmatization handler ==>> lemma_tokens:['wow'] and lemma_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:48	DEBUG	Ngram handler ==>> unigram:['wow'] == bigram:[] == trigram:[]
2019-04-09 14:42:48	DEBUG	Punctuation handler ==>> text to process:good evening
2019-04-09 14:42:48	DEBUG	Tokenization handler ==>> takens:['good', 'evening'] and tokenize_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'even'] and stem_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'evening'] and lemma_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:48	DEBUG	Ngram handler ==>> unigram:['good', 'evening'] == bigram:['good evening'] == trigram:[]
2019-04-09 14:42:48	DEBUG	Punctuation handler ==>> text to process:good morning
2019-04-09 14:42:48	DEBUG	Tokenization handler ==>> takens:['good', 'morning'] and tokenize_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'morn'] and stem_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'morning'] and lemma_without_stop_words:[]
2019-04-09 14:42:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:48	DEBUG	Ngram handler ==>> unigram:['good', 'morning'] == bigram:['good morning'] == trigram:[]
2019-04-09 14:42:49	DEBUG	Punctuation handler ==>> text to process:siapa nama kamu
2019-04-09 14:42:49	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:49	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'kamu'] == bigram:['siapa nama', 'nama kamu'] == trigram:['siapa nama kamu']
2019-04-09 14:42:49	DEBUG	Punctuation handler ==>> text to process:bagaimana aku memanggilmu
2019-04-09 14:42:49	DEBUG	Tokenization handler ==>> takens:['bagaimana', 'aku', 'memanggilmu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	Stemmer handler ==>> stem_tokens:['bagaimana', 'aku', 'memanggilmu'] and stem_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	lemmatization handler ==>> lemma_tokens:['bagaimana', 'aku', 'memanggilmu'] and lemma_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:49	DEBUG	Ngram handler ==>> unigram:['bagaimana', 'aku', 'memanggilmu'] == bigram:['bagaimana aku', 'aku memanggilmu'] == trigram:['bagaimana aku memanggilmu']
2019-04-09 14:42:49	DEBUG	Punctuation handler ==>> text to process:boleh tahu siapa nama kamu
2019-04-09 14:42:49	DEBUG	Tokenization handler ==>> takens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	Stemmer handler ==>> stem_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	lemmatization handler ==>> lemma_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:49	DEBUG	Ngram handler ==>> unigram:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] == bigram:['boleh tahu', 'tahu siapa', 'siapa nama', 'nama kamu'] == trigram:['boleh tahu siapa', 'tahu siapa nama', 'siapa nama kamu']
2019-04-09 14:42:49	DEBUG	Punctuation handler ==>> text to process:siapa nama panggilan mu
2019-04-09 14:42:49	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'panggilan', 'mu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'panggilan', 'mu'] and stem_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'panggilan', 'mu'] and lemma_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:49	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'panggilan', 'mu'] == bigram:['siapa nama', 'nama panggilan', 'panggilan mu'] == trigram:['siapa nama panggilan', 'nama panggilan mu']
2019-04-09 14:42:49	DEBUG	Punctuation handler ==>> text to process:tolong kasih tahu nama kamu
2019-04-09 14:42:49	DEBUG	Tokenization handler ==>> takens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	Stemmer handler ==>> stem_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	lemmatization handler ==>> lemma_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:49	DEBUG	Ngram handler ==>> unigram:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] == bigram:['tolong kasih', 'kasih tahu', 'tahu nama', 'nama kamu'] == trigram:['tolong kasih tahu', 'kasih tahu nama', 'tahu nama kamu']
2019-04-09 14:42:49	DEBUG	Punctuation handler ==>> text to process:kamu ingin dipanggil dengan nama apa
2019-04-09 14:42:49	DEBUG	Tokenization handler ==>> takens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and tokenize_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	Stemmer handler ==>> stem_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and stem_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	lemmatization handler ==>> lemma_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and lemma_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:49	DEBUG	Ngram handler ==>> unigram:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] == bigram:['kamu ingin', 'ingin dipanggil', 'dipanggil dengan', 'dengan nama', 'nama apa'] == trigram:['kamu ingin dipanggil', 'ingin dipanggil dengan', 'dipanggil dengan nama', 'dengan nama apa']
2019-04-09 14:42:49	DEBUG	Punctuation handler ==>> text to process:hello
2019-04-09 14:42:49	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	lemmatization handler ==>> lemma_tokens:['hello'] and lemma_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:49	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-04-09 14:42:49	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-09 14:42:49	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:49	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-09 14:42:49	DEBUG	Punctuation handler ==>> text to process:ha ha ha
2019-04-09 14:42:49	DEBUG	Tokenization handler ==>> takens:['ha', 'ha', 'ha'] and tokenize_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	Stemmer handler ==>> stem_tokens:['ha', 'ha', 'ha'] and stem_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	lemmatization handler ==>> lemma_tokens:['ha', 'ha', 'ha'] and lemma_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:49	DEBUG	Ngram handler ==>> unigram:['ha', 'ha', 'ha'] == bigram:['ha ha', 'ha ha'] == trigram:['ha ha ha']
2019-04-09 14:42:49	DEBUG	Punctuation handler ==>> text to process:wow
2019-04-09 14:42:49	DEBUG	Tokenization handler ==>> takens:['wow'] and tokenize_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	Stemmer handler ==>> stem_tokens:['wow'] and stem_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	lemmatization handler ==>> lemma_tokens:['wow'] and lemma_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:49	DEBUG	Ngram handler ==>> unigram:['wow'] == bigram:[] == trigram:[]
2019-04-09 14:42:49	DEBUG	Punctuation handler ==>> text to process:good evening
2019-04-09 14:42:49	DEBUG	Tokenization handler ==>> takens:['good', 'evening'] and tokenize_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'even'] and stem_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'evening'] and lemma_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:49	DEBUG	Ngram handler ==>> unigram:['good', 'evening'] == bigram:['good evening'] == trigram:[]
2019-04-09 14:42:49	DEBUG	Punctuation handler ==>> text to process:good morning
2019-04-09 14:42:49	DEBUG	Tokenization handler ==>> takens:['good', 'morning'] and tokenize_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'morn'] and stem_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'morning'] and lemma_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:49	DEBUG	Ngram handler ==>> unigram:['good', 'morning'] == bigram:['good morning'] == trigram:[]
2019-04-09 14:42:49	DEBUG	Punctuation handler ==>> text to process:hello
2019-04-09 14:42:49	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	lemmatization handler ==>> lemma_tokens:['hello'] and lemma_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:49	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-04-09 14:42:49	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-09 14:42:49	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:49	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-09 14:42:49	DEBUG	Punctuation handler ==>> text to process:ha ha ha
2019-04-09 14:42:49	DEBUG	Tokenization handler ==>> takens:['ha', 'ha', 'ha'] and tokenize_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	Stemmer handler ==>> stem_tokens:['ha', 'ha', 'ha'] and stem_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	lemmatization handler ==>> lemma_tokens:['ha', 'ha', 'ha'] and lemma_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:49	DEBUG	Ngram handler ==>> unigram:['ha', 'ha', 'ha'] == bigram:['ha ha', 'ha ha'] == trigram:['ha ha ha']
2019-04-09 14:42:49	DEBUG	Punctuation handler ==>> text to process:wow
2019-04-09 14:42:49	DEBUG	Tokenization handler ==>> takens:['wow'] and tokenize_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	Stemmer handler ==>> stem_tokens:['wow'] and stem_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	lemmatization handler ==>> lemma_tokens:['wow'] and lemma_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:49	DEBUG	Ngram handler ==>> unigram:['wow'] == bigram:[] == trigram:[]
2019-04-09 14:42:49	DEBUG	Punctuation handler ==>> text to process:good evening
2019-04-09 14:42:49	DEBUG	Tokenization handler ==>> takens:['good', 'evening'] and tokenize_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'even'] and stem_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'evening'] and lemma_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:49	DEBUG	Ngram handler ==>> unigram:['good', 'evening'] == bigram:['good evening'] == trigram:[]
2019-04-09 14:42:49	DEBUG	Punctuation handler ==>> text to process:good morning
2019-04-09 14:42:49	DEBUG	Tokenization handler ==>> takens:['good', 'morning'] and tokenize_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'morn'] and stem_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'morning'] and lemma_without_stop_words:[]
2019-04-09 14:42:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:49	DEBUG	Ngram handler ==>> unigram:['good', 'morning'] == bigram:['good morning'] == trigram:[]
2019-04-09 14:42:52	DEBUG	Punctuation handler ==>> text to process:siapa nama kamu
2019-04-09 14:42:52	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:52	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'kamu'] == bigram:['siapa nama', 'nama kamu'] == trigram:['siapa nama kamu']
2019-04-09 14:42:52	DEBUG	Punctuation handler ==>> text to process:bagaimana aku memanggilmu
2019-04-09 14:42:52	DEBUG	Tokenization handler ==>> takens:['bagaimana', 'aku', 'memanggilmu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	Stemmer handler ==>> stem_tokens:['bagaimana', 'aku', 'memanggilmu'] and stem_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	lemmatization handler ==>> lemma_tokens:['bagaimana', 'aku', 'memanggilmu'] and lemma_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:52	DEBUG	Ngram handler ==>> unigram:['bagaimana', 'aku', 'memanggilmu'] == bigram:['bagaimana aku', 'aku memanggilmu'] == trigram:['bagaimana aku memanggilmu']
2019-04-09 14:42:52	DEBUG	Punctuation handler ==>> text to process:boleh tahu siapa nama kamu
2019-04-09 14:42:52	DEBUG	Tokenization handler ==>> takens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	Stemmer handler ==>> stem_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	lemmatization handler ==>> lemma_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:52	DEBUG	Ngram handler ==>> unigram:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] == bigram:['boleh tahu', 'tahu siapa', 'siapa nama', 'nama kamu'] == trigram:['boleh tahu siapa', 'tahu siapa nama', 'siapa nama kamu']
2019-04-09 14:42:52	DEBUG	Punctuation handler ==>> text to process:siapa nama panggilan mu
2019-04-09 14:42:52	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'panggilan', 'mu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'panggilan', 'mu'] and stem_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'panggilan', 'mu'] and lemma_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:52	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'panggilan', 'mu'] == bigram:['siapa nama', 'nama panggilan', 'panggilan mu'] == trigram:['siapa nama panggilan', 'nama panggilan mu']
2019-04-09 14:42:52	DEBUG	Punctuation handler ==>> text to process:tolong kasih tahu nama kamu
2019-04-09 14:42:52	DEBUG	Tokenization handler ==>> takens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	Stemmer handler ==>> stem_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	lemmatization handler ==>> lemma_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:52	DEBUG	Ngram handler ==>> unigram:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] == bigram:['tolong kasih', 'kasih tahu', 'tahu nama', 'nama kamu'] == trigram:['tolong kasih tahu', 'kasih tahu nama', 'tahu nama kamu']
2019-04-09 14:42:52	DEBUG	Punctuation handler ==>> text to process:kamu ingin dipanggil dengan nama apa
2019-04-09 14:42:52	DEBUG	Tokenization handler ==>> takens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and tokenize_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	Stemmer handler ==>> stem_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and stem_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	lemmatization handler ==>> lemma_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and lemma_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:52	DEBUG	Ngram handler ==>> unigram:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] == bigram:['kamu ingin', 'ingin dipanggil', 'dipanggil dengan', 'dengan nama', 'nama apa'] == trigram:['kamu ingin dipanggil', 'ingin dipanggil dengan', 'dipanggil dengan nama', 'dengan nama apa']
2019-04-09 14:42:52	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-09 14:42:52	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:52	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-09 14:42:52	DEBUG	Punctuation handler ==>> text to process:ha ha ha
2019-04-09 14:42:52	DEBUG	Tokenization handler ==>> takens:['ha', 'ha', 'ha'] and tokenize_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	Stemmer handler ==>> stem_tokens:['ha', 'ha', 'ha'] and stem_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	lemmatization handler ==>> lemma_tokens:['ha', 'ha', 'ha'] and lemma_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:52	DEBUG	Ngram handler ==>> unigram:['ha', 'ha', 'ha'] == bigram:['ha ha', 'ha ha'] == trigram:['ha ha ha']
2019-04-09 14:42:52	DEBUG	Punctuation handler ==>> text to process:wow
2019-04-09 14:42:52	DEBUG	Tokenization handler ==>> takens:['wow'] and tokenize_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	Stemmer handler ==>> stem_tokens:['wow'] and stem_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	lemmatization handler ==>> lemma_tokens:['wow'] and lemma_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:52	DEBUG	Ngram handler ==>> unigram:['wow'] == bigram:[] == trigram:[]
2019-04-09 14:42:52	DEBUG	Punctuation handler ==>> text to process:good evening
2019-04-09 14:42:52	DEBUG	Tokenization handler ==>> takens:['good', 'evening'] and tokenize_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'even'] and stem_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'evening'] and lemma_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:52	DEBUG	Ngram handler ==>> unigram:['good', 'evening'] == bigram:['good evening'] == trigram:[]
2019-04-09 14:42:52	DEBUG	Punctuation handler ==>> text to process:good morning
2019-04-09 14:42:52	DEBUG	Tokenization handler ==>> takens:['good', 'morning'] and tokenize_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'morn'] and stem_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'morning'] and lemma_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:52	DEBUG	Ngram handler ==>> unigram:['good', 'morning'] == bigram:['good morning'] == trigram:[]
2019-04-09 14:42:52	DEBUG	Punctuation handler ==>> text to process:hello
2019-04-09 14:42:52	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	lemmatization handler ==>> lemma_tokens:['hello'] and lemma_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:52	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-04-09 14:42:52	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-09 14:42:52	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:52	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-09 14:42:52	DEBUG	Punctuation handler ==>> text to process:ha ha ha
2019-04-09 14:42:52	DEBUG	Tokenization handler ==>> takens:['ha', 'ha', 'ha'] and tokenize_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	Stemmer handler ==>> stem_tokens:['ha', 'ha', 'ha'] and stem_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	lemmatization handler ==>> lemma_tokens:['ha', 'ha', 'ha'] and lemma_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:52	DEBUG	Ngram handler ==>> unigram:['ha', 'ha', 'ha'] == bigram:['ha ha', 'ha ha'] == trigram:['ha ha ha']
2019-04-09 14:42:52	DEBUG	Punctuation handler ==>> text to process:wow
2019-04-09 14:42:52	DEBUG	Tokenization handler ==>> takens:['wow'] and tokenize_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	Stemmer handler ==>> stem_tokens:['wow'] and stem_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	lemmatization handler ==>> lemma_tokens:['wow'] and lemma_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:52	DEBUG	Ngram handler ==>> unigram:['wow'] == bigram:[] == trigram:[]
2019-04-09 14:42:52	DEBUG	Punctuation handler ==>> text to process:good evening
2019-04-09 14:42:52	DEBUG	Tokenization handler ==>> takens:['good', 'evening'] and tokenize_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'even'] and stem_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'evening'] and lemma_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:52	DEBUG	Ngram handler ==>> unigram:['good', 'evening'] == bigram:['good evening'] == trigram:[]
2019-04-09 14:42:52	DEBUG	Punctuation handler ==>> text to process:good morning
2019-04-09 14:42:52	DEBUG	Tokenization handler ==>> takens:['good', 'morning'] and tokenize_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'morn'] and stem_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'morning'] and lemma_without_stop_words:[]
2019-04-09 14:42:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:52	DEBUG	Ngram handler ==>> unigram:['good', 'morning'] == bigram:['good morning'] == trigram:[]
2019-04-09 14:42:53	DEBUG	Punctuation handler ==>> text to process:siapa nama kamu
2019-04-09 14:42:53	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:53	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:42:53	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:42:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:53	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'kamu'] == bigram:['siapa nama', 'nama kamu'] == trigram:['siapa nama kamu']
2019-04-09 14:42:53	DEBUG	Punctuation handler ==>> text to process:bagaimana aku memanggilmu
2019-04-09 14:42:53	DEBUG	Tokenization handler ==>> takens:['bagaimana', 'aku', 'memanggilmu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:53	DEBUG	Stemmer handler ==>> stem_tokens:['bagaimana', 'aku', 'memanggilmu'] and stem_without_stop_words:[]
2019-04-09 14:42:53	DEBUG	lemmatization handler ==>> lemma_tokens:['bagaimana', 'aku', 'memanggilmu'] and lemma_without_stop_words:[]
2019-04-09 14:42:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:53	DEBUG	Ngram handler ==>> unigram:['bagaimana', 'aku', 'memanggilmu'] == bigram:['bagaimana aku', 'aku memanggilmu'] == trigram:['bagaimana aku memanggilmu']
2019-04-09 14:42:53	DEBUG	Punctuation handler ==>> text to process:boleh tahu siapa nama kamu
2019-04-09 14:42:53	DEBUG	Tokenization handler ==>> takens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:53	DEBUG	Stemmer handler ==>> stem_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:42:53	DEBUG	lemmatization handler ==>> lemma_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:42:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:53	DEBUG	Ngram handler ==>> unigram:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] == bigram:['boleh tahu', 'tahu siapa', 'siapa nama', 'nama kamu'] == trigram:['boleh tahu siapa', 'tahu siapa nama', 'siapa nama kamu']
2019-04-09 14:42:53	DEBUG	Punctuation handler ==>> text to process:siapa nama panggilan mu
2019-04-09 14:42:53	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'panggilan', 'mu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:53	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'panggilan', 'mu'] and stem_without_stop_words:[]
2019-04-09 14:42:53	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'panggilan', 'mu'] and lemma_without_stop_words:[]
2019-04-09 14:42:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:53	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'panggilan', 'mu'] == bigram:['siapa nama', 'nama panggilan', 'panggilan mu'] == trigram:['siapa nama panggilan', 'nama panggilan mu']
2019-04-09 14:42:53	DEBUG	Punctuation handler ==>> text to process:tolong kasih tahu nama kamu
2019-04-09 14:42:53	DEBUG	Tokenization handler ==>> takens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	Stemmer handler ==>> stem_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	lemmatization handler ==>> lemma_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:54	DEBUG	Ngram handler ==>> unigram:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] == bigram:['tolong kasih', 'kasih tahu', 'tahu nama', 'nama kamu'] == trigram:['tolong kasih tahu', 'kasih tahu nama', 'tahu nama kamu']
2019-04-09 14:42:54	DEBUG	Punctuation handler ==>> text to process:kamu ingin dipanggil dengan nama apa
2019-04-09 14:42:54	DEBUG	Tokenization handler ==>> takens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and tokenize_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	Stemmer handler ==>> stem_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and stem_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	lemmatization handler ==>> lemma_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and lemma_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:54	DEBUG	Ngram handler ==>> unigram:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] == bigram:['kamu ingin', 'ingin dipanggil', 'dipanggil dengan', 'dengan nama', 'nama apa'] == trigram:['kamu ingin dipanggil', 'ingin dipanggil dengan', 'dipanggil dengan nama', 'dengan nama apa']
2019-04-09 14:42:54	DEBUG	Punctuation handler ==>> text to process:ha ha ha
2019-04-09 14:42:54	DEBUG	Tokenization handler ==>> takens:['ha', 'ha', 'ha'] and tokenize_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	Stemmer handler ==>> stem_tokens:['ha', 'ha', 'ha'] and stem_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	lemmatization handler ==>> lemma_tokens:['ha', 'ha', 'ha'] and lemma_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:54	DEBUG	Ngram handler ==>> unigram:['ha', 'ha', 'ha'] == bigram:['ha ha', 'ha ha'] == trigram:['ha ha ha']
2019-04-09 14:42:54	DEBUG	Punctuation handler ==>> text to process:wow
2019-04-09 14:42:54	DEBUG	Tokenization handler ==>> takens:['wow'] and tokenize_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	Stemmer handler ==>> stem_tokens:['wow'] and stem_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	lemmatization handler ==>> lemma_tokens:['wow'] and lemma_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:54	DEBUG	Ngram handler ==>> unigram:['wow'] == bigram:[] == trigram:[]
2019-04-09 14:42:54	DEBUG	Punctuation handler ==>> text to process:good evening
2019-04-09 14:42:54	DEBUG	Tokenization handler ==>> takens:['good', 'evening'] and tokenize_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'even'] and stem_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'evening'] and lemma_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:54	DEBUG	Ngram handler ==>> unigram:['good', 'evening'] == bigram:['good evening'] == trigram:[]
2019-04-09 14:42:54	DEBUG	Punctuation handler ==>> text to process:good morning
2019-04-09 14:42:54	DEBUG	Tokenization handler ==>> takens:['good', 'morning'] and tokenize_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'morn'] and stem_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'morning'] and lemma_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:54	DEBUG	Ngram handler ==>> unigram:['good', 'morning'] == bigram:['good morning'] == trigram:[]
2019-04-09 14:42:54	DEBUG	Punctuation handler ==>> text to process:hello
2019-04-09 14:42:54	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	lemmatization handler ==>> lemma_tokens:['hello'] and lemma_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:54	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-04-09 14:42:54	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-09 14:42:54	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:54	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-09 14:42:54	DEBUG	Punctuation handler ==>> text to process:ha ha ha
2019-04-09 14:42:54	DEBUG	Tokenization handler ==>> takens:['ha', 'ha', 'ha'] and tokenize_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	Stemmer handler ==>> stem_tokens:['ha', 'ha', 'ha'] and stem_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	lemmatization handler ==>> lemma_tokens:['ha', 'ha', 'ha'] and lemma_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:54	DEBUG	Ngram handler ==>> unigram:['ha', 'ha', 'ha'] == bigram:['ha ha', 'ha ha'] == trigram:['ha ha ha']
2019-04-09 14:42:54	DEBUG	Punctuation handler ==>> text to process:wow
2019-04-09 14:42:54	DEBUG	Tokenization handler ==>> takens:['wow'] and tokenize_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	Stemmer handler ==>> stem_tokens:['wow'] and stem_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	lemmatization handler ==>> lemma_tokens:['wow'] and lemma_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:54	DEBUG	Ngram handler ==>> unigram:['wow'] == bigram:[] == trigram:[]
2019-04-09 14:42:54	DEBUG	Punctuation handler ==>> text to process:good evening
2019-04-09 14:42:54	DEBUG	Tokenization handler ==>> takens:['good', 'evening'] and tokenize_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'even'] and stem_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'evening'] and lemma_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:54	DEBUG	Ngram handler ==>> unigram:['good', 'evening'] == bigram:['good evening'] == trigram:[]
2019-04-09 14:42:54	DEBUG	Punctuation handler ==>> text to process:good morning
2019-04-09 14:42:54	DEBUG	Tokenization handler ==>> takens:['good', 'morning'] and tokenize_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'morn'] and stem_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'morning'] and lemma_without_stop_words:[]
2019-04-09 14:42:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:54	DEBUG	Ngram handler ==>> unigram:['good', 'morning'] == bigram:['good morning'] == trigram:[]
2019-04-09 14:42:55	DEBUG	Punctuation handler ==>> text to process:siapa nama kamu
2019-04-09 14:42:55	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:55	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'kamu'] == bigram:['siapa nama', 'nama kamu'] == trigram:['siapa nama kamu']
2019-04-09 14:42:55	DEBUG	Punctuation handler ==>> text to process:bagaimana aku memanggilmu
2019-04-09 14:42:55	DEBUG	Tokenization handler ==>> takens:['bagaimana', 'aku', 'memanggilmu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	Stemmer handler ==>> stem_tokens:['bagaimana', 'aku', 'memanggilmu'] and stem_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	lemmatization handler ==>> lemma_tokens:['bagaimana', 'aku', 'memanggilmu'] and lemma_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:55	DEBUG	Ngram handler ==>> unigram:['bagaimana', 'aku', 'memanggilmu'] == bigram:['bagaimana aku', 'aku memanggilmu'] == trigram:['bagaimana aku memanggilmu']
2019-04-09 14:42:55	DEBUG	Punctuation handler ==>> text to process:boleh tahu siapa nama kamu
2019-04-09 14:42:55	DEBUG	Tokenization handler ==>> takens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	Stemmer handler ==>> stem_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	lemmatization handler ==>> lemma_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:55	DEBUG	Ngram handler ==>> unigram:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] == bigram:['boleh tahu', 'tahu siapa', 'siapa nama', 'nama kamu'] == trigram:['boleh tahu siapa', 'tahu siapa nama', 'siapa nama kamu']
2019-04-09 14:42:55	DEBUG	Punctuation handler ==>> text to process:siapa nama panggilan mu
2019-04-09 14:42:55	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'panggilan', 'mu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'panggilan', 'mu'] and stem_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'panggilan', 'mu'] and lemma_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:55	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'panggilan', 'mu'] == bigram:['siapa nama', 'nama panggilan', 'panggilan mu'] == trigram:['siapa nama panggilan', 'nama panggilan mu']
2019-04-09 14:42:55	DEBUG	Punctuation handler ==>> text to process:tolong kasih tahu nama kamu
2019-04-09 14:42:55	DEBUG	Tokenization handler ==>> takens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	Stemmer handler ==>> stem_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	lemmatization handler ==>> lemma_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:55	DEBUG	Ngram handler ==>> unigram:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] == bigram:['tolong kasih', 'kasih tahu', 'tahu nama', 'nama kamu'] == trigram:['tolong kasih tahu', 'kasih tahu nama', 'tahu nama kamu']
2019-04-09 14:42:55	DEBUG	Punctuation handler ==>> text to process:kamu ingin dipanggil dengan nama apa
2019-04-09 14:42:55	DEBUG	Tokenization handler ==>> takens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and tokenize_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	Stemmer handler ==>> stem_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and stem_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	lemmatization handler ==>> lemma_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and lemma_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:55	DEBUG	Ngram handler ==>> unigram:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] == bigram:['kamu ingin', 'ingin dipanggil', 'dipanggil dengan', 'dengan nama', 'nama apa'] == trigram:['kamu ingin dipanggil', 'ingin dipanggil dengan', 'dipanggil dengan nama', 'dengan nama apa']
2019-04-09 14:42:55	DEBUG	Punctuation handler ==>> text to process:ha ha ha
2019-04-09 14:42:55	DEBUG	Tokenization handler ==>> takens:['ha', 'ha', 'ha'] and tokenize_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	Stemmer handler ==>> stem_tokens:['ha', 'ha', 'ha'] and stem_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	lemmatization handler ==>> lemma_tokens:['ha', 'ha', 'ha'] and lemma_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:55	DEBUG	Ngram handler ==>> unigram:['ha', 'ha', 'ha'] == bigram:['ha ha', 'ha ha'] == trigram:['ha ha ha']
2019-04-09 14:42:55	DEBUG	Punctuation handler ==>> text to process:wow
2019-04-09 14:42:55	DEBUG	Tokenization handler ==>> takens:['wow'] and tokenize_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	Stemmer handler ==>> stem_tokens:['wow'] and stem_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	lemmatization handler ==>> lemma_tokens:['wow'] and lemma_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:55	DEBUG	Ngram handler ==>> unigram:['wow'] == bigram:[] == trigram:[]
2019-04-09 14:42:55	DEBUG	Punctuation handler ==>> text to process:good morning
2019-04-09 14:42:55	DEBUG	Tokenization handler ==>> takens:['good', 'morning'] and tokenize_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'morn'] and stem_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'morning'] and lemma_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:55	DEBUG	Ngram handler ==>> unigram:['good', 'morning'] == bigram:['good morning'] == trigram:[]
2019-04-09 14:42:55	DEBUG	Punctuation handler ==>> text to process:hello
2019-04-09 14:42:55	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	lemmatization handler ==>> lemma_tokens:['hello'] and lemma_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:55	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-04-09 14:42:55	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-09 14:42:55	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:55	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-09 14:42:55	DEBUG	Punctuation handler ==>> text to process:ha ha ha
2019-04-09 14:42:55	DEBUG	Tokenization handler ==>> takens:['ha', 'ha', 'ha'] and tokenize_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	Stemmer handler ==>> stem_tokens:['ha', 'ha', 'ha'] and stem_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	lemmatization handler ==>> lemma_tokens:['ha', 'ha', 'ha'] and lemma_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:55	DEBUG	Ngram handler ==>> unigram:['ha', 'ha', 'ha'] == bigram:['ha ha', 'ha ha'] == trigram:['ha ha ha']
2019-04-09 14:42:55	DEBUG	Punctuation handler ==>> text to process:wow
2019-04-09 14:42:55	DEBUG	Tokenization handler ==>> takens:['wow'] and tokenize_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	Stemmer handler ==>> stem_tokens:['wow'] and stem_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	lemmatization handler ==>> lemma_tokens:['wow'] and lemma_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:55	DEBUG	Ngram handler ==>> unigram:['wow'] == bigram:[] == trigram:[]
2019-04-09 14:42:55	DEBUG	Punctuation handler ==>> text to process:good evening
2019-04-09 14:42:55	DEBUG	Tokenization handler ==>> takens:['good', 'evening'] and tokenize_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'even'] and stem_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'evening'] and lemma_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:55	DEBUG	Ngram handler ==>> unigram:['good', 'evening'] == bigram:['good evening'] == trigram:[]
2019-04-09 14:42:55	DEBUG	Punctuation handler ==>> text to process:good morning
2019-04-09 14:42:55	DEBUG	Tokenization handler ==>> takens:['good', 'morning'] and tokenize_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'morn'] and stem_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'morning'] and lemma_without_stop_words:[]
2019-04-09 14:42:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:55	DEBUG	Ngram handler ==>> unigram:['good', 'morning'] == bigram:['good morning'] == trigram:[]
2019-04-09 14:42:57	DEBUG	Punctuation handler ==>> text to process:siapa nama kamu
2019-04-09 14:42:57	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:57	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'kamu'] == bigram:['siapa nama', 'nama kamu'] == trigram:['siapa nama kamu']
2019-04-09 14:42:57	DEBUG	Punctuation handler ==>> text to process:bagaimana aku memanggilmu
2019-04-09 14:42:57	DEBUG	Tokenization handler ==>> takens:['bagaimana', 'aku', 'memanggilmu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	Stemmer handler ==>> stem_tokens:['bagaimana', 'aku', 'memanggilmu'] and stem_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	lemmatization handler ==>> lemma_tokens:['bagaimana', 'aku', 'memanggilmu'] and lemma_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:57	DEBUG	Ngram handler ==>> unigram:['bagaimana', 'aku', 'memanggilmu'] == bigram:['bagaimana aku', 'aku memanggilmu'] == trigram:['bagaimana aku memanggilmu']
2019-04-09 14:42:57	DEBUG	Punctuation handler ==>> text to process:boleh tahu siapa nama kamu
2019-04-09 14:42:57	DEBUG	Tokenization handler ==>> takens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	Stemmer handler ==>> stem_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	lemmatization handler ==>> lemma_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:57	DEBUG	Ngram handler ==>> unigram:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] == bigram:['boleh tahu', 'tahu siapa', 'siapa nama', 'nama kamu'] == trigram:['boleh tahu siapa', 'tahu siapa nama', 'siapa nama kamu']
2019-04-09 14:42:57	DEBUG	Punctuation handler ==>> text to process:siapa nama panggilan mu
2019-04-09 14:42:57	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'panggilan', 'mu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'panggilan', 'mu'] and stem_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'panggilan', 'mu'] and lemma_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:57	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'panggilan', 'mu'] == bigram:['siapa nama', 'nama panggilan', 'panggilan mu'] == trigram:['siapa nama panggilan', 'nama panggilan mu']
2019-04-09 14:42:57	DEBUG	Punctuation handler ==>> text to process:tolong kasih tahu nama kamu
2019-04-09 14:42:57	DEBUG	Tokenization handler ==>> takens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	Stemmer handler ==>> stem_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	lemmatization handler ==>> lemma_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:57	DEBUG	Ngram handler ==>> unigram:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] == bigram:['tolong kasih', 'kasih tahu', 'tahu nama', 'nama kamu'] == trigram:['tolong kasih tahu', 'kasih tahu nama', 'tahu nama kamu']
2019-04-09 14:42:57	DEBUG	Punctuation handler ==>> text to process:kamu ingin dipanggil dengan nama apa
2019-04-09 14:42:57	DEBUG	Tokenization handler ==>> takens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and tokenize_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	Stemmer handler ==>> stem_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and stem_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	lemmatization handler ==>> lemma_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and lemma_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:57	DEBUG	Ngram handler ==>> unigram:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] == bigram:['kamu ingin', 'ingin dipanggil', 'dipanggil dengan', 'dengan nama', 'nama apa'] == trigram:['kamu ingin dipanggil', 'ingin dipanggil dengan', 'dipanggil dengan nama', 'dengan nama apa']
2019-04-09 14:42:57	DEBUG	Punctuation handler ==>> text to process:ha ha ha
2019-04-09 14:42:57	DEBUG	Tokenization handler ==>> takens:['ha', 'ha', 'ha'] and tokenize_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	Stemmer handler ==>> stem_tokens:['ha', 'ha', 'ha'] and stem_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	lemmatization handler ==>> lemma_tokens:['ha', 'ha', 'ha'] and lemma_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:57	DEBUG	Ngram handler ==>> unigram:['ha', 'ha', 'ha'] == bigram:['ha ha', 'ha ha'] == trigram:['ha ha ha']
2019-04-09 14:42:57	DEBUG	Punctuation handler ==>> text to process:wow
2019-04-09 14:42:57	DEBUG	Tokenization handler ==>> takens:['wow'] and tokenize_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	Stemmer handler ==>> stem_tokens:['wow'] and stem_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	lemmatization handler ==>> lemma_tokens:['wow'] and lemma_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:57	DEBUG	Ngram handler ==>> unigram:['wow'] == bigram:[] == trigram:[]
2019-04-09 14:42:57	DEBUG	Punctuation handler ==>> text to process:hello
2019-04-09 14:42:57	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	lemmatization handler ==>> lemma_tokens:['hello'] and lemma_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:57	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-04-09 14:42:57	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-09 14:42:57	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:57	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-09 14:42:57	DEBUG	Punctuation handler ==>> text to process:ha ha ha
2019-04-09 14:42:57	DEBUG	Tokenization handler ==>> takens:['ha', 'ha', 'ha'] and tokenize_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	Stemmer handler ==>> stem_tokens:['ha', 'ha', 'ha'] and stem_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	lemmatization handler ==>> lemma_tokens:['ha', 'ha', 'ha'] and lemma_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:57	DEBUG	Ngram handler ==>> unigram:['ha', 'ha', 'ha'] == bigram:['ha ha', 'ha ha'] == trigram:['ha ha ha']
2019-04-09 14:42:57	DEBUG	Punctuation handler ==>> text to process:wow
2019-04-09 14:42:57	DEBUG	Tokenization handler ==>> takens:['wow'] and tokenize_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	Stemmer handler ==>> stem_tokens:['wow'] and stem_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	lemmatization handler ==>> lemma_tokens:['wow'] and lemma_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:57	DEBUG	Ngram handler ==>> unigram:['wow'] == bigram:[] == trigram:[]
2019-04-09 14:42:57	DEBUG	Punctuation handler ==>> text to process:good evening
2019-04-09 14:42:57	DEBUG	Tokenization handler ==>> takens:['good', 'evening'] and tokenize_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'even'] and stem_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'evening'] and lemma_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:57	DEBUG	Ngram handler ==>> unigram:['good', 'evening'] == bigram:['good evening'] == trigram:[]
2019-04-09 14:42:57	DEBUG	Punctuation handler ==>> text to process:good morning
2019-04-09 14:42:57	DEBUG	Tokenization handler ==>> takens:['good', 'morning'] and tokenize_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'morn'] and stem_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'morning'] and lemma_without_stop_words:[]
2019-04-09 14:42:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:57	DEBUG	Ngram handler ==>> unigram:['good', 'morning'] == bigram:['good morning'] == trigram:[]
2019-04-09 14:42:59	DEBUG	Punctuation handler ==>> text to process:siapa nama kamu
2019-04-09 14:42:59	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:59	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'kamu'] == bigram:['siapa nama', 'nama kamu'] == trigram:['siapa nama kamu']
2019-04-09 14:42:59	DEBUG	Punctuation handler ==>> text to process:bagaimana aku memanggilmu
2019-04-09 14:42:59	DEBUG	Tokenization handler ==>> takens:['bagaimana', 'aku', 'memanggilmu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	Stemmer handler ==>> stem_tokens:['bagaimana', 'aku', 'memanggilmu'] and stem_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	lemmatization handler ==>> lemma_tokens:['bagaimana', 'aku', 'memanggilmu'] and lemma_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:59	DEBUG	Ngram handler ==>> unigram:['bagaimana', 'aku', 'memanggilmu'] == bigram:['bagaimana aku', 'aku memanggilmu'] == trigram:['bagaimana aku memanggilmu']
2019-04-09 14:42:59	DEBUG	Punctuation handler ==>> text to process:boleh tahu siapa nama kamu
2019-04-09 14:42:59	DEBUG	Tokenization handler ==>> takens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	Stemmer handler ==>> stem_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	lemmatization handler ==>> lemma_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:59	DEBUG	Ngram handler ==>> unigram:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] == bigram:['boleh tahu', 'tahu siapa', 'siapa nama', 'nama kamu'] == trigram:['boleh tahu siapa', 'tahu siapa nama', 'siapa nama kamu']
2019-04-09 14:42:59	DEBUG	Punctuation handler ==>> text to process:siapa nama panggilan mu
2019-04-09 14:42:59	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'panggilan', 'mu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'panggilan', 'mu'] and stem_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'panggilan', 'mu'] and lemma_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:59	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'panggilan', 'mu'] == bigram:['siapa nama', 'nama panggilan', 'panggilan mu'] == trigram:['siapa nama panggilan', 'nama panggilan mu']
2019-04-09 14:42:59	DEBUG	Punctuation handler ==>> text to process:tolong kasih tahu nama kamu
2019-04-09 14:42:59	DEBUG	Tokenization handler ==>> takens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	Stemmer handler ==>> stem_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	lemmatization handler ==>> lemma_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:59	DEBUG	Ngram handler ==>> unigram:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] == bigram:['tolong kasih', 'kasih tahu', 'tahu nama', 'nama kamu'] == trigram:['tolong kasih tahu', 'kasih tahu nama', 'tahu nama kamu']
2019-04-09 14:42:59	DEBUG	Punctuation handler ==>> text to process:kamu ingin dipanggil dengan nama apa
2019-04-09 14:42:59	DEBUG	Tokenization handler ==>> takens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and tokenize_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	Stemmer handler ==>> stem_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and stem_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	lemmatization handler ==>> lemma_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and lemma_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:59	DEBUG	Ngram handler ==>> unigram:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] == bigram:['kamu ingin', 'ingin dipanggil', 'dipanggil dengan', 'dengan nama', 'nama apa'] == trigram:['kamu ingin dipanggil', 'ingin dipanggil dengan', 'dipanggil dengan nama', 'dengan nama apa']
2019-04-09 14:42:59	DEBUG	Punctuation handler ==>> text to process:ha ha ha
2019-04-09 14:42:59	DEBUG	Tokenization handler ==>> takens:['ha', 'ha', 'ha'] and tokenize_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	Stemmer handler ==>> stem_tokens:['ha', 'ha', 'ha'] and stem_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	lemmatization handler ==>> lemma_tokens:['ha', 'ha', 'ha'] and lemma_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:59	DEBUG	Ngram handler ==>> unigram:['ha', 'ha', 'ha'] == bigram:['ha ha', 'ha ha'] == trigram:['ha ha ha']
2019-04-09 14:42:59	DEBUG	Punctuation handler ==>> text to process:wow
2019-04-09 14:42:59	DEBUG	Tokenization handler ==>> takens:['wow'] and tokenize_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	Stemmer handler ==>> stem_tokens:['wow'] and stem_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	lemmatization handler ==>> lemma_tokens:['wow'] and lemma_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:59	DEBUG	Ngram handler ==>> unigram:['wow'] == bigram:[] == trigram:[]
2019-04-09 14:42:59	DEBUG	Punctuation handler ==>> text to process:how are you
2019-04-09 14:42:59	DEBUG	Tokenization handler ==>> takens:['how', 'are', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'are', 'you'] and stem_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'are', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:59	DEBUG	Ngram handler ==>> unigram:['how', 'are', 'you'] == bigram:['how are', 'are you'] == trigram:['how are you']
2019-04-09 14:42:59	DEBUG	Punctuation handler ==>> text to process:ha ha ha
2019-04-09 14:42:59	DEBUG	Tokenization handler ==>> takens:['ha', 'ha', 'ha'] and tokenize_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	Stemmer handler ==>> stem_tokens:['ha', 'ha', 'ha'] and stem_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	lemmatization handler ==>> lemma_tokens:['ha', 'ha', 'ha'] and lemma_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:59	DEBUG	Ngram handler ==>> unigram:['ha', 'ha', 'ha'] == bigram:['ha ha', 'ha ha'] == trigram:['ha ha ha']
2019-04-09 14:42:59	DEBUG	Punctuation handler ==>> text to process:wow
2019-04-09 14:42:59	DEBUG	Tokenization handler ==>> takens:['wow'] and tokenize_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	Stemmer handler ==>> stem_tokens:['wow'] and stem_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	lemmatization handler ==>> lemma_tokens:['wow'] and lemma_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:59	DEBUG	Ngram handler ==>> unigram:['wow'] == bigram:[] == trigram:[]
2019-04-09 14:42:59	DEBUG	Punctuation handler ==>> text to process:good evening
2019-04-09 14:42:59	DEBUG	Tokenization handler ==>> takens:['good', 'evening'] and tokenize_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'even'] and stem_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'evening'] and lemma_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:59	DEBUG	Ngram handler ==>> unigram:['good', 'evening'] == bigram:['good evening'] == trigram:[]
2019-04-09 14:42:59	DEBUG	Punctuation handler ==>> text to process:good morning
2019-04-09 14:42:59	DEBUG	Tokenization handler ==>> takens:['good', 'morning'] and tokenize_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'morn'] and stem_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'morning'] and lemma_without_stop_words:[]
2019-04-09 14:42:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:42:59	DEBUG	Ngram handler ==>> unigram:['good', 'morning'] == bigram:['good morning'] == trigram:[]
2019-04-09 14:43:01	DEBUG	Punctuation handler ==>> text to process:siapa nama kamu
2019-04-09 14:43:01	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:01	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'kamu'] == bigram:['siapa nama', 'nama kamu'] == trigram:['siapa nama kamu']
2019-04-09 14:43:01	DEBUG	Punctuation handler ==>> text to process:bagaimana aku memanggilmu
2019-04-09 14:43:01	DEBUG	Tokenization handler ==>> takens:['bagaimana', 'aku', 'memanggilmu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	Stemmer handler ==>> stem_tokens:['bagaimana', 'aku', 'memanggilmu'] and stem_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	lemmatization handler ==>> lemma_tokens:['bagaimana', 'aku', 'memanggilmu'] and lemma_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:01	DEBUG	Ngram handler ==>> unigram:['bagaimana', 'aku', 'memanggilmu'] == bigram:['bagaimana aku', 'aku memanggilmu'] == trigram:['bagaimana aku memanggilmu']
2019-04-09 14:43:01	DEBUG	Punctuation handler ==>> text to process:boleh tahu siapa nama kamu
2019-04-09 14:43:01	DEBUG	Tokenization handler ==>> takens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	Stemmer handler ==>> stem_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	lemmatization handler ==>> lemma_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:01	DEBUG	Ngram handler ==>> unigram:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] == bigram:['boleh tahu', 'tahu siapa', 'siapa nama', 'nama kamu'] == trigram:['boleh tahu siapa', 'tahu siapa nama', 'siapa nama kamu']
2019-04-09 14:43:01	DEBUG	Punctuation handler ==>> text to process:siapa nama panggilan mu
2019-04-09 14:43:01	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'panggilan', 'mu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'panggilan', 'mu'] and stem_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'panggilan', 'mu'] and lemma_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:01	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'panggilan', 'mu'] == bigram:['siapa nama', 'nama panggilan', 'panggilan mu'] == trigram:['siapa nama panggilan', 'nama panggilan mu']
2019-04-09 14:43:01	DEBUG	Punctuation handler ==>> text to process:tolong kasih tahu nama kamu
2019-04-09 14:43:01	DEBUG	Tokenization handler ==>> takens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	Stemmer handler ==>> stem_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	lemmatization handler ==>> lemma_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:01	DEBUG	Ngram handler ==>> unigram:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] == bigram:['tolong kasih', 'kasih tahu', 'tahu nama', 'nama kamu'] == trigram:['tolong kasih tahu', 'kasih tahu nama', 'tahu nama kamu']
2019-04-09 14:43:01	DEBUG	Punctuation handler ==>> text to process:kamu ingin dipanggil dengan nama apa
2019-04-09 14:43:01	DEBUG	Tokenization handler ==>> takens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and tokenize_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	Stemmer handler ==>> stem_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and stem_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	lemmatization handler ==>> lemma_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and lemma_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:01	DEBUG	Ngram handler ==>> unigram:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] == bigram:['kamu ingin', 'ingin dipanggil', 'dipanggil dengan', 'dengan nama', 'nama apa'] == trigram:['kamu ingin dipanggil', 'ingin dipanggil dengan', 'dipanggil dengan nama', 'dengan nama apa']
2019-04-09 14:43:01	DEBUG	Punctuation handler ==>> text to process:ha ha ha
2019-04-09 14:43:01	DEBUG	Tokenization handler ==>> takens:['ha', 'ha', 'ha'] and tokenize_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	Stemmer handler ==>> stem_tokens:['ha', 'ha', 'ha'] and stem_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	lemmatization handler ==>> lemma_tokens:['ha', 'ha', 'ha'] and lemma_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:01	DEBUG	Ngram handler ==>> unigram:['ha', 'ha', 'ha'] == bigram:['ha ha', 'ha ha'] == trigram:['ha ha ha']
2019-04-09 14:43:01	DEBUG	Punctuation handler ==>> text to process:wow
2019-04-09 14:43:01	DEBUG	Tokenization handler ==>> takens:['wow'] and tokenize_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	Stemmer handler ==>> stem_tokens:['wow'] and stem_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	lemmatization handler ==>> lemma_tokens:['wow'] and lemma_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:01	DEBUG	Ngram handler ==>> unigram:['wow'] == bigram:[] == trigram:[]
2019-04-09 14:43:01	DEBUG	Punctuation handler ==>> text to process:ha ha ha
2019-04-09 14:43:01	DEBUG	Tokenization handler ==>> takens:['ha', 'ha', 'ha'] and tokenize_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	Stemmer handler ==>> stem_tokens:['ha', 'ha', 'ha'] and stem_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	lemmatization handler ==>> lemma_tokens:['ha', 'ha', 'ha'] and lemma_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:01	DEBUG	Ngram handler ==>> unigram:['ha', 'ha', 'ha'] == bigram:['ha ha', 'ha ha'] == trigram:['ha ha ha']
2019-04-09 14:43:01	DEBUG	Punctuation handler ==>> text to process:wow
2019-04-09 14:43:01	DEBUG	Tokenization handler ==>> takens:['wow'] and tokenize_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	Stemmer handler ==>> stem_tokens:['wow'] and stem_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	lemmatization handler ==>> lemma_tokens:['wow'] and lemma_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:01	DEBUG	Ngram handler ==>> unigram:['wow'] == bigram:[] == trigram:[]
2019-04-09 14:43:01	DEBUG	Punctuation handler ==>> text to process:good evening
2019-04-09 14:43:01	DEBUG	Tokenization handler ==>> takens:['good', 'evening'] and tokenize_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'even'] and stem_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'evening'] and lemma_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:01	DEBUG	Ngram handler ==>> unigram:['good', 'evening'] == bigram:['good evening'] == trigram:[]
2019-04-09 14:43:01	DEBUG	Punctuation handler ==>> text to process:good morning
2019-04-09 14:43:01	DEBUG	Tokenization handler ==>> takens:['good', 'morning'] and tokenize_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'morn'] and stem_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'morning'] and lemma_without_stop_words:[]
2019-04-09 14:43:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:01	DEBUG	Ngram handler ==>> unigram:['good', 'morning'] == bigram:['good morning'] == trigram:[]
2019-04-09 14:43:03	DEBUG	Punctuation handler ==>> text to process:siapa nama kamu
2019-04-09 14:43:03	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:03	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'kamu'] == bigram:['siapa nama', 'nama kamu'] == trigram:['siapa nama kamu']
2019-04-09 14:43:03	DEBUG	Punctuation handler ==>> text to process:bagaimana aku memanggilmu
2019-04-09 14:43:03	DEBUG	Tokenization handler ==>> takens:['bagaimana', 'aku', 'memanggilmu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	Stemmer handler ==>> stem_tokens:['bagaimana', 'aku', 'memanggilmu'] and stem_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	lemmatization handler ==>> lemma_tokens:['bagaimana', 'aku', 'memanggilmu'] and lemma_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:03	DEBUG	Ngram handler ==>> unigram:['bagaimana', 'aku', 'memanggilmu'] == bigram:['bagaimana aku', 'aku memanggilmu'] == trigram:['bagaimana aku memanggilmu']
2019-04-09 14:43:03	DEBUG	Punctuation handler ==>> text to process:boleh tahu siapa nama kamu
2019-04-09 14:43:03	DEBUG	Tokenization handler ==>> takens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	Stemmer handler ==>> stem_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	lemmatization handler ==>> lemma_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:03	DEBUG	Ngram handler ==>> unigram:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] == bigram:['boleh tahu', 'tahu siapa', 'siapa nama', 'nama kamu'] == trigram:['boleh tahu siapa', 'tahu siapa nama', 'siapa nama kamu']
2019-04-09 14:43:03	DEBUG	Punctuation handler ==>> text to process:siapa nama panggilan mu
2019-04-09 14:43:03	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'panggilan', 'mu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'panggilan', 'mu'] and stem_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'panggilan', 'mu'] and lemma_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:03	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'panggilan', 'mu'] == bigram:['siapa nama', 'nama panggilan', 'panggilan mu'] == trigram:['siapa nama panggilan', 'nama panggilan mu']
2019-04-09 14:43:03	DEBUG	Punctuation handler ==>> text to process:tolong kasih tahu nama kamu
2019-04-09 14:43:03	DEBUG	Tokenization handler ==>> takens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	Stemmer handler ==>> stem_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	lemmatization handler ==>> lemma_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:03	DEBUG	Ngram handler ==>> unigram:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] == bigram:['tolong kasih', 'kasih tahu', 'tahu nama', 'nama kamu'] == trigram:['tolong kasih tahu', 'kasih tahu nama', 'tahu nama kamu']
2019-04-09 14:43:03	DEBUG	Punctuation handler ==>> text to process:kamu ingin dipanggil dengan nama apa
2019-04-09 14:43:03	DEBUG	Tokenization handler ==>> takens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and tokenize_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	Stemmer handler ==>> stem_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and stem_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	lemmatization handler ==>> lemma_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and lemma_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:03	DEBUG	Ngram handler ==>> unigram:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] == bigram:['kamu ingin', 'ingin dipanggil', 'dipanggil dengan', 'dengan nama', 'nama apa'] == trigram:['kamu ingin dipanggil', 'ingin dipanggil dengan', 'dipanggil dengan nama', 'dengan nama apa']
2019-04-09 14:43:03	DEBUG	Punctuation handler ==>> text to process:ha ha ha
2019-04-09 14:43:03	DEBUG	Tokenization handler ==>> takens:['ha', 'ha', 'ha'] and tokenize_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	Stemmer handler ==>> stem_tokens:['ha', 'ha', 'ha'] and stem_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	lemmatization handler ==>> lemma_tokens:['ha', 'ha', 'ha'] and lemma_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:03	DEBUG	Ngram handler ==>> unigram:['ha', 'ha', 'ha'] == bigram:['ha ha', 'ha ha'] == trigram:['ha ha ha']
2019-04-09 14:43:03	DEBUG	Punctuation handler ==>> text to process:wow
2019-04-09 14:43:03	DEBUG	Tokenization handler ==>> takens:['wow'] and tokenize_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	Stemmer handler ==>> stem_tokens:['wow'] and stem_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	lemmatization handler ==>> lemma_tokens:['wow'] and lemma_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:03	DEBUG	Ngram handler ==>> unigram:['wow'] == bigram:[] == trigram:[]
2019-04-09 14:43:03	DEBUG	Punctuation handler ==>> text to process:ha ha ha
2019-04-09 14:43:03	DEBUG	Tokenization handler ==>> takens:['ha', 'ha', 'ha'] and tokenize_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	Stemmer handler ==>> stem_tokens:['ha', 'ha', 'ha'] and stem_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	lemmatization handler ==>> lemma_tokens:['ha', 'ha', 'ha'] and lemma_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:03	DEBUG	Ngram handler ==>> unigram:['ha', 'ha', 'ha'] == bigram:['ha ha', 'ha ha'] == trigram:['ha ha ha']
2019-04-09 14:43:03	DEBUG	Punctuation handler ==>> text to process:wow
2019-04-09 14:43:03	DEBUG	Tokenization handler ==>> takens:['wow'] and tokenize_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	Stemmer handler ==>> stem_tokens:['wow'] and stem_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	lemmatization handler ==>> lemma_tokens:['wow'] and lemma_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:03	DEBUG	Ngram handler ==>> unigram:['wow'] == bigram:[] == trigram:[]
2019-04-09 14:43:03	DEBUG	Punctuation handler ==>> text to process:good morning
2019-04-09 14:43:03	DEBUG	Tokenization handler ==>> takens:['good', 'morning'] and tokenize_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	Stemmer handler ==>> stem_tokens:['good', 'morn'] and stem_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	lemmatization handler ==>> lemma_tokens:['good', 'morning'] and lemma_without_stop_words:[]
2019-04-09 14:43:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:03	DEBUG	Ngram handler ==>> unigram:['good', 'morning'] == bigram:['good morning'] == trigram:[]
2019-04-09 14:43:04	DEBUG	Punctuation handler ==>> text to process:siapa nama kamu
2019-04-09 14:43:04	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:04	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:43:04	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:43:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:04	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'kamu'] == bigram:['siapa nama', 'nama kamu'] == trigram:['siapa nama kamu']
2019-04-09 14:43:04	DEBUG	Punctuation handler ==>> text to process:bagaimana aku memanggilmu
2019-04-09 14:43:04	DEBUG	Tokenization handler ==>> takens:['bagaimana', 'aku', 'memanggilmu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:04	DEBUG	Stemmer handler ==>> stem_tokens:['bagaimana', 'aku', 'memanggilmu'] and stem_without_stop_words:[]
2019-04-09 14:43:04	DEBUG	lemmatization handler ==>> lemma_tokens:['bagaimana', 'aku', 'memanggilmu'] and lemma_without_stop_words:[]
2019-04-09 14:43:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:04	DEBUG	Ngram handler ==>> unigram:['bagaimana', 'aku', 'memanggilmu'] == bigram:['bagaimana aku', 'aku memanggilmu'] == trigram:['bagaimana aku memanggilmu']
2019-04-09 14:43:04	DEBUG	Punctuation handler ==>> text to process:boleh tahu siapa nama kamu
2019-04-09 14:43:04	DEBUG	Tokenization handler ==>> takens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:04	DEBUG	Stemmer handler ==>> stem_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:43:04	DEBUG	lemmatization handler ==>> lemma_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:43:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:04	DEBUG	Ngram handler ==>> unigram:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] == bigram:['boleh tahu', 'tahu siapa', 'siapa nama', 'nama kamu'] == trigram:['boleh tahu siapa', 'tahu siapa nama', 'siapa nama kamu']
2019-04-09 14:43:04	DEBUG	Punctuation handler ==>> text to process:siapa nama panggilan mu
2019-04-09 14:43:04	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'panggilan', 'mu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:04	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'panggilan', 'mu'] and stem_without_stop_words:[]
2019-04-09 14:43:04	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'panggilan', 'mu'] and lemma_without_stop_words:[]
2019-04-09 14:43:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:04	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'panggilan', 'mu'] == bigram:['siapa nama', 'nama panggilan', 'panggilan mu'] == trigram:['siapa nama panggilan', 'nama panggilan mu']
2019-04-09 14:43:04	DEBUG	Punctuation handler ==>> text to process:tolong kasih tahu nama kamu
2019-04-09 14:43:04	DEBUG	Tokenization handler ==>> takens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:04	DEBUG	Stemmer handler ==>> stem_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:43:04	DEBUG	lemmatization handler ==>> lemma_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:43:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:04	DEBUG	Ngram handler ==>> unigram:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] == bigram:['tolong kasih', 'kasih tahu', 'tahu nama', 'nama kamu'] == trigram:['tolong kasih tahu', 'kasih tahu nama', 'tahu nama kamu']
2019-04-09 14:43:04	DEBUG	Punctuation handler ==>> text to process:kamu ingin dipanggil dengan nama apa
2019-04-09 14:43:04	DEBUG	Tokenization handler ==>> takens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and tokenize_without_stop_words:[]
2019-04-09 14:43:04	DEBUG	Stemmer handler ==>> stem_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and stem_without_stop_words:[]
2019-04-09 14:43:04	DEBUG	lemmatization handler ==>> lemma_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and lemma_without_stop_words:[]
2019-04-09 14:43:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:04	DEBUG	Ngram handler ==>> unigram:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] == bigram:['kamu ingin', 'ingin dipanggil', 'dipanggil dengan', 'dengan nama', 'nama apa'] == trigram:['kamu ingin dipanggil', 'ingin dipanggil dengan', 'dipanggil dengan nama', 'dengan nama apa']
2019-04-09 14:43:04	DEBUG	Punctuation handler ==>> text to process:ha ha ha
2019-04-09 14:43:04	DEBUG	Tokenization handler ==>> takens:['ha', 'ha', 'ha'] and tokenize_without_stop_words:[]
2019-04-09 14:43:04	DEBUG	Stemmer handler ==>> stem_tokens:['ha', 'ha', 'ha'] and stem_without_stop_words:[]
2019-04-09 14:43:04	DEBUG	lemmatization handler ==>> lemma_tokens:['ha', 'ha', 'ha'] and lemma_without_stop_words:[]
2019-04-09 14:43:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:04	DEBUG	Ngram handler ==>> unigram:['ha', 'ha', 'ha'] == bigram:['ha ha', 'ha ha'] == trigram:['ha ha ha']
2019-04-09 14:43:04	DEBUG	Punctuation handler ==>> text to process:wow
2019-04-09 14:43:04	DEBUG	Tokenization handler ==>> takens:['wow'] and tokenize_without_stop_words:[]
2019-04-09 14:43:04	DEBUG	Stemmer handler ==>> stem_tokens:['wow'] and stem_without_stop_words:[]
2019-04-09 14:43:04	DEBUG	lemmatization handler ==>> lemma_tokens:['wow'] and lemma_without_stop_words:[]
2019-04-09 14:43:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:04	DEBUG	Ngram handler ==>> unigram:['wow'] == bigram:[] == trigram:[]
2019-04-09 14:43:04	DEBUG	Punctuation handler ==>> text to process:ha ha ha
2019-04-09 14:43:04	DEBUG	Tokenization handler ==>> takens:['ha', 'ha', 'ha'] and tokenize_without_stop_words:[]
2019-04-09 14:43:04	DEBUG	Stemmer handler ==>> stem_tokens:['ha', 'ha', 'ha'] and stem_without_stop_words:[]
2019-04-09 14:43:04	DEBUG	lemmatization handler ==>> lemma_tokens:['ha', 'ha', 'ha'] and lemma_without_stop_words:[]
2019-04-09 14:43:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:04	DEBUG	Ngram handler ==>> unigram:['ha', 'ha', 'ha'] == bigram:['ha ha', 'ha ha'] == trigram:['ha ha ha']
2019-04-09 14:43:04	DEBUG	Punctuation handler ==>> text to process:wow
2019-04-09 14:43:04	DEBUG	Tokenization handler ==>> takens:['wow'] and tokenize_without_stop_words:[]
2019-04-09 14:43:04	DEBUG	Stemmer handler ==>> stem_tokens:['wow'] and stem_without_stop_words:[]
2019-04-09 14:43:04	DEBUG	lemmatization handler ==>> lemma_tokens:['wow'] and lemma_without_stop_words:[]
2019-04-09 14:43:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:04	DEBUG	Ngram handler ==>> unigram:['wow'] == bigram:[] == trigram:[]
2019-04-09 14:43:07	DEBUG	Punctuation handler ==>> text to process:siapa nama kamu
2019-04-09 14:43:07	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:07	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:43:07	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:43:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:07	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'kamu'] == bigram:['siapa nama', 'nama kamu'] == trigram:['siapa nama kamu']
2019-04-09 14:43:07	DEBUG	Punctuation handler ==>> text to process:bagaimana aku memanggilmu
2019-04-09 14:43:07	DEBUG	Tokenization handler ==>> takens:['bagaimana', 'aku', 'memanggilmu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:07	DEBUG	Stemmer handler ==>> stem_tokens:['bagaimana', 'aku', 'memanggilmu'] and stem_without_stop_words:[]
2019-04-09 14:43:07	DEBUG	lemmatization handler ==>> lemma_tokens:['bagaimana', 'aku', 'memanggilmu'] and lemma_without_stop_words:[]
2019-04-09 14:43:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:07	DEBUG	Ngram handler ==>> unigram:['bagaimana', 'aku', 'memanggilmu'] == bigram:['bagaimana aku', 'aku memanggilmu'] == trigram:['bagaimana aku memanggilmu']
2019-04-09 14:43:07	DEBUG	Punctuation handler ==>> text to process:boleh tahu siapa nama kamu
2019-04-09 14:43:07	DEBUG	Tokenization handler ==>> takens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:07	DEBUG	Stemmer handler ==>> stem_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:43:07	DEBUG	lemmatization handler ==>> lemma_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:43:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:07	DEBUG	Ngram handler ==>> unigram:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] == bigram:['boleh tahu', 'tahu siapa', 'siapa nama', 'nama kamu'] == trigram:['boleh tahu siapa', 'tahu siapa nama', 'siapa nama kamu']
2019-04-09 14:43:07	DEBUG	Punctuation handler ==>> text to process:siapa nama panggilan mu
2019-04-09 14:43:07	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'panggilan', 'mu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:07	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'panggilan', 'mu'] and stem_without_stop_words:[]
2019-04-09 14:43:07	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'panggilan', 'mu'] and lemma_without_stop_words:[]
2019-04-09 14:43:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:07	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'panggilan', 'mu'] == bigram:['siapa nama', 'nama panggilan', 'panggilan mu'] == trigram:['siapa nama panggilan', 'nama panggilan mu']
2019-04-09 14:43:07	DEBUG	Punctuation handler ==>> text to process:tolong kasih tahu nama kamu
2019-04-09 14:43:07	DEBUG	Tokenization handler ==>> takens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:07	DEBUG	Stemmer handler ==>> stem_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:43:07	DEBUG	lemmatization handler ==>> lemma_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:43:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:07	DEBUG	Ngram handler ==>> unigram:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] == bigram:['tolong kasih', 'kasih tahu', 'tahu nama', 'nama kamu'] == trigram:['tolong kasih tahu', 'kasih tahu nama', 'tahu nama kamu']
2019-04-09 14:43:07	DEBUG	Punctuation handler ==>> text to process:kamu ingin dipanggil dengan nama apa
2019-04-09 14:43:07	DEBUG	Tokenization handler ==>> takens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and tokenize_without_stop_words:[]
2019-04-09 14:43:07	DEBUG	Stemmer handler ==>> stem_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and stem_without_stop_words:[]
2019-04-09 14:43:07	DEBUG	lemmatization handler ==>> lemma_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and lemma_without_stop_words:[]
2019-04-09 14:43:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:07	DEBUG	Ngram handler ==>> unigram:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] == bigram:['kamu ingin', 'ingin dipanggil', 'dipanggil dengan', 'dengan nama', 'nama apa'] == trigram:['kamu ingin dipanggil', 'ingin dipanggil dengan', 'dipanggil dengan nama', 'dengan nama apa']
2019-04-09 14:43:07	DEBUG	Punctuation handler ==>> text to process:wow
2019-04-09 14:43:07	DEBUG	Tokenization handler ==>> takens:['wow'] and tokenize_without_stop_words:[]
2019-04-09 14:43:07	DEBUG	Stemmer handler ==>> stem_tokens:['wow'] and stem_without_stop_words:[]
2019-04-09 14:43:07	DEBUG	lemmatization handler ==>> lemma_tokens:['wow'] and lemma_without_stop_words:[]
2019-04-09 14:43:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:07	DEBUG	Ngram handler ==>> unigram:['wow'] == bigram:[] == trigram:[]
2019-04-09 14:43:07	DEBUG	Punctuation handler ==>> text to process:ha ha ha
2019-04-09 14:43:07	DEBUG	Tokenization handler ==>> takens:['ha', 'ha', 'ha'] and tokenize_without_stop_words:[]
2019-04-09 14:43:07	DEBUG	Stemmer handler ==>> stem_tokens:['ha', 'ha', 'ha'] and stem_without_stop_words:[]
2019-04-09 14:43:07	DEBUG	lemmatization handler ==>> lemma_tokens:['ha', 'ha', 'ha'] and lemma_without_stop_words:[]
2019-04-09 14:43:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:07	DEBUG	Ngram handler ==>> unigram:['ha', 'ha', 'ha'] == bigram:['ha ha', 'ha ha'] == trigram:['ha ha ha']
2019-04-09 14:43:07	DEBUG	Punctuation handler ==>> text to process:wow
2019-04-09 14:43:07	DEBUG	Tokenization handler ==>> takens:['wow'] and tokenize_without_stop_words:[]
2019-04-09 14:43:07	DEBUG	Stemmer handler ==>> stem_tokens:['wow'] and stem_without_stop_words:[]
2019-04-09 14:43:07	DEBUG	lemmatization handler ==>> lemma_tokens:['wow'] and lemma_without_stop_words:[]
2019-04-09 14:43:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:07	DEBUG	Ngram handler ==>> unigram:['wow'] == bigram:[] == trigram:[]
2019-04-09 14:43:09	DEBUG	Punctuation handler ==>> text to process:siapa nama kamu
2019-04-09 14:43:09	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:09	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:43:09	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:43:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:09	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'kamu'] == bigram:['siapa nama', 'nama kamu'] == trigram:['siapa nama kamu']
2019-04-09 14:43:09	DEBUG	Punctuation handler ==>> text to process:bagaimana aku memanggilmu
2019-04-09 14:43:09	DEBUG	Tokenization handler ==>> takens:['bagaimana', 'aku', 'memanggilmu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:09	DEBUG	Stemmer handler ==>> stem_tokens:['bagaimana', 'aku', 'memanggilmu'] and stem_without_stop_words:[]
2019-04-09 14:43:09	DEBUG	lemmatization handler ==>> lemma_tokens:['bagaimana', 'aku', 'memanggilmu'] and lemma_without_stop_words:[]
2019-04-09 14:43:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:09	DEBUG	Ngram handler ==>> unigram:['bagaimana', 'aku', 'memanggilmu'] == bigram:['bagaimana aku', 'aku memanggilmu'] == trigram:['bagaimana aku memanggilmu']
2019-04-09 14:43:09	DEBUG	Punctuation handler ==>> text to process:boleh tahu siapa nama kamu
2019-04-09 14:43:09	DEBUG	Tokenization handler ==>> takens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:09	DEBUG	Stemmer handler ==>> stem_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:43:09	DEBUG	lemmatization handler ==>> lemma_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:43:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:09	DEBUG	Ngram handler ==>> unigram:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] == bigram:['boleh tahu', 'tahu siapa', 'siapa nama', 'nama kamu'] == trigram:['boleh tahu siapa', 'tahu siapa nama', 'siapa nama kamu']
2019-04-09 14:43:09	DEBUG	Punctuation handler ==>> text to process:siapa nama panggilan mu
2019-04-09 14:43:09	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'panggilan', 'mu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:09	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'panggilan', 'mu'] and stem_without_stop_words:[]
2019-04-09 14:43:09	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'panggilan', 'mu'] and lemma_without_stop_words:[]
2019-04-09 14:43:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:09	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'panggilan', 'mu'] == bigram:['siapa nama', 'nama panggilan', 'panggilan mu'] == trigram:['siapa nama panggilan', 'nama panggilan mu']
2019-04-09 14:43:09	DEBUG	Punctuation handler ==>> text to process:tolong kasih tahu nama kamu
2019-04-09 14:43:09	DEBUG	Tokenization handler ==>> takens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:09	DEBUG	Stemmer handler ==>> stem_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:43:09	DEBUG	lemmatization handler ==>> lemma_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:43:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:09	DEBUG	Ngram handler ==>> unigram:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] == bigram:['tolong kasih', 'kasih tahu', 'tahu nama', 'nama kamu'] == trigram:['tolong kasih tahu', 'kasih tahu nama', 'tahu nama kamu']
2019-04-09 14:43:09	DEBUG	Punctuation handler ==>> text to process:kamu ingin dipanggil dengan nama apa
2019-04-09 14:43:09	DEBUG	Tokenization handler ==>> takens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and tokenize_without_stop_words:[]
2019-04-09 14:43:09	DEBUG	Stemmer handler ==>> stem_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and stem_without_stop_words:[]
2019-04-09 14:43:09	DEBUG	lemmatization handler ==>> lemma_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and lemma_without_stop_words:[]
2019-04-09 14:43:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:09	DEBUG	Ngram handler ==>> unigram:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] == bigram:['kamu ingin', 'ingin dipanggil', 'dipanggil dengan', 'dengan nama', 'nama apa'] == trigram:['kamu ingin dipanggil', 'ingin dipanggil dengan', 'dipanggil dengan nama', 'dengan nama apa']
2019-04-09 14:43:09	DEBUG	Punctuation handler ==>> text to process:ha ha ha
2019-04-09 14:43:09	DEBUG	Tokenization handler ==>> takens:['ha', 'ha', 'ha'] and tokenize_without_stop_words:[]
2019-04-09 14:43:09	DEBUG	Stemmer handler ==>> stem_tokens:['ha', 'ha', 'ha'] and stem_without_stop_words:[]
2019-04-09 14:43:09	DEBUG	lemmatization handler ==>> lemma_tokens:['ha', 'ha', 'ha'] and lemma_without_stop_words:[]
2019-04-09 14:43:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:09	DEBUG	Ngram handler ==>> unigram:['ha', 'ha', 'ha'] == bigram:['ha ha', 'ha ha'] == trigram:['ha ha ha']
2019-04-09 14:43:09	DEBUG	Punctuation handler ==>> text to process:wow
2019-04-09 14:43:09	DEBUG	Tokenization handler ==>> takens:['wow'] and tokenize_without_stop_words:[]
2019-04-09 14:43:09	DEBUG	Stemmer handler ==>> stem_tokens:['wow'] and stem_without_stop_words:[]
2019-04-09 14:43:09	DEBUG	lemmatization handler ==>> lemma_tokens:['wow'] and lemma_without_stop_words:[]
2019-04-09 14:43:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:09	DEBUG	Ngram handler ==>> unigram:['wow'] == bigram:[] == trigram:[]
2019-04-09 14:43:10	DEBUG	Punctuation handler ==>> text to process:siapa nama kamu
2019-04-09 14:43:10	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:10	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:43:10	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:43:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:10	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'kamu'] == bigram:['siapa nama', 'nama kamu'] == trigram:['siapa nama kamu']
2019-04-09 14:43:10	DEBUG	Punctuation handler ==>> text to process:bagaimana aku memanggilmu
2019-04-09 14:43:10	DEBUG	Tokenization handler ==>> takens:['bagaimana', 'aku', 'memanggilmu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:10	DEBUG	Stemmer handler ==>> stem_tokens:['bagaimana', 'aku', 'memanggilmu'] and stem_without_stop_words:[]
2019-04-09 14:43:10	DEBUG	lemmatization handler ==>> lemma_tokens:['bagaimana', 'aku', 'memanggilmu'] and lemma_without_stop_words:[]
2019-04-09 14:43:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:10	DEBUG	Ngram handler ==>> unigram:['bagaimana', 'aku', 'memanggilmu'] == bigram:['bagaimana aku', 'aku memanggilmu'] == trigram:['bagaimana aku memanggilmu']
2019-04-09 14:43:10	DEBUG	Punctuation handler ==>> text to process:boleh tahu siapa nama kamu
2019-04-09 14:43:10	DEBUG	Tokenization handler ==>> takens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:10	DEBUG	Stemmer handler ==>> stem_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:43:10	DEBUG	lemmatization handler ==>> lemma_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:43:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:10	DEBUG	Ngram handler ==>> unigram:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] == bigram:['boleh tahu', 'tahu siapa', 'siapa nama', 'nama kamu'] == trigram:['boleh tahu siapa', 'tahu siapa nama', 'siapa nama kamu']
2019-04-09 14:43:10	DEBUG	Punctuation handler ==>> text to process:siapa nama panggilan mu
2019-04-09 14:43:10	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'panggilan', 'mu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:10	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'panggilan', 'mu'] and stem_without_stop_words:[]
2019-04-09 14:43:10	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'panggilan', 'mu'] and lemma_without_stop_words:[]
2019-04-09 14:43:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:10	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'panggilan', 'mu'] == bigram:['siapa nama', 'nama panggilan', 'panggilan mu'] == trigram:['siapa nama panggilan', 'nama panggilan mu']
2019-04-09 14:43:10	DEBUG	Punctuation handler ==>> text to process:tolong kasih tahu nama kamu
2019-04-09 14:43:10	DEBUG	Tokenization handler ==>> takens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:10	DEBUG	Stemmer handler ==>> stem_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:43:10	DEBUG	lemmatization handler ==>> lemma_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:43:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:10	DEBUG	Ngram handler ==>> unigram:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] == bigram:['tolong kasih', 'kasih tahu', 'tahu nama', 'nama kamu'] == trigram:['tolong kasih tahu', 'kasih tahu nama', 'tahu nama kamu']
2019-04-09 14:43:10	DEBUG	Punctuation handler ==>> text to process:kamu ingin dipanggil dengan nama apa
2019-04-09 14:43:10	DEBUG	Tokenization handler ==>> takens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and tokenize_without_stop_words:[]
2019-04-09 14:43:10	DEBUG	Stemmer handler ==>> stem_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and stem_without_stop_words:[]
2019-04-09 14:43:10	DEBUG	lemmatization handler ==>> lemma_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and lemma_without_stop_words:[]
2019-04-09 14:43:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:10	DEBUG	Ngram handler ==>> unigram:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] == bigram:['kamu ingin', 'ingin dipanggil', 'dipanggil dengan', 'dengan nama', 'nama apa'] == trigram:['kamu ingin dipanggil', 'ingin dipanggil dengan', 'dipanggil dengan nama', 'dengan nama apa']
2019-04-09 14:43:10	DEBUG	Punctuation handler ==>> text to process:wow
2019-04-09 14:43:10	DEBUG	Tokenization handler ==>> takens:['wow'] and tokenize_without_stop_words:[]
2019-04-09 14:43:10	DEBUG	Stemmer handler ==>> stem_tokens:['wow'] and stem_without_stop_words:[]
2019-04-09 14:43:10	DEBUG	lemmatization handler ==>> lemma_tokens:['wow'] and lemma_without_stop_words:[]
2019-04-09 14:43:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:10	DEBUG	Ngram handler ==>> unigram:['wow'] == bigram:[] == trigram:[]
2019-04-09 14:43:12	DEBUG	Punctuation handler ==>> text to process:siapa nama kamu
2019-04-09 14:43:12	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:12	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:43:12	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:43:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:12	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'kamu'] == bigram:['siapa nama', 'nama kamu'] == trigram:['siapa nama kamu']
2019-04-09 14:43:12	DEBUG	Punctuation handler ==>> text to process:bagaimana aku memanggilmu
2019-04-09 14:43:12	DEBUG	Tokenization handler ==>> takens:['bagaimana', 'aku', 'memanggilmu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:12	DEBUG	Stemmer handler ==>> stem_tokens:['bagaimana', 'aku', 'memanggilmu'] and stem_without_stop_words:[]
2019-04-09 14:43:12	DEBUG	lemmatization handler ==>> lemma_tokens:['bagaimana', 'aku', 'memanggilmu'] and lemma_without_stop_words:[]
2019-04-09 14:43:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:12	DEBUG	Ngram handler ==>> unigram:['bagaimana', 'aku', 'memanggilmu'] == bigram:['bagaimana aku', 'aku memanggilmu'] == trigram:['bagaimana aku memanggilmu']
2019-04-09 14:43:12	DEBUG	Punctuation handler ==>> text to process:boleh tahu siapa nama kamu
2019-04-09 14:43:12	DEBUG	Tokenization handler ==>> takens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:12	DEBUG	Stemmer handler ==>> stem_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:43:12	DEBUG	lemmatization handler ==>> lemma_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:43:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:12	DEBUG	Ngram handler ==>> unigram:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] == bigram:['boleh tahu', 'tahu siapa', 'siapa nama', 'nama kamu'] == trigram:['boleh tahu siapa', 'tahu siapa nama', 'siapa nama kamu']
2019-04-09 14:43:12	DEBUG	Punctuation handler ==>> text to process:siapa nama panggilan mu
2019-04-09 14:43:12	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'panggilan', 'mu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:12	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'panggilan', 'mu'] and stem_without_stop_words:[]
2019-04-09 14:43:12	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'panggilan', 'mu'] and lemma_without_stop_words:[]
2019-04-09 14:43:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:12	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'panggilan', 'mu'] == bigram:['siapa nama', 'nama panggilan', 'panggilan mu'] == trigram:['siapa nama panggilan', 'nama panggilan mu']
2019-04-09 14:43:12	DEBUG	Punctuation handler ==>> text to process:tolong kasih tahu nama kamu
2019-04-09 14:43:12	DEBUG	Tokenization handler ==>> takens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:12	DEBUG	Stemmer handler ==>> stem_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:43:12	DEBUG	lemmatization handler ==>> lemma_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:43:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:12	DEBUG	Ngram handler ==>> unigram:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] == bigram:['tolong kasih', 'kasih tahu', 'tahu nama', 'nama kamu'] == trigram:['tolong kasih tahu', 'kasih tahu nama', 'tahu nama kamu']
2019-04-09 14:43:12	DEBUG	Punctuation handler ==>> text to process:kamu ingin dipanggil dengan nama apa
2019-04-09 14:43:12	DEBUG	Tokenization handler ==>> takens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and tokenize_without_stop_words:[]
2019-04-09 14:43:12	DEBUG	Stemmer handler ==>> stem_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and stem_without_stop_words:[]
2019-04-09 14:43:12	DEBUG	lemmatization handler ==>> lemma_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and lemma_without_stop_words:[]
2019-04-09 14:43:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:12	DEBUG	Ngram handler ==>> unigram:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] == bigram:['kamu ingin', 'ingin dipanggil', 'dipanggil dengan', 'dengan nama', 'nama apa'] == trigram:['kamu ingin dipanggil', 'ingin dipanggil dengan', 'dipanggil dengan nama', 'dengan nama apa']
2019-04-09 14:43:21	DEBUG	Punctuation handler ==>> text to process:siapa nama kamu
2019-04-09 14:43:21	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:21	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'kamu'] == bigram:['siapa nama', 'nama kamu'] == trigram:['siapa nama kamu']
2019-04-09 14:43:21	DEBUG	Punctuation handler ==>> text to process:bagaimana aku memanggilmu
2019-04-09 14:43:21	DEBUG	Tokenization handler ==>> takens:['bagaimana', 'aku', 'memanggilmu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	Stemmer handler ==>> stem_tokens:['bagaimana', 'aku', 'memanggilmu'] and stem_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	lemmatization handler ==>> lemma_tokens:['bagaimana', 'aku', 'memanggilmu'] and lemma_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:21	DEBUG	Ngram handler ==>> unigram:['bagaimana', 'aku', 'memanggilmu'] == bigram:['bagaimana aku', 'aku memanggilmu'] == trigram:['bagaimana aku memanggilmu']
2019-04-09 14:43:21	DEBUG	Punctuation handler ==>> text to process:boleh tahu siapa nama kamu
2019-04-09 14:43:21	DEBUG	Tokenization handler ==>> takens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	Stemmer handler ==>> stem_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	lemmatization handler ==>> lemma_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:21	DEBUG	Ngram handler ==>> unigram:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] == bigram:['boleh tahu', 'tahu siapa', 'siapa nama', 'nama kamu'] == trigram:['boleh tahu siapa', 'tahu siapa nama', 'siapa nama kamu']
2019-04-09 14:43:21	DEBUG	Punctuation handler ==>> text to process:siapa nama panggilan mu
2019-04-09 14:43:21	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'panggilan', 'mu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'panggilan', 'mu'] and stem_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'panggilan', 'mu'] and lemma_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:21	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'panggilan', 'mu'] == bigram:['siapa nama', 'nama panggilan', 'panggilan mu'] == trigram:['siapa nama panggilan', 'nama panggilan mu']
2019-04-09 14:43:21	DEBUG	Punctuation handler ==>> text to process:tolong kasih tahu nama kamu
2019-04-09 14:43:21	DEBUG	Tokenization handler ==>> takens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	Stemmer handler ==>> stem_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	lemmatization handler ==>> lemma_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:21	DEBUG	Ngram handler ==>> unigram:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] == bigram:['tolong kasih', 'kasih tahu', 'tahu nama', 'nama kamu'] == trigram:['tolong kasih tahu', 'kasih tahu nama', 'tahu nama kamu']
2019-04-09 14:43:21	DEBUG	Punctuation handler ==>> text to process:kamu ingin dipanggil dengan nama apa
2019-04-09 14:43:21	DEBUG	Tokenization handler ==>> takens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and tokenize_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	Stemmer handler ==>> stem_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and stem_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	lemmatization handler ==>> lemma_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and lemma_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:21	DEBUG	Ngram handler ==>> unigram:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] == bigram:['kamu ingin', 'ingin dipanggil', 'dipanggil dengan', 'dengan nama', 'nama apa'] == trigram:['kamu ingin dipanggil', 'ingin dipanggil dengan', 'dipanggil dengan nama', 'dengan nama apa']
2019-04-09 14:43:21	DEBUG	Punctuation handler ==>> text to process:whats your name
2019-04-09 14:43:21	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name'] and tokenize_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name'] and stem_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name'] and lemma_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:21	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name'] == bigram:['whats your', 'your name'] == trigram:['whats your name']
2019-04-09 14:43:21	DEBUG	Punctuation handler ==>> text to process:what can i call you
2019-04-09 14:43:21	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:21	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you'] == bigram:['what can', 'can i', 'i call', 'call you'] == trigram:['what can i', 'can i call', 'i call you']
2019-04-09 14:43:21	DEBUG	Punctuation handler ==>> text to process:may i know what your name is
2019-04-09 14:43:21	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and tokenize_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and stem_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and lemma_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:21	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is']
2019-04-09 14:43:21	DEBUG	Punctuation handler ==>> text to process:how can i call you
2019-04-09 14:43:21	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:21	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you'] == bigram:['how can', 'can i', 'i call', 'call you'] == trigram:['how can i', 'can i call', 'i call you']
2019-04-09 14:43:21	DEBUG	Punctuation handler ==>> text to process:what is your good name
2019-04-09 14:43:21	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name'] and tokenize_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name'] and stem_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name'] and lemma_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:21	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name'] == bigram:['what is', 'is your', 'your good', 'good name'] == trigram:['what is your', 'is your good', 'your good name']
2019-04-09 14:43:21	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called
2019-04-09 14:43:21	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and tokenize_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call'] and stem_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and lemma_without_stop_words:[]
2019-04-09 14:43:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:21	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called']
2019-04-09 14:43:25	DEBUG	Punctuation handler ==>> text to process:siapa nama kamu
2019-04-09 14:43:25	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:25	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:43:25	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:43:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:25	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'kamu'] == bigram:['siapa nama', 'nama kamu'] == trigram:['siapa nama kamu']
2019-04-09 14:43:25	DEBUG	Punctuation handler ==>> text to process:bagaimana aku memanggilmu
2019-04-09 14:43:25	DEBUG	Tokenization handler ==>> takens:['bagaimana', 'aku', 'memanggilmu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:25	DEBUG	Stemmer handler ==>> stem_tokens:['bagaimana', 'aku', 'memanggilmu'] and stem_without_stop_words:[]
2019-04-09 14:43:25	DEBUG	lemmatization handler ==>> lemma_tokens:['bagaimana', 'aku', 'memanggilmu'] and lemma_without_stop_words:[]
2019-04-09 14:43:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:25	DEBUG	Ngram handler ==>> unigram:['bagaimana', 'aku', 'memanggilmu'] == bigram:['bagaimana aku', 'aku memanggilmu'] == trigram:['bagaimana aku memanggilmu']
2019-04-09 14:43:25	DEBUG	Punctuation handler ==>> text to process:boleh tahu siapa nama kamu
2019-04-09 14:43:25	DEBUG	Tokenization handler ==>> takens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:25	DEBUG	Stemmer handler ==>> stem_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:43:25	DEBUG	lemmatization handler ==>> lemma_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:43:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:25	DEBUG	Ngram handler ==>> unigram:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] == bigram:['boleh tahu', 'tahu siapa', 'siapa nama', 'nama kamu'] == trigram:['boleh tahu siapa', 'tahu siapa nama', 'siapa nama kamu']
2019-04-09 14:43:25	DEBUG	Punctuation handler ==>> text to process:siapa nama panggilan mu
2019-04-09 14:43:25	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'panggilan', 'mu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:25	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'panggilan', 'mu'] and stem_without_stop_words:[]
2019-04-09 14:43:25	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'panggilan', 'mu'] and lemma_without_stop_words:[]
2019-04-09 14:43:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:25	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'panggilan', 'mu'] == bigram:['siapa nama', 'nama panggilan', 'panggilan mu'] == trigram:['siapa nama panggilan', 'nama panggilan mu']
2019-04-09 14:43:25	DEBUG	Punctuation handler ==>> text to process:tolong kasih tahu nama kamu
2019-04-09 14:43:25	DEBUG	Tokenization handler ==>> takens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:43:25	DEBUG	Stemmer handler ==>> stem_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:43:25	DEBUG	lemmatization handler ==>> lemma_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:43:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:25	DEBUG	Ngram handler ==>> unigram:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] == bigram:['tolong kasih', 'kasih tahu', 'tahu nama', 'nama kamu'] == trigram:['tolong kasih tahu', 'kasih tahu nama', 'tahu nama kamu']
2019-04-09 14:43:25	DEBUG	Punctuation handler ==>> text to process:kamu ingin dipanggil dengan nama apa
2019-04-09 14:43:25	DEBUG	Tokenization handler ==>> takens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and tokenize_without_stop_words:[]
2019-04-09 14:43:25	DEBUG	Stemmer handler ==>> stem_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and stem_without_stop_words:[]
2019-04-09 14:43:25	DEBUG	lemmatization handler ==>> lemma_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and lemma_without_stop_words:[]
2019-04-09 14:43:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:25	DEBUG	Ngram handler ==>> unigram:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] == bigram:['kamu ingin', 'ingin dipanggil', 'dipanggil dengan', 'dengan nama', 'nama apa'] == trigram:['kamu ingin dipanggil', 'ingin dipanggil dengan', 'dipanggil dengan nama', 'dengan nama apa']
2019-04-09 14:43:25	DEBUG	Punctuation handler ==>> text to process:whats your name
2019-04-09 14:43:25	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name'] and tokenize_without_stop_words:[]
2019-04-09 14:43:25	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name'] and stem_without_stop_words:[]
2019-04-09 14:43:25	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name'] and lemma_without_stop_words:[]
2019-04-09 14:43:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:25	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name'] == bigram:['whats your', 'your name'] == trigram:['whats your name']
2019-04-09 14:43:25	DEBUG	Punctuation handler ==>> text to process:what can i call you
2019-04-09 14:43:25	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:43:25	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 14:43:25	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:43:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:26	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you'] == bigram:['what can', 'can i', 'i call', 'call you'] == trigram:['what can i', 'can i call', 'i call you']
2019-04-09 14:43:26	DEBUG	Punctuation handler ==>> text to process:may i know what your name is
2019-04-09 14:43:26	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and tokenize_without_stop_words:[]
2019-04-09 14:43:26	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and stem_without_stop_words:[]
2019-04-09 14:43:26	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and lemma_without_stop_words:[]
2019-04-09 14:43:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:26	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is']
2019-04-09 14:43:26	DEBUG	Punctuation handler ==>> text to process:how can i call you
2019-04-09 14:43:26	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:43:26	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 14:43:26	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:43:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:26	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you'] == bigram:['how can', 'can i', 'i call', 'call you'] == trigram:['how can i', 'can i call', 'i call you']
2019-04-09 14:43:26	DEBUG	Punctuation handler ==>> text to process:what is your good name
2019-04-09 14:43:26	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name'] and tokenize_without_stop_words:[]
2019-04-09 14:43:26	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name'] and stem_without_stop_words:[]
2019-04-09 14:43:26	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name'] and lemma_without_stop_words:[]
2019-04-09 14:43:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:26	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name'] == bigram:['what is', 'is your', 'your good', 'good name'] == trigram:['what is your', 'is your good', 'your good name']
2019-04-09 14:43:26	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called
2019-04-09 14:43:26	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and tokenize_without_stop_words:[]
2019-04-09 14:43:26	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call'] and stem_without_stop_words:[]
2019-04-09 14:43:26	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and lemma_without_stop_words:[]
2019-04-09 14:43:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:26	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called']
2019-04-09 14:43:26	DEBUG	Punctuation handler ==>> text to process:where are you now
2019-04-09 14:43:26	DEBUG	Tokenization handler ==>> takens:['where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:43:26	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:43:26	DEBUG	lemmatization handler ==>> lemma_tokens:['where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:43:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:26	DEBUG	Ngram handler ==>> unigram:['where', 'are', 'you', 'now'] == bigram:['where are', 'are you', 'you now'] == trigram:['where are you', 'are you now']
2019-04-09 14:43:26	DEBUG	Punctuation handler ==>> text to process:tell me where are you now
2019-04-09 14:43:26	DEBUG	Tokenization handler ==>> takens:['tell', 'me', 'where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:43:26	DEBUG	Stemmer handler ==>> stem_tokens:['tell', 'me', 'where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:43:26	DEBUG	lemmatization handler ==>> lemma_tokens:['tell', 'me', 'where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:43:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:26	DEBUG	Ngram handler ==>> unigram:['tell', 'me', 'where', 'are', 'you', 'now'] == bigram:['tell me', 'me where', 'where are', 'are you', 'you now'] == trigram:['tell me where', 'me where are', 'where are you', 'are you now']
2019-04-09 14:43:26	DEBUG	Punctuation handler ==>> text to process:i would like to know where are you now
2019-04-09 14:43:26	DEBUG	Tokenization handler ==>> takens:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:43:26	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:43:26	DEBUG	lemmatization handler ==>> lemma_tokens:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:43:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:26	DEBUG	Ngram handler ==>> unigram:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] == bigram:['i would', 'would like', 'like to', 'to know', 'know where', 'where are', 'are you', 'you now'] == trigram:['i would like', 'would like to', 'like to know', 'to know where', 'know where are', 'where are you', 'are you now']
2019-04-09 14:43:26	DEBUG	Punctuation handler ==>> text to process:where are you now  please tell me
2019-04-09 14:43:26	DEBUG	Tokenization handler ==>> takens:['where', 'are', 'you', 'now', 'please', 'tell', 'me'] and tokenize_without_stop_words:[]
2019-04-09 14:43:26	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'are', 'you', 'now', 'pleas', 'tell', 'me'] and stem_without_stop_words:[]
2019-04-09 14:43:26	DEBUG	lemmatization handler ==>> lemma_tokens:['where', 'are', 'you', 'now', 'please', 'tell', 'me'] and lemma_without_stop_words:[]
2019-04-09 14:43:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:26	DEBUG	Ngram handler ==>> unigram:['where', 'are', 'you', 'now', 'please', 'tell', 'me'] == bigram:['where are', 'are you', 'you now', 'now please', 'please tell', 'tell me'] == trigram:['where are you', 'are you now', 'you now please', 'now please tell', 'please tell me']
2019-04-09 14:43:26	DEBUG	Punctuation handler ==>> text to process:can you please tell me where are you now
2019-04-09 14:43:26	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'please', 'tell', 'me', 'where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:43:26	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'pleas', 'tell', 'me', 'where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:43:26	DEBUG	lemmatization handler ==>> lemma_tokens:['can', 'you', 'please', 'tell', 'me', 'where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:43:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:26	DEBUG	Ngram handler ==>> unigram:['can', 'you', 'please', 'tell', 'me', 'where', 'are', 'you', 'now'] == bigram:['can you', 'you please', 'please tell', 'tell me', 'me where', 'where are', 'are you', 'you now'] == trigram:['can you please', 'you please tell', 'please tell me', 'tell me where', 'me where are', 'where are you', 'are you now']
2019-04-09 14:43:26	DEBUG	Punctuation handler ==>> text to process:where can i find you
2019-04-09 14:43:26	DEBUG	Tokenization handler ==>> takens:['where', 'can', 'i', 'find', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:43:26	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'can', 'i', 'find', 'you'] and stem_without_stop_words:[]
2019-04-09 14:43:26	DEBUG	lemmatization handler ==>> lemma_tokens:['where', 'can', 'i', 'find', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:43:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:43:26	DEBUG	Ngram handler ==>> unigram:['where', 'can', 'i', 'find', 'you'] == bigram:['where can', 'can i', 'i find', 'find you'] == trigram:['where can i', 'can i find', 'i find you']
2019-04-09 14:44:32	DEBUG	Punctuation handler ==>> text to process:siapa nama kamu
2019-04-09 14:44:32	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:32	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'kamu'] == bigram:['siapa nama', 'nama kamu'] == trigram:['siapa nama kamu']
2019-04-09 14:44:32	DEBUG	Punctuation handler ==>> text to process:bagaimana aku memanggilmu
2019-04-09 14:44:32	DEBUG	Tokenization handler ==>> takens:['bagaimana', 'aku', 'memanggilmu'] and tokenize_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	Stemmer handler ==>> stem_tokens:['bagaimana', 'aku', 'memanggilmu'] and stem_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	lemmatization handler ==>> lemma_tokens:['bagaimana', 'aku', 'memanggilmu'] and lemma_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:32	DEBUG	Ngram handler ==>> unigram:['bagaimana', 'aku', 'memanggilmu'] == bigram:['bagaimana aku', 'aku memanggilmu'] == trigram:['bagaimana aku memanggilmu']
2019-04-09 14:44:32	DEBUG	Punctuation handler ==>> text to process:boleh tahu siapa nama kamu
2019-04-09 14:44:32	DEBUG	Tokenization handler ==>> takens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	Stemmer handler ==>> stem_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	lemmatization handler ==>> lemma_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:32	DEBUG	Ngram handler ==>> unigram:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] == bigram:['boleh tahu', 'tahu siapa', 'siapa nama', 'nama kamu'] == trigram:['boleh tahu siapa', 'tahu siapa nama', 'siapa nama kamu']
2019-04-09 14:44:32	DEBUG	Punctuation handler ==>> text to process:siapa nama panggilan mu
2019-04-09 14:44:32	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'panggilan', 'mu'] and tokenize_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'panggilan', 'mu'] and stem_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'panggilan', 'mu'] and lemma_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:32	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'panggilan', 'mu'] == bigram:['siapa nama', 'nama panggilan', 'panggilan mu'] == trigram:['siapa nama panggilan', 'nama panggilan mu']
2019-04-09 14:44:32	DEBUG	Punctuation handler ==>> text to process:tolong kasih tahu nama kamu
2019-04-09 14:44:32	DEBUG	Tokenization handler ==>> takens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	Stemmer handler ==>> stem_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	lemmatization handler ==>> lemma_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:32	DEBUG	Ngram handler ==>> unigram:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] == bigram:['tolong kasih', 'kasih tahu', 'tahu nama', 'nama kamu'] == trigram:['tolong kasih tahu', 'kasih tahu nama', 'tahu nama kamu']
2019-04-09 14:44:32	DEBUG	Punctuation handler ==>> text to process:kamu ingin dipanggil dengan nama apa
2019-04-09 14:44:32	DEBUG	Tokenization handler ==>> takens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and tokenize_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	Stemmer handler ==>> stem_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and stem_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	lemmatization handler ==>> lemma_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and lemma_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:32	DEBUG	Ngram handler ==>> unigram:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] == bigram:['kamu ingin', 'ingin dipanggil', 'dipanggil dengan', 'dengan nama', 'nama apa'] == trigram:['kamu ingin dipanggil', 'ingin dipanggil dengan', 'dipanggil dengan nama', 'dengan nama apa']
2019-04-09 14:44:32	DEBUG	Punctuation handler ==>> text to process:whats your name
2019-04-09 14:44:32	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name'] and tokenize_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name'] and stem_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name'] and lemma_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:32	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name'] == bigram:['whats your', 'your name'] == trigram:['whats your name']
2019-04-09 14:44:32	DEBUG	Punctuation handler ==>> text to process:what can i call you
2019-04-09 14:44:32	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:32	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you'] == bigram:['what can', 'can i', 'i call', 'call you'] == trigram:['what can i', 'can i call', 'i call you']
2019-04-09 14:44:32	DEBUG	Punctuation handler ==>> text to process:may i know what your name is
2019-04-09 14:44:32	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and tokenize_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and stem_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and lemma_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:32	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is']
2019-04-09 14:44:32	DEBUG	Punctuation handler ==>> text to process:how can i call you
2019-04-09 14:44:32	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:32	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you'] == bigram:['how can', 'can i', 'i call', 'call you'] == trigram:['how can i', 'can i call', 'i call you']
2019-04-09 14:44:32	DEBUG	Punctuation handler ==>> text to process:what is your good name
2019-04-09 14:44:32	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name'] and tokenize_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name'] and stem_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name'] and lemma_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:32	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name'] == bigram:['what is', 'is your', 'your good', 'good name'] == trigram:['what is your', 'is your good', 'your good name']
2019-04-09 14:44:32	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called
2019-04-09 14:44:32	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and tokenize_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call'] and stem_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and lemma_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:32	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called']
2019-04-09 14:44:32	DEBUG	Punctuation handler ==>> text to process:where are you now
2019-04-09 14:44:32	DEBUG	Tokenization handler ==>> takens:['where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	lemmatization handler ==>> lemma_tokens:['where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:32	DEBUG	Ngram handler ==>> unigram:['where', 'are', 'you', 'now'] == bigram:['where are', 'are you', 'you now'] == trigram:['where are you', 'are you now']
2019-04-09 14:44:32	DEBUG	Punctuation handler ==>> text to process:tell me where are you now
2019-04-09 14:44:32	DEBUG	Tokenization handler ==>> takens:['tell', 'me', 'where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	Stemmer handler ==>> stem_tokens:['tell', 'me', 'where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	lemmatization handler ==>> lemma_tokens:['tell', 'me', 'where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:32	DEBUG	Ngram handler ==>> unigram:['tell', 'me', 'where', 'are', 'you', 'now'] == bigram:['tell me', 'me where', 'where are', 'are you', 'you now'] == trigram:['tell me where', 'me where are', 'where are you', 'are you now']
2019-04-09 14:44:32	DEBUG	Punctuation handler ==>> text to process:i would like to know where are you now
2019-04-09 14:44:32	DEBUG	Tokenization handler ==>> takens:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	lemmatization handler ==>> lemma_tokens:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:32	DEBUG	Ngram handler ==>> unigram:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] == bigram:['i would', 'would like', 'like to', 'to know', 'know where', 'where are', 'are you', 'you now'] == trigram:['i would like', 'would like to', 'like to know', 'to know where', 'know where are', 'where are you', 'are you now']
2019-04-09 14:44:32	DEBUG	Punctuation handler ==>> text to process:where are you now  please tell me
2019-04-09 14:44:32	DEBUG	Tokenization handler ==>> takens:['where', 'are', 'you', 'now', 'please', 'tell', 'me'] and tokenize_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'are', 'you', 'now', 'pleas', 'tell', 'me'] and stem_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	lemmatization handler ==>> lemma_tokens:['where', 'are', 'you', 'now', 'please', 'tell', 'me'] and lemma_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:32	DEBUG	Ngram handler ==>> unigram:['where', 'are', 'you', 'now', 'please', 'tell', 'me'] == bigram:['where are', 'are you', 'you now', 'now please', 'please tell', 'tell me'] == trigram:['where are you', 'are you now', 'you now please', 'now please tell', 'please tell me']
2019-04-09 14:44:32	DEBUG	Punctuation handler ==>> text to process:can you please tell me where are you now
2019-04-09 14:44:32	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'please', 'tell', 'me', 'where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'pleas', 'tell', 'me', 'where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	lemmatization handler ==>> lemma_tokens:['can', 'you', 'please', 'tell', 'me', 'where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:32	DEBUG	Ngram handler ==>> unigram:['can', 'you', 'please', 'tell', 'me', 'where', 'are', 'you', 'now'] == bigram:['can you', 'you please', 'please tell', 'tell me', 'me where', 'where are', 'are you', 'you now'] == trigram:['can you please', 'you please tell', 'please tell me', 'tell me where', 'me where are', 'where are you', 'are you now']
2019-04-09 14:44:32	DEBUG	Punctuation handler ==>> text to process:where can i find you
2019-04-09 14:44:32	DEBUG	Tokenization handler ==>> takens:['where', 'can', 'i', 'find', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'can', 'i', 'find', 'you'] and stem_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	lemmatization handler ==>> lemma_tokens:['where', 'can', 'i', 'find', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:32	DEBUG	Ngram handler ==>> unigram:['where', 'can', 'i', 'find', 'you'] == bigram:['where can', 'can i', 'i find', 'find you'] == trigram:['where can i', 'can i find', 'i find you']
2019-04-09 14:44:32	DEBUG	Punctuation handler ==>> text to process:can i meet you
2019-04-09 14:44:32	DEBUG	Tokenization handler ==>> takens:['can', 'i', 'meet', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'i', 'meet', 'you'] and stem_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	lemmatization handler ==>> lemma_tokens:['can', 'i', 'meet', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:32	DEBUG	Ngram handler ==>> unigram:['can', 'i', 'meet', 'you'] == bigram:['can i', 'i meet', 'meet you'] == trigram:['can i meet', 'i meet you']
2019-04-09 14:44:32	DEBUG	Punctuation handler ==>> text to process:can we meet
2019-04-09 14:44:32	DEBUG	Tokenization handler ==>> takens:['can', 'we', 'meet'] and tokenize_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'we', 'meet'] and stem_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	lemmatization handler ==>> lemma_tokens:['can', 'we', 'meet'] and lemma_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:32	DEBUG	Ngram handler ==>> unigram:['can', 'we', 'meet'] == bigram:['can we', 'we meet'] == trigram:['can we meet']
2019-04-09 14:44:32	DEBUG	Punctuation handler ==>> text to process:i would like to meet you
2019-04-09 14:44:32	DEBUG	Tokenization handler ==>> takens:['i', 'would', 'like', 'to', 'meet', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'would', 'like', 'to', 'meet', 'you'] and stem_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	lemmatization handler ==>> lemma_tokens:['i', 'would', 'like', 'to', 'meet', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:32	DEBUG	Ngram handler ==>> unigram:['i', 'would', 'like', 'to', 'meet', 'you'] == bigram:['i would', 'would like', 'like to', 'to meet', 'meet you'] == trigram:['i would like', 'would like to', 'like to meet', 'to meet you']
2019-04-09 14:44:32	DEBUG	Punctuation handler ==>> text to process:when can i meet you
2019-04-09 14:44:32	DEBUG	Tokenization handler ==>> takens:['when', 'can', 'i', 'meet', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	Stemmer handler ==>> stem_tokens:['when', 'can', 'i', 'meet', 'you'] and stem_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	lemmatization handler ==>> lemma_tokens:['when', 'can', 'i', 'meet', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:32	DEBUG	Ngram handler ==>> unigram:['when', 'can', 'i', 'meet', 'you'] == bigram:['when can', 'can i', 'i meet', 'meet you'] == trigram:['when can i', 'can i meet', 'i meet you']
2019-04-09 14:44:32	DEBUG	Punctuation handler ==>> text to process:when can we meet
2019-04-09 14:44:32	DEBUG	Tokenization handler ==>> takens:['when', 'can', 'we', 'meet'] and tokenize_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	Stemmer handler ==>> stem_tokens:['when', 'can', 'we', 'meet'] and stem_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	lemmatization handler ==>> lemma_tokens:['when', 'can', 'we', 'meet'] and lemma_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:32	DEBUG	Ngram handler ==>> unigram:['when', 'can', 'we', 'meet'] == bigram:['when can', 'can we', 'we meet'] == trigram:['when can we', 'can we meet']
2019-04-09 14:44:32	DEBUG	Punctuation handler ==>> text to process:when will we meet
2019-04-09 14:44:32	DEBUG	Tokenization handler ==>> takens:['when', 'will', 'we', 'meet'] and tokenize_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	Stemmer handler ==>> stem_tokens:['when', 'will', 'we', 'meet'] and stem_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	lemmatization handler ==>> lemma_tokens:['when', 'will', 'we', 'meet'] and lemma_without_stop_words:[]
2019-04-09 14:44:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:32	DEBUG	Ngram handler ==>> unigram:['when', 'will', 'we', 'meet'] == bigram:['when will', 'will we', 'we meet'] == trigram:['when will we', 'will we meet']
2019-04-09 14:44:44	DEBUG	Punctuation handler ==>> text to process:siapa nama kamu
2019-04-09 14:44:44	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:44	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'kamu'] == bigram:['siapa nama', 'nama kamu'] == trigram:['siapa nama kamu']
2019-04-09 14:44:44	DEBUG	Punctuation handler ==>> text to process:bagaimana aku memanggilmu
2019-04-09 14:44:44	DEBUG	Tokenization handler ==>> takens:['bagaimana', 'aku', 'memanggilmu'] and tokenize_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['bagaimana', 'aku', 'memanggilmu'] and stem_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:['bagaimana', 'aku', 'memanggilmu'] and lemma_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:44	DEBUG	Ngram handler ==>> unigram:['bagaimana', 'aku', 'memanggilmu'] == bigram:['bagaimana aku', 'aku memanggilmu'] == trigram:['bagaimana aku memanggilmu']
2019-04-09 14:44:44	DEBUG	Punctuation handler ==>> text to process:boleh tahu siapa nama kamu
2019-04-09 14:44:44	DEBUG	Tokenization handler ==>> takens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:44	DEBUG	Ngram handler ==>> unigram:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] == bigram:['boleh tahu', 'tahu siapa', 'siapa nama', 'nama kamu'] == trigram:['boleh tahu siapa', 'tahu siapa nama', 'siapa nama kamu']
2019-04-09 14:44:44	DEBUG	Punctuation handler ==>> text to process:siapa nama panggilan mu
2019-04-09 14:44:44	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'panggilan', 'mu'] and tokenize_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'panggilan', 'mu'] and stem_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'panggilan', 'mu'] and lemma_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:44	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'panggilan', 'mu'] == bigram:['siapa nama', 'nama panggilan', 'panggilan mu'] == trigram:['siapa nama panggilan', 'nama panggilan mu']
2019-04-09 14:44:44	DEBUG	Punctuation handler ==>> text to process:tolong kasih tahu nama kamu
2019-04-09 14:44:44	DEBUG	Tokenization handler ==>> takens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:44	DEBUG	Ngram handler ==>> unigram:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] == bigram:['tolong kasih', 'kasih tahu', 'tahu nama', 'nama kamu'] == trigram:['tolong kasih tahu', 'kasih tahu nama', 'tahu nama kamu']
2019-04-09 14:44:44	DEBUG	Punctuation handler ==>> text to process:kamu ingin dipanggil dengan nama apa
2019-04-09 14:44:44	DEBUG	Tokenization handler ==>> takens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and tokenize_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and stem_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and lemma_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:44	DEBUG	Ngram handler ==>> unigram:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] == bigram:['kamu ingin', 'ingin dipanggil', 'dipanggil dengan', 'dengan nama', 'nama apa'] == trigram:['kamu ingin dipanggil', 'ingin dipanggil dengan', 'dipanggil dengan nama', 'dengan nama apa']
2019-04-09 14:44:44	DEBUG	Punctuation handler ==>> text to process:whats your name
2019-04-09 14:44:44	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name'] and tokenize_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name'] and stem_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name'] and lemma_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:44	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name'] == bigram:['whats your', 'your name'] == trigram:['whats your name']
2019-04-09 14:44:44	DEBUG	Punctuation handler ==>> text to process:what can i call you
2019-04-09 14:44:44	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:44	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you'] == bigram:['what can', 'can i', 'i call', 'call you'] == trigram:['what can i', 'can i call', 'i call you']
2019-04-09 14:44:44	DEBUG	Punctuation handler ==>> text to process:may i know what your name is
2019-04-09 14:44:44	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and tokenize_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and stem_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and lemma_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:44	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is']
2019-04-09 14:44:44	DEBUG	Punctuation handler ==>> text to process:how can i call you
2019-04-09 14:44:44	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:44	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you'] == bigram:['how can', 'can i', 'i call', 'call you'] == trigram:['how can i', 'can i call', 'i call you']
2019-04-09 14:44:44	DEBUG	Punctuation handler ==>> text to process:what is your good name
2019-04-09 14:44:44	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name'] and tokenize_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name'] and stem_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name'] and lemma_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:44	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name'] == bigram:['what is', 'is your', 'your good', 'good name'] == trigram:['what is your', 'is your good', 'your good name']
2019-04-09 14:44:44	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called
2019-04-09 14:44:44	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and tokenize_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call'] and stem_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and lemma_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:44	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called']
2019-04-09 14:44:44	DEBUG	Punctuation handler ==>> text to process:where are you now
2019-04-09 14:44:44	DEBUG	Tokenization handler ==>> takens:['where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:['where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:44	DEBUG	Ngram handler ==>> unigram:['where', 'are', 'you', 'now'] == bigram:['where are', 'are you', 'you now'] == trigram:['where are you', 'are you now']
2019-04-09 14:44:44	DEBUG	Punctuation handler ==>> text to process:tell me where are you now
2019-04-09 14:44:44	DEBUG	Tokenization handler ==>> takens:['tell', 'me', 'where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['tell', 'me', 'where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:['tell', 'me', 'where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:44	DEBUG	Ngram handler ==>> unigram:['tell', 'me', 'where', 'are', 'you', 'now'] == bigram:['tell me', 'me where', 'where are', 'are you', 'you now'] == trigram:['tell me where', 'me where are', 'where are you', 'are you now']
2019-04-09 14:44:44	DEBUG	Punctuation handler ==>> text to process:i would like to know where are you now
2019-04-09 14:44:44	DEBUG	Tokenization handler ==>> takens:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:44	DEBUG	Ngram handler ==>> unigram:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] == bigram:['i would', 'would like', 'like to', 'to know', 'know where', 'where are', 'are you', 'you now'] == trigram:['i would like', 'would like to', 'like to know', 'to know where', 'know where are', 'where are you', 'are you now']
2019-04-09 14:44:44	DEBUG	Punctuation handler ==>> text to process:where are you now  please tell me
2019-04-09 14:44:44	DEBUG	Tokenization handler ==>> takens:['where', 'are', 'you', 'now', 'please', 'tell', 'me'] and tokenize_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'are', 'you', 'now', 'pleas', 'tell', 'me'] and stem_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:['where', 'are', 'you', 'now', 'please', 'tell', 'me'] and lemma_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:44	DEBUG	Ngram handler ==>> unigram:['where', 'are', 'you', 'now', 'please', 'tell', 'me'] == bigram:['where are', 'are you', 'you now', 'now please', 'please tell', 'tell me'] == trigram:['where are you', 'are you now', 'you now please', 'now please tell', 'please tell me']
2019-04-09 14:44:44	DEBUG	Punctuation handler ==>> text to process:can you please tell me where are you now
2019-04-09 14:44:44	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'please', 'tell', 'me', 'where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'pleas', 'tell', 'me', 'where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:['can', 'you', 'please', 'tell', 'me', 'where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:44	DEBUG	Ngram handler ==>> unigram:['can', 'you', 'please', 'tell', 'me', 'where', 'are', 'you', 'now'] == bigram:['can you', 'you please', 'please tell', 'tell me', 'me where', 'where are', 'are you', 'you now'] == trigram:['can you please', 'you please tell', 'please tell me', 'tell me where', 'me where are', 'where are you', 'are you now']
2019-04-09 14:44:44	DEBUG	Punctuation handler ==>> text to process:where can i find you
2019-04-09 14:44:44	DEBUG	Tokenization handler ==>> takens:['where', 'can', 'i', 'find', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'can', 'i', 'find', 'you'] and stem_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:['where', 'can', 'i', 'find', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:44	DEBUG	Ngram handler ==>> unigram:['where', 'can', 'i', 'find', 'you'] == bigram:['where can', 'can i', 'i find', 'find you'] == trigram:['where can i', 'can i find', 'i find you']
2019-04-09 14:44:44	DEBUG	Punctuation handler ==>> text to process:can i meet youok
2019-04-09 14:44:44	DEBUG	Tokenization handler ==>> takens:['can', 'i', 'meet', 'youok'] and tokenize_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'i', 'meet', 'youok'] and stem_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:['can', 'i', 'meet', 'youok'] and lemma_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:44	DEBUG	Ngram handler ==>> unigram:['can', 'i', 'meet', 'youok'] == bigram:['can i', 'i meet', 'meet youok'] == trigram:['can i meet', 'i meet youok']
2019-04-09 14:44:44	DEBUG	Punctuation handler ==>> text to process:can we meet
2019-04-09 14:44:44	DEBUG	Tokenization handler ==>> takens:['can', 'we', 'meet'] and tokenize_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'we', 'meet'] and stem_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:['can', 'we', 'meet'] and lemma_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:44	DEBUG	Ngram handler ==>> unigram:['can', 'we', 'meet'] == bigram:['can we', 'we meet'] == trigram:['can we meet']
2019-04-09 14:44:44	DEBUG	Punctuation handler ==>> text to process:i would like to meet you
2019-04-09 14:44:44	DEBUG	Tokenization handler ==>> takens:['i', 'would', 'like', 'to', 'meet', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'would', 'like', 'to', 'meet', 'you'] and stem_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:['i', 'would', 'like', 'to', 'meet', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:44	DEBUG	Ngram handler ==>> unigram:['i', 'would', 'like', 'to', 'meet', 'you'] == bigram:['i would', 'would like', 'like to', 'to meet', 'meet you'] == trigram:['i would like', 'would like to', 'like to meet', 'to meet you']
2019-04-09 14:44:44	DEBUG	Punctuation handler ==>> text to process:when can i meet you
2019-04-09 14:44:44	DEBUG	Tokenization handler ==>> takens:['when', 'can', 'i', 'meet', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['when', 'can', 'i', 'meet', 'you'] and stem_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:['when', 'can', 'i', 'meet', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:44	DEBUG	Ngram handler ==>> unigram:['when', 'can', 'i', 'meet', 'you'] == bigram:['when can', 'can i', 'i meet', 'meet you'] == trigram:['when can i', 'can i meet', 'i meet you']
2019-04-09 14:44:44	DEBUG	Punctuation handler ==>> text to process:when can we meet
2019-04-09 14:44:44	DEBUG	Tokenization handler ==>> takens:['when', 'can', 'we', 'meet'] and tokenize_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['when', 'can', 'we', 'meet'] and stem_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:['when', 'can', 'we', 'meet'] and lemma_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:44	DEBUG	Ngram handler ==>> unigram:['when', 'can', 'we', 'meet'] == bigram:['when can', 'can we', 'we meet'] == trigram:['when can we', 'can we meet']
2019-04-09 14:44:44	DEBUG	Punctuation handler ==>> text to process:when will we meet
2019-04-09 14:44:44	DEBUG	Tokenization handler ==>> takens:['when', 'will', 'we', 'meet'] and tokenize_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['when', 'will', 'we', 'meet'] and stem_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:['when', 'will', 'we', 'meet'] and lemma_without_stop_words:[]
2019-04-09 14:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:44:44	DEBUG	Ngram handler ==>> unigram:['when', 'will', 'we', 'meet'] == bigram:['when will', 'will we', 'we meet'] == trigram:['when will we', 'will we meet']
2019-04-09 14:45:21	DEBUG	Punctuation handler ==>> text to process:siapa nama kamu
2019-04-09 14:45:21	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:45:21	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'kamu'] == bigram:['siapa nama', 'nama kamu'] == trigram:['siapa nama kamu']
2019-04-09 14:45:21	DEBUG	Punctuation handler ==>> text to process:bagaimana aku memanggilmu
2019-04-09 14:45:21	DEBUG	Tokenization handler ==>> takens:['bagaimana', 'aku', 'memanggilmu'] and tokenize_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	Stemmer handler ==>> stem_tokens:['bagaimana', 'aku', 'memanggilmu'] and stem_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	lemmatization handler ==>> lemma_tokens:['bagaimana', 'aku', 'memanggilmu'] and lemma_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:45:21	DEBUG	Ngram handler ==>> unigram:['bagaimana', 'aku', 'memanggilmu'] == bigram:['bagaimana aku', 'aku memanggilmu'] == trigram:['bagaimana aku memanggilmu']
2019-04-09 14:45:21	DEBUG	Punctuation handler ==>> text to process:boleh tahu siapa nama kamu
2019-04-09 14:45:21	DEBUG	Tokenization handler ==>> takens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	Stemmer handler ==>> stem_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	lemmatization handler ==>> lemma_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:45:21	DEBUG	Ngram handler ==>> unigram:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] == bigram:['boleh tahu', 'tahu siapa', 'siapa nama', 'nama kamu'] == trigram:['boleh tahu siapa', 'tahu siapa nama', 'siapa nama kamu']
2019-04-09 14:45:21	DEBUG	Punctuation handler ==>> text to process:siapa nama panggilan mu
2019-04-09 14:45:21	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'panggilan', 'mu'] and tokenize_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'panggilan', 'mu'] and stem_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'panggilan', 'mu'] and lemma_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:45:21	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'panggilan', 'mu'] == bigram:['siapa nama', 'nama panggilan', 'panggilan mu'] == trigram:['siapa nama panggilan', 'nama panggilan mu']
2019-04-09 14:45:21	DEBUG	Punctuation handler ==>> text to process:tolong kasih tahu nama kamu
2019-04-09 14:45:21	DEBUG	Tokenization handler ==>> takens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	Stemmer handler ==>> stem_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	lemmatization handler ==>> lemma_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:45:21	DEBUG	Ngram handler ==>> unigram:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] == bigram:['tolong kasih', 'kasih tahu', 'tahu nama', 'nama kamu'] == trigram:['tolong kasih tahu', 'kasih tahu nama', 'tahu nama kamu']
2019-04-09 14:45:21	DEBUG	Punctuation handler ==>> text to process:kamu ingin dipanggil dengan nama apa
2019-04-09 14:45:21	DEBUG	Tokenization handler ==>> takens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and tokenize_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	Stemmer handler ==>> stem_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and stem_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	lemmatization handler ==>> lemma_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and lemma_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:45:21	DEBUG	Ngram handler ==>> unigram:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] == bigram:['kamu ingin', 'ingin dipanggil', 'dipanggil dengan', 'dengan nama', 'nama apa'] == trigram:['kamu ingin dipanggil', 'ingin dipanggil dengan', 'dipanggil dengan nama', 'dengan nama apa']
2019-04-09 14:45:21	DEBUG	Punctuation handler ==>> text to process:whats your name
2019-04-09 14:45:21	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name'] and tokenize_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name'] and stem_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name'] and lemma_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:45:21	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name'] == bigram:['whats your', 'your name'] == trigram:['whats your name']
2019-04-09 14:45:21	DEBUG	Punctuation handler ==>> text to process:what can i call you
2019-04-09 14:45:21	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:45:21	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you'] == bigram:['what can', 'can i', 'i call', 'call you'] == trigram:['what can i', 'can i call', 'i call you']
2019-04-09 14:45:21	DEBUG	Punctuation handler ==>> text to process:may i know what your name is
2019-04-09 14:45:21	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and tokenize_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and stem_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and lemma_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:45:21	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is']
2019-04-09 14:45:21	DEBUG	Punctuation handler ==>> text to process:how can i call you
2019-04-09 14:45:21	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:45:21	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you'] == bigram:['how can', 'can i', 'i call', 'call you'] == trigram:['how can i', 'can i call', 'i call you']
2019-04-09 14:45:21	DEBUG	Punctuation handler ==>> text to process:what is your good name
2019-04-09 14:45:21	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name'] and tokenize_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name'] and stem_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name'] and lemma_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:45:21	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name'] == bigram:['what is', 'is your', 'your good', 'good name'] == trigram:['what is your', 'is your good', 'your good name']
2019-04-09 14:45:21	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called
2019-04-09 14:45:21	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and tokenize_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call'] and stem_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and lemma_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:45:21	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called']
2019-04-09 14:45:21	DEBUG	Punctuation handler ==>> text to process:where are you now
2019-04-09 14:45:21	DEBUG	Tokenization handler ==>> takens:['where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	lemmatization handler ==>> lemma_tokens:['where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:45:21	DEBUG	Ngram handler ==>> unigram:['where', 'are', 'you', 'now'] == bigram:['where are', 'are you', 'you now'] == trigram:['where are you', 'are you now']
2019-04-09 14:45:21	DEBUG	Punctuation handler ==>> text to process:tell me where are you now
2019-04-09 14:45:21	DEBUG	Tokenization handler ==>> takens:['tell', 'me', 'where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	Stemmer handler ==>> stem_tokens:['tell', 'me', 'where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	lemmatization handler ==>> lemma_tokens:['tell', 'me', 'where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:45:21	DEBUG	Ngram handler ==>> unigram:['tell', 'me', 'where', 'are', 'you', 'now'] == bigram:['tell me', 'me where', 'where are', 'are you', 'you now'] == trigram:['tell me where', 'me where are', 'where are you', 'are you now']
2019-04-09 14:45:21	DEBUG	Punctuation handler ==>> text to process:i would like to know where are you now
2019-04-09 14:45:21	DEBUG	Tokenization handler ==>> takens:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	lemmatization handler ==>> lemma_tokens:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:45:21	DEBUG	Ngram handler ==>> unigram:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] == bigram:['i would', 'would like', 'like to', 'to know', 'know where', 'where are', 'are you', 'you now'] == trigram:['i would like', 'would like to', 'like to know', 'to know where', 'know where are', 'where are you', 'are you now']
2019-04-09 14:45:21	DEBUG	Punctuation handler ==>> text to process:where are you now  please tell me
2019-04-09 14:45:21	DEBUG	Tokenization handler ==>> takens:['where', 'are', 'you', 'now', 'please', 'tell', 'me'] and tokenize_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'are', 'you', 'now', 'pleas', 'tell', 'me'] and stem_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	lemmatization handler ==>> lemma_tokens:['where', 'are', 'you', 'now', 'please', 'tell', 'me'] and lemma_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:45:21	DEBUG	Ngram handler ==>> unigram:['where', 'are', 'you', 'now', 'please', 'tell', 'me'] == bigram:['where are', 'are you', 'you now', 'now please', 'please tell', 'tell me'] == trigram:['where are you', 'are you now', 'you now please', 'now please tell', 'please tell me']
2019-04-09 14:45:21	DEBUG	Punctuation handler ==>> text to process:can you please tell me where are you now
2019-04-09 14:45:21	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'please', 'tell', 'me', 'where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'pleas', 'tell', 'me', 'where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	lemmatization handler ==>> lemma_tokens:['can', 'you', 'please', 'tell', 'me', 'where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:45:21	DEBUG	Ngram handler ==>> unigram:['can', 'you', 'please', 'tell', 'me', 'where', 'are', 'you', 'now'] == bigram:['can you', 'you please', 'please tell', 'tell me', 'me where', 'where are', 'are you', 'you now'] == trigram:['can you please', 'you please tell', 'please tell me', 'tell me where', 'me where are', 'where are you', 'are you now']
2019-04-09 14:45:21	DEBUG	Punctuation handler ==>> text to process:where can i find you
2019-04-09 14:45:21	DEBUG	Tokenization handler ==>> takens:['where', 'can', 'i', 'find', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'can', 'i', 'find', 'you'] and stem_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	lemmatization handler ==>> lemma_tokens:['where', 'can', 'i', 'find', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:45:21	DEBUG	Ngram handler ==>> unigram:['where', 'can', 'i', 'find', 'you'] == bigram:['where can', 'can i', 'i find', 'find you'] == trigram:['where can i', 'can i find', 'i find you']
2019-04-09 14:45:21	DEBUG	Punctuation handler ==>> text to process:can i meet youok
2019-04-09 14:45:21	DEBUG	Tokenization handler ==>> takens:['can', 'i', 'meet', 'youok'] and tokenize_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'i', 'meet', 'youok'] and stem_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	lemmatization handler ==>> lemma_tokens:['can', 'i', 'meet', 'youok'] and lemma_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:45:21	DEBUG	Ngram handler ==>> unigram:['can', 'i', 'meet', 'youok'] == bigram:['can i', 'i meet', 'meet youok'] == trigram:['can i meet', 'i meet youok']
2019-04-09 14:45:21	DEBUG	Punctuation handler ==>> text to process:can we meet
2019-04-09 14:45:21	DEBUG	Tokenization handler ==>> takens:['can', 'we', 'meet'] and tokenize_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'we', 'meet'] and stem_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	lemmatization handler ==>> lemma_tokens:['can', 'we', 'meet'] and lemma_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:45:21	DEBUG	Ngram handler ==>> unigram:['can', 'we', 'meet'] == bigram:['can we', 'we meet'] == trigram:['can we meet']
2019-04-09 14:45:21	DEBUG	Punctuation handler ==>> text to process:i would like to meet you
2019-04-09 14:45:21	DEBUG	Tokenization handler ==>> takens:['i', 'would', 'like', 'to', 'meet', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'would', 'like', 'to', 'meet', 'you'] and stem_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	lemmatization handler ==>> lemma_tokens:['i', 'would', 'like', 'to', 'meet', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:45:21	DEBUG	Ngram handler ==>> unigram:['i', 'would', 'like', 'to', 'meet', 'you'] == bigram:['i would', 'would like', 'like to', 'to meet', 'meet you'] == trigram:['i would like', 'would like to', 'like to meet', 'to meet you']
2019-04-09 14:45:21	DEBUG	Punctuation handler ==>> text to process:when can i meet you
2019-04-09 14:45:21	DEBUG	Tokenization handler ==>> takens:['when', 'can', 'i', 'meet', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	Stemmer handler ==>> stem_tokens:['when', 'can', 'i', 'meet', 'you'] and stem_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	lemmatization handler ==>> lemma_tokens:['when', 'can', 'i', 'meet', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:45:21	DEBUG	Ngram handler ==>> unigram:['when', 'can', 'i', 'meet', 'you'] == bigram:['when can', 'can i', 'i meet', 'meet you'] == trigram:['when can i', 'can i meet', 'i meet you']
2019-04-09 14:45:21	DEBUG	Punctuation handler ==>> text to process:when can we meet
2019-04-09 14:45:21	DEBUG	Tokenization handler ==>> takens:['when', 'can', 'we', 'meet'] and tokenize_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	Stemmer handler ==>> stem_tokens:['when', 'can', 'we', 'meet'] and stem_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	lemmatization handler ==>> lemma_tokens:['when', 'can', 'we', 'meet'] and lemma_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:45:21	DEBUG	Ngram handler ==>> unigram:['when', 'can', 'we', 'meet'] == bigram:['when can', 'can we', 'we meet'] == trigram:['when can we', 'can we meet']
2019-04-09 14:45:21	DEBUG	Punctuation handler ==>> text to process:when will we meet
2019-04-09 14:45:21	DEBUG	Tokenization handler ==>> takens:['when', 'will', 'we', 'meet'] and tokenize_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	Stemmer handler ==>> stem_tokens:['when', 'will', 'we', 'meet'] and stem_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	lemmatization handler ==>> lemma_tokens:['when', 'will', 'we', 'meet'] and lemma_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:45:21	DEBUG	Ngram handler ==>> unigram:['when', 'will', 'we', 'meet'] == bigram:['when will', 'will we', 'we meet'] == trigram:['when will we', 'will we meet']
2019-04-09 14:45:21	DEBUG	Punctuation handler ==>> text to process:do you eat food
2019-04-09 14:45:21	DEBUG	Tokenization handler ==>> takens:['do', 'you', 'eat', 'food'] and tokenize_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	Stemmer handler ==>> stem_tokens:['do', 'you', 'eat', 'food'] and stem_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	lemmatization handler ==>> lemma_tokens:['do', 'you', 'eat', 'food'] and lemma_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:45:21	DEBUG	Ngram handler ==>> unigram:['do', 'you', 'eat', 'food'] == bigram:['do you', 'you eat', 'eat food'] == trigram:['do you eat', 'you eat food']
2019-04-09 14:45:21	DEBUG	Punctuation handler ==>> text to process:what food do you eat
2019-04-09 14:45:21	DEBUG	Tokenization handler ==>> takens:['what', 'food', 'do', 'you', 'eat'] and tokenize_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'food', 'do', 'you', 'eat'] and stem_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'food', 'do', 'you', 'eat'] and lemma_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:45:21	DEBUG	Ngram handler ==>> unigram:['what', 'food', 'do', 'you', 'eat'] == bigram:['what food', 'food do', 'do you', 'you eat'] == trigram:['what food do', 'food do you', 'do you eat']
2019-04-09 14:45:21	DEBUG	Punctuation handler ==>> text to process:what do you eat
2019-04-09 14:45:21	DEBUG	Tokenization handler ==>> takens:['what', 'do', 'you', 'eat'] and tokenize_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'do', 'you', 'eat'] and stem_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'do', 'you', 'eat'] and lemma_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:45:21	DEBUG	Ngram handler ==>> unigram:['what', 'do', 'you', 'eat'] == bigram:['what do', 'do you', 'you eat'] == trigram:['what do you', 'do you eat']
2019-04-09 14:45:21	DEBUG	Punctuation handler ==>> text to process:what do you eat for food
2019-04-09 14:45:21	DEBUG	Tokenization handler ==>> takens:['what', 'do', 'you', 'eat', 'for', 'food'] and tokenize_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'do', 'you', 'eat', 'for', 'food'] and stem_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'do', 'you', 'eat', 'for', 'food'] and lemma_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:45:21	DEBUG	Ngram handler ==>> unigram:['what', 'do', 'you', 'eat', 'for', 'food'] == bigram:['what do', 'do you', 'you eat', 'eat for', 'for food'] == trigram:['what do you', 'do you eat', 'you eat for', 'eat for food']
2019-04-09 14:45:21	DEBUG	Punctuation handler ==>> text to process:may i know what you eat
2019-04-09 14:45:21	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'you', 'eat'] and tokenize_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'you', 'eat'] and stem_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'you', 'eat'] and lemma_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:45:21	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'you', 'eat'] == bigram:['may i', 'i know', 'know what', 'what you', 'you eat'] == trigram:['may i know', 'i know what', 'know what you', 'what you eat']
2019-04-09 14:45:21	DEBUG	Punctuation handler ==>> text to process:what food you eat
2019-04-09 14:45:21	DEBUG	Tokenization handler ==>> takens:['what', 'food', 'you', 'eat'] and tokenize_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'food', 'you', 'eat'] and stem_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'food', 'you', 'eat'] and lemma_without_stop_words:[]
2019-04-09 14:45:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:45:21	DEBUG	Ngram handler ==>> unigram:['what', 'food', 'you', 'eat'] == bigram:['what food', 'food you', 'you eat'] == trigram:['what food you', 'food you eat']
2019-04-09 14:49:16	DEBUG	Punctuation handler ==>> text to process:siapa nama kamu
2019-04-09 14:49:16	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:49:16	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'kamu'] == bigram:['siapa nama', 'nama kamu'] == trigram:['siapa nama kamu']
2019-04-09 14:49:16	DEBUG	Punctuation handler ==>> text to process:bagaimana aku memanggilmu
2019-04-09 14:49:16	DEBUG	Tokenization handler ==>> takens:['bagaimana', 'aku', 'memanggilmu'] and tokenize_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	Stemmer handler ==>> stem_tokens:['bagaimana', 'aku', 'memanggilmu'] and stem_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	lemmatization handler ==>> lemma_tokens:['bagaimana', 'aku', 'memanggilmu'] and lemma_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:49:16	DEBUG	Ngram handler ==>> unigram:['bagaimana', 'aku', 'memanggilmu'] == bigram:['bagaimana aku', 'aku memanggilmu'] == trigram:['bagaimana aku memanggilmu']
2019-04-09 14:49:16	DEBUG	Punctuation handler ==>> text to process:boleh tahu siapa nama kamu
2019-04-09 14:49:16	DEBUG	Tokenization handler ==>> takens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	Stemmer handler ==>> stem_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	lemmatization handler ==>> lemma_tokens:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:49:16	DEBUG	Ngram handler ==>> unigram:['boleh', 'tahu', 'siapa', 'nama', 'kamu'] == bigram:['boleh tahu', 'tahu siapa', 'siapa nama', 'nama kamu'] == trigram:['boleh tahu siapa', 'tahu siapa nama', 'siapa nama kamu']
2019-04-09 14:49:16	DEBUG	Punctuation handler ==>> text to process:siapa nama panggilan mu
2019-04-09 14:49:16	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'panggilan', 'mu'] and tokenize_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'panggilan', 'mu'] and stem_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'panggilan', 'mu'] and lemma_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:49:16	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'panggilan', 'mu'] == bigram:['siapa nama', 'nama panggilan', 'panggilan mu'] == trigram:['siapa nama panggilan', 'nama panggilan mu']
2019-04-09 14:49:16	DEBUG	Punctuation handler ==>> text to process:tolong kasih tahu nama kamu
2019-04-09 14:49:16	DEBUG	Tokenization handler ==>> takens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	Stemmer handler ==>> stem_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	lemmatization handler ==>> lemma_tokens:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:49:16	DEBUG	Ngram handler ==>> unigram:['tolong', 'kasih', 'tahu', 'nama', 'kamu'] == bigram:['tolong kasih', 'kasih tahu', 'tahu nama', 'nama kamu'] == trigram:['tolong kasih tahu', 'kasih tahu nama', 'tahu nama kamu']
2019-04-09 14:49:16	DEBUG	Punctuation handler ==>> text to process:kamu ingin dipanggil dengan nama apa
2019-04-09 14:49:16	DEBUG	Tokenization handler ==>> takens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and tokenize_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	Stemmer handler ==>> stem_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and stem_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	lemmatization handler ==>> lemma_tokens:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] and lemma_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:49:16	DEBUG	Ngram handler ==>> unigram:['kamu', 'ingin', 'dipanggil', 'dengan', 'nama', 'apa'] == bigram:['kamu ingin', 'ingin dipanggil', 'dipanggil dengan', 'dengan nama', 'nama apa'] == trigram:['kamu ingin dipanggil', 'ingin dipanggil dengan', 'dipanggil dengan nama', 'dengan nama apa']
2019-04-09 14:49:16	DEBUG	Punctuation handler ==>> text to process:whats your name
2019-04-09 14:49:16	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name'] and tokenize_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name'] and stem_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name'] and lemma_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:49:16	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name'] == bigram:['whats your', 'your name'] == trigram:['whats your name']
2019-04-09 14:49:16	DEBUG	Punctuation handler ==>> text to process:what can i call you
2019-04-09 14:49:16	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:49:16	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you'] == bigram:['what can', 'can i', 'i call', 'call you'] == trigram:['what can i', 'can i call', 'i call you']
2019-04-09 14:49:16	DEBUG	Punctuation handler ==>> text to process:may i know what your name is
2019-04-09 14:49:16	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and tokenize_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and stem_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is'] and lemma_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:49:16	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is']
2019-04-09 14:49:16	DEBUG	Punctuation handler ==>> text to process:how can i call you
2019-04-09 14:49:16	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you'] and stem_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:49:16	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you'] == bigram:['how can', 'can i', 'i call', 'call you'] == trigram:['how can i', 'can i call', 'i call you']
2019-04-09 14:49:16	DEBUG	Punctuation handler ==>> text to process:what is your good name
2019-04-09 14:49:16	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name'] and tokenize_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name'] and stem_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name'] and lemma_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:49:16	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name'] == bigram:['what is', 'is your', 'your good', 'good name'] == trigram:['what is your', 'is your good', 'your good name']
2019-04-09 14:49:16	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called
2019-04-09 14:49:16	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and tokenize_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call'] and stem_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] and lemma_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:49:16	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called']
2019-04-09 14:49:16	DEBUG	Punctuation handler ==>> text to process:where are you now
2019-04-09 14:49:16	DEBUG	Tokenization handler ==>> takens:['where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	lemmatization handler ==>> lemma_tokens:['where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:49:16	DEBUG	Ngram handler ==>> unigram:['where', 'are', 'you', 'now'] == bigram:['where are', 'are you', 'you now'] == trigram:['where are you', 'are you now']
2019-04-09 14:49:16	DEBUG	Punctuation handler ==>> text to process:tell me where are you now
2019-04-09 14:49:16	DEBUG	Tokenization handler ==>> takens:['tell', 'me', 'where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	Stemmer handler ==>> stem_tokens:['tell', 'me', 'where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	lemmatization handler ==>> lemma_tokens:['tell', 'me', 'where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:49:16	DEBUG	Ngram handler ==>> unigram:['tell', 'me', 'where', 'are', 'you', 'now'] == bigram:['tell me', 'me where', 'where are', 'are you', 'you now'] == trigram:['tell me where', 'me where are', 'where are you', 'are you now']
2019-04-09 14:49:16	DEBUG	Punctuation handler ==>> text to process:i would like to know where are you now
2019-04-09 14:49:16	DEBUG	Tokenization handler ==>> takens:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	lemmatization handler ==>> lemma_tokens:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:49:16	DEBUG	Ngram handler ==>> unigram:['i', 'would', 'like', 'to', 'know', 'where', 'are', 'you', 'now'] == bigram:['i would', 'would like', 'like to', 'to know', 'know where', 'where are', 'are you', 'you now'] == trigram:['i would like', 'would like to', 'like to know', 'to know where', 'know where are', 'where are you', 'are you now']
2019-04-09 14:49:16	DEBUG	Punctuation handler ==>> text to process:where are you now  please tell me
2019-04-09 14:49:16	DEBUG	Tokenization handler ==>> takens:['where', 'are', 'you', 'now', 'please', 'tell', 'me'] and tokenize_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'are', 'you', 'now', 'pleas', 'tell', 'me'] and stem_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	lemmatization handler ==>> lemma_tokens:['where', 'are', 'you', 'now', 'please', 'tell', 'me'] and lemma_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:49:16	DEBUG	Ngram handler ==>> unigram:['where', 'are', 'you', 'now', 'please', 'tell', 'me'] == bigram:['where are', 'are you', 'you now', 'now please', 'please tell', 'tell me'] == trigram:['where are you', 'are you now', 'you now please', 'now please tell', 'please tell me']
2019-04-09 14:49:16	DEBUG	Punctuation handler ==>> text to process:can you please tell me where are you now
2019-04-09 14:49:16	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'please', 'tell', 'me', 'where', 'are', 'you', 'now'] and tokenize_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'pleas', 'tell', 'me', 'where', 'are', 'you', 'now'] and stem_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	lemmatization handler ==>> lemma_tokens:['can', 'you', 'please', 'tell', 'me', 'where', 'are', 'you', 'now'] and lemma_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:49:16	DEBUG	Ngram handler ==>> unigram:['can', 'you', 'please', 'tell', 'me', 'where', 'are', 'you', 'now'] == bigram:['can you', 'you please', 'please tell', 'tell me', 'me where', 'where are', 'are you', 'you now'] == trigram:['can you please', 'you please tell', 'please tell me', 'tell me where', 'me where are', 'where are you', 'are you now']
2019-04-09 14:49:16	DEBUG	Punctuation handler ==>> text to process:where can i find you
2019-04-09 14:49:16	DEBUG	Tokenization handler ==>> takens:['where', 'can', 'i', 'find', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'can', 'i', 'find', 'you'] and stem_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	lemmatization handler ==>> lemma_tokens:['where', 'can', 'i', 'find', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:49:16	DEBUG	Ngram handler ==>> unigram:['where', 'can', 'i', 'find', 'you'] == bigram:['where can', 'can i', 'i find', 'find you'] == trigram:['where can i', 'can i find', 'i find you']
2019-04-09 14:49:16	DEBUG	Punctuation handler ==>> text to process:can i meet youok
2019-04-09 14:49:16	DEBUG	Tokenization handler ==>> takens:['can', 'i', 'meet', 'youok'] and tokenize_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'i', 'meet', 'youok'] and stem_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	lemmatization handler ==>> lemma_tokens:['can', 'i', 'meet', 'youok'] and lemma_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:49:16	DEBUG	Ngram handler ==>> unigram:['can', 'i', 'meet', 'youok'] == bigram:['can i', 'i meet', 'meet youok'] == trigram:['can i meet', 'i meet youok']
2019-04-09 14:49:16	DEBUG	Punctuation handler ==>> text to process:can we meet
2019-04-09 14:49:16	DEBUG	Tokenization handler ==>> takens:['can', 'we', 'meet'] and tokenize_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'we', 'meet'] and stem_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	lemmatization handler ==>> lemma_tokens:['can', 'we', 'meet'] and lemma_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:49:16	DEBUG	Ngram handler ==>> unigram:['can', 'we', 'meet'] == bigram:['can we', 'we meet'] == trigram:['can we meet']
2019-04-09 14:49:16	DEBUG	Punctuation handler ==>> text to process:i would like to meet you
2019-04-09 14:49:16	DEBUG	Tokenization handler ==>> takens:['i', 'would', 'like', 'to', 'meet', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'would', 'like', 'to', 'meet', 'you'] and stem_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	lemmatization handler ==>> lemma_tokens:['i', 'would', 'like', 'to', 'meet', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:49:16	DEBUG	Ngram handler ==>> unigram:['i', 'would', 'like', 'to', 'meet', 'you'] == bigram:['i would', 'would like', 'like to', 'to meet', 'meet you'] == trigram:['i would like', 'would like to', 'like to meet', 'to meet you']
2019-04-09 14:49:16	DEBUG	Punctuation handler ==>> text to process:when can i meet you
2019-04-09 14:49:16	DEBUG	Tokenization handler ==>> takens:['when', 'can', 'i', 'meet', 'you'] and tokenize_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	Stemmer handler ==>> stem_tokens:['when', 'can', 'i', 'meet', 'you'] and stem_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	lemmatization handler ==>> lemma_tokens:['when', 'can', 'i', 'meet', 'you'] and lemma_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:49:16	DEBUG	Ngram handler ==>> unigram:['when', 'can', 'i', 'meet', 'you'] == bigram:['when can', 'can i', 'i meet', 'meet you'] == trigram:['when can i', 'can i meet', 'i meet you']
2019-04-09 14:49:16	DEBUG	Punctuation handler ==>> text to process:when can we meet
2019-04-09 14:49:16	DEBUG	Tokenization handler ==>> takens:['when', 'can', 'we', 'meet'] and tokenize_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	Stemmer handler ==>> stem_tokens:['when', 'can', 'we', 'meet'] and stem_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	lemmatization handler ==>> lemma_tokens:['when', 'can', 'we', 'meet'] and lemma_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:49:16	DEBUG	Ngram handler ==>> unigram:['when', 'can', 'we', 'meet'] == bigram:['when can', 'can we', 'we meet'] == trigram:['when can we', 'can we meet']
2019-04-09 14:49:16	DEBUG	Punctuation handler ==>> text to process:when will we meet
2019-04-09 14:49:16	DEBUG	Tokenization handler ==>> takens:['when', 'will', 'we', 'meet'] and tokenize_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	Stemmer handler ==>> stem_tokens:['when', 'will', 'we', 'meet'] and stem_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	lemmatization handler ==>> lemma_tokens:['when', 'will', 'we', 'meet'] and lemma_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:49:16	DEBUG	Ngram handler ==>> unigram:['when', 'will', 'we', 'meet'] == bigram:['when will', 'will we', 'we meet'] == trigram:['when will we', 'will we meet']
2019-04-09 14:49:16	DEBUG	Punctuation handler ==>> text to process:do you eat food
2019-04-09 14:49:16	DEBUG	Tokenization handler ==>> takens:['do', 'you', 'eat', 'food'] and tokenize_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	Stemmer handler ==>> stem_tokens:['do', 'you', 'eat', 'food'] and stem_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	lemmatization handler ==>> lemma_tokens:['do', 'you', 'eat', 'food'] and lemma_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:49:16	DEBUG	Ngram handler ==>> unigram:['do', 'you', 'eat', 'food'] == bigram:['do you', 'you eat', 'eat food'] == trigram:['do you eat', 'you eat food']
2019-04-09 14:49:16	DEBUG	Punctuation handler ==>> text to process:what food do you eat
2019-04-09 14:49:16	DEBUG	Tokenization handler ==>> takens:['what', 'food', 'do', 'you', 'eat'] and tokenize_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'food', 'do', 'you', 'eat'] and stem_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'food', 'do', 'you', 'eat'] and lemma_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:49:16	DEBUG	Ngram handler ==>> unigram:['what', 'food', 'do', 'you', 'eat'] == bigram:['what food', 'food do', 'do you', 'you eat'] == trigram:['what food do', 'food do you', 'do you eat']
2019-04-09 14:49:16	DEBUG	Punctuation handler ==>> text to process:what do you eat
2019-04-09 14:49:16	DEBUG	Tokenization handler ==>> takens:['what', 'do', 'you', 'eat'] and tokenize_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'do', 'you', 'eat'] and stem_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'do', 'you', 'eat'] and lemma_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:49:16	DEBUG	Ngram handler ==>> unigram:['what', 'do', 'you', 'eat'] == bigram:['what do', 'do you', 'you eat'] == trigram:['what do you', 'do you eat']
2019-04-09 14:49:16	DEBUG	Punctuation handler ==>> text to process:what do you eat for food
2019-04-09 14:49:16	DEBUG	Tokenization handler ==>> takens:['what', 'do', 'you', 'eat', 'for', 'food'] and tokenize_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'do', 'you', 'eat', 'for', 'food'] and stem_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'do', 'you', 'eat', 'for', 'food'] and lemma_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:49:16	DEBUG	Ngram handler ==>> unigram:['what', 'do', 'you', 'eat', 'for', 'food'] == bigram:['what do', 'do you', 'you eat', 'eat for', 'for food'] == trigram:['what do you', 'do you eat', 'you eat for', 'eat for food']
2019-04-09 14:49:16	DEBUG	Punctuation handler ==>> text to process:may i know what you eat
2019-04-09 14:49:16	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'you', 'eat'] and tokenize_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'you', 'eat'] and stem_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'you', 'eat'] and lemma_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:49:16	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'you', 'eat'] == bigram:['may i', 'i know', 'know what', 'what you', 'you eat'] == trigram:['may i know', 'i know what', 'know what you', 'what you eat']
2019-04-09 14:49:16	DEBUG	Punctuation handler ==>> text to process:what food you eat
2019-04-09 14:49:16	DEBUG	Tokenization handler ==>> takens:['what', 'food', 'you', 'eat'] and tokenize_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'food', 'you', 'eat'] and stem_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'food', 'you', 'eat'] and lemma_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:49:16	DEBUG	Ngram handler ==>> unigram:['what', 'food', 'you', 'eat'] == bigram:['what food', 'food you', 'you eat'] == trigram:['what food you', 'food you eat']
2019-04-09 14:49:16	DEBUG	Punctuation handler ==>> text to process:dvg
2019-04-09 14:49:16	DEBUG	Tokenization handler ==>> takens:['dvg'] and tokenize_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	Stemmer handler ==>> stem_tokens:['dvg'] and stem_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	lemmatization handler ==>> lemma_tokens:['dvg'] and lemma_without_stop_words:[]
2019-04-09 14:49:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 14:49:16	DEBUG	Ngram handler ==>> unigram:['dvg'] == bigram:[] == trigram:[]
2019-04-09 15:53:29	DEBUG	Punctuation handler ==>> text to process:aimana aku memanggilmu
2019-04-09 15:53:29	DEBUG	Tokenization handler ==>> takens:['aimana', 'aku', 'memanggilmu'] and tokenize_without_stop_words:[]
2019-04-09 15:53:29	DEBUG	Stemmer handler ==>> stem_tokens:['aimana', 'aku', 'memanggilmu'] and stem_without_stop_words:[]
2019-04-09 15:53:33	DEBUG	lemmatization handler ==>> lemma_tokens:['aimana', 'aku', 'memanggilmu'] and lemma_without_stop_words:[]
2019-04-09 15:53:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 15:53:33	DEBUG	Ngram handler ==>> unigram:['aimana', 'aku', 'memanggilmu'] == bigram:['aimana aku', 'aku memanggilmu'] == trigram:['aimana aku memanggilmu']
2019-04-09 15:54:05	DEBUG	Punctuation handler ==>> text to process:siapa nama kamu
2019-04-09 15:54:05	DEBUG	Tokenization handler ==>> takens:['siapa', 'nama', 'kamu'] and tokenize_without_stop_words:[]
2019-04-09 15:54:05	DEBUG	Stemmer handler ==>> stem_tokens:['siapa', 'nama', 'kamu'] and stem_without_stop_words:[]
2019-04-09 15:54:05	DEBUG	lemmatization handler ==>> lemma_tokens:['siapa', 'nama', 'kamu'] and lemma_without_stop_words:[]
2019-04-09 15:54:05	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-09 15:54:05	DEBUG	Ngram handler ==>> unigram:['siapa', 'nama', 'kamu'] == bigram:['siapa nama', 'nama kamu'] == trigram:['siapa nama kamu']
2019-04-23 10:46:27	DEBUG	Punctuation handler ==>> text to process:whats your name
2019-04-23 10:46:27	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name'] and tokenize_without_stop_words:[]
2019-04-23 10:46:27	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name'] and stem_without_stop_words:[]
2019-04-23 10:46:31	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name'] and lemma_without_stop_words:[]
2019-04-23 10:46:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-23 10:46:31	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name'] == bigram:['whats your', 'your name'] == trigram:['whats your name']
2019-04-23 19:11:06	DEBUG	Punctuation handler ==>> text to process:????
2019-04-23 19:11:06	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-23 19:11:06	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-04-23 19:11:09	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-04-23 19:11:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-23 19:11:09	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-04-23 19:11:13	DEBUG	Punctuation handler ==>> text to process:???
2019-04-23 19:11:13	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-23 19:11:13	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-04-23 19:11:13	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-04-23 19:11:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-23 19:11:13	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-04-23 19:11:37	DEBUG	Punctuation handler ==>> text to process:????
2019-04-23 19:11:37	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-23 19:11:37	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-04-23 19:11:37	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-04-23 19:11:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-23 19:11:37	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-04-23 19:11:38	DEBUG	Punctuation handler ==>> text to process:???
2019-04-23 19:11:38	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-23 19:11:38	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-04-23 19:11:38	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-04-23 19:11:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-23 19:11:38	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-04-23 19:12:28	DEBUG	Punctuation handler ==>> text to process:????
2019-04-23 19:12:28	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-23 19:12:28	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-04-23 19:12:31	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-04-23 19:12:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-23 19:12:31	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-04-23 19:12:31	DEBUG	Punctuation handler ==>> text to process:???
2019-04-23 19:12:31	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-23 19:12:31	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-04-23 19:12:31	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-04-23 19:12:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-23 19:12:31	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-04-23 19:12:31	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-04-23 19:12:31	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-04-23 19:12:31	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-04-23 19:12:31	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-04-23 19:12:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-23 19:12:31	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-04-23 19:12:31	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-04-23 19:12:31	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-04-23 19:12:31	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-04-23 19:12:31	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-04-23 19:12:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-23 19:12:31	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-04-23 19:12:31	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-04-23 19:12:31	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-04-23 19:12:31	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-04-23 19:12:31	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-04-23 19:12:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-23 19:12:31	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-04-23 19:12:31	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-04-23 19:12:31	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-04-23 19:12:31	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-04-23 19:12:31	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-04-23 19:12:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-23 19:12:31	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-04-23 19:12:31	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-04-23 19:12:31	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-04-23 19:12:31	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-04-23 19:12:31	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-04-23 19:12:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-23 19:12:31	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-04-23 19:12:31	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-04-23 19:12:31	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-04-23 19:12:31	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-04-23 19:12:31	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-04-23 19:12:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-23 19:12:31	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-04-23 19:17:25	DEBUG	Punctuation handler ==>> text to process:
2019-04-23 19:17:25	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-23 19:17:25	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-23 19:17:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-23 19:17:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-23 19:17:25	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-23 19:17:26	DEBUG	Punctuation handler ==>> text to process:???
2019-04-23 19:17:26	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-23 19:17:26	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-04-23 19:17:26	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-04-23 19:17:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-23 19:17:26	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-04-24 10:05:38	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 10:05:38	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 10:05:38	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 10:05:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 10:05:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 10:05:38	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 10:05:39	DEBUG	Punctuation handler ==>> text to process:???
2019-04-24 10:05:39	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-24 10:05:39	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-04-24 10:05:42	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-04-24 10:05:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 10:05:42	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-04-24 10:06:30	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 10:06:31	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 10:06:31	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 10:06:32	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 10:06:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 10:06:33	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 10:07:03	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 10:07:03	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 10:07:03	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 10:07:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 10:07:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 10:07:03	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 10:07:03	DEBUG	Punctuation handler ==>> text to process:????
2019-04-24 10:07:03	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-24 10:07:03	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-04-24 10:07:08	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-04-24 10:07:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 10:07:08	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-04-24 10:08:01	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 10:08:02	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 10:08:02	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 10:08:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 10:08:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 10:08:03	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 10:08:04	DEBUG	Punctuation handler ==>> text to process:????
2019-04-24 10:08:06	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-24 10:08:07	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-04-24 10:08:11	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-04-24 10:08:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 10:08:13	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-04-24 10:09:42	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 10:09:43	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 10:09:43	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 10:09:44	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 10:09:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 10:09:50	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 10:11:43	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 10:11:43	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 10:11:43	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 10:11:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 10:11:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 10:11:43	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 10:12:06	DEBUG	Punctuation handler ==>> text to process:???
2019-04-24 10:12:10	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-24 10:12:10	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-04-24 10:12:14	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-04-24 10:12:14	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 10:12:14	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-04-24 10:13:15	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 10:13:15	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 10:13:15	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 10:13:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 10:13:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 10:13:15	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 10:13:25	DEBUG	Punctuation handler ==>> text to process:???
2019-04-24 10:13:25	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-24 10:13:25	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-04-24 10:13:25	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-04-24 10:13:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 10:13:25	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-04-24 10:13:59	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 10:13:59	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 10:13:59	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 10:13:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 10:13:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 10:13:59	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 10:14:25	DEBUG	Punctuation handler ==>> text to process:???
2019-04-24 10:14:25	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-24 10:14:25	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-04-24 10:14:54	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 10:14:56	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 10:14:57	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 10:14:58	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 10:14:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 10:15:00	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 10:15:14	DEBUG	Punctuation handler ==>> text to process:???
2019-04-24 10:15:20	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-24 10:15:21	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-04-24 10:15:25	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-04-24 10:15:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 10:15:28	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-04-24 10:17:58	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 10:17:58	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 10:17:58	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 10:17:58	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 10:17:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 10:17:58	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 10:17:58	DEBUG	Punctuation handler ==>> text to process:???
2019-04-24 10:17:59	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-24 10:17:59	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-04-24 10:18:02	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-04-24 10:18:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 10:18:03	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-04-24 10:21:36	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 10:21:36	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 10:21:36	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 10:21:36	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 10:21:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 10:21:36	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 10:21:36	DEBUG	Punctuation handler ==>> text to process:????
2019-04-24 10:21:36	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-24 10:21:36	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-04-24 10:21:40	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-04-24 10:21:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 10:21:40	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-04-24 10:21:40	DEBUG	Punctuation handler ==>> text to process:????
2019-04-24 10:21:40	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-24 10:21:40	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-04-24 10:21:40	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-04-24 10:21:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 10:21:40	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-04-24 10:23:17	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 10:23:17	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 10:23:17	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 10:23:17	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 10:23:17	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 10:23:17	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 10:23:17	DEBUG	Punctuation handler ==>> text to process:?????
2019-04-24 10:23:17	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-24 10:23:17	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?', '?'] and stem_without_stop_words:[]
2019-04-24 10:23:21	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-04-24 10:23:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 10:23:21	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?', '? ? ?']
2019-04-24 10:23:21	DEBUG	Punctuation handler ==>> text to process:?????
2019-04-24 10:23:21	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-24 10:23:21	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?', '?'] and stem_without_stop_words:[]
2019-04-24 10:23:21	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-04-24 10:23:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 10:23:21	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?', '? ? ?']
2019-04-24 10:23:46	DEBUG	Punctuation handler ==>> text to process:shows 
2019-04-24 10:23:46	DEBUG	Tokenization handler ==>> takens:['shows'] and tokenize_without_stop_words:[]
2019-04-24 10:23:46	DEBUG	Stemmer handler ==>> stem_tokens:['show'] and stem_without_stop_words:[]
2019-04-24 10:23:46	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 10:23:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 10:23:46	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 10:23:46	DEBUG	Punctuation handler ==>> text to process:shows ???
2019-04-24 10:23:46	DEBUG	Tokenization handler ==>> takens:['shows', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-24 10:23:46	DEBUG	Stemmer handler ==>> stem_tokens:['show', '?', '?', '?'] and stem_without_stop_words:[]
2019-04-24 10:23:46	DEBUG	lemmatization handler ==>> lemma_tokens:['show', '?', '?', '?'] and lemma_without_stop_words:[]
2019-04-24 10:23:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 10:23:46	DEBUG	Ngram handler ==>> unigram:['shows', '?', '?', '?'] == bigram:['shows ?', '? ?', '? ?'] == trigram:['shows ? ?', '? ? ?']
2019-04-24 10:23:46	DEBUG	Punctuation handler ==>> text to process:shows ???
2019-04-24 10:23:46	DEBUG	Tokenization handler ==>> takens:['shows', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-24 10:23:46	DEBUG	Stemmer handler ==>> stem_tokens:['show', '?', '?', '?'] and stem_without_stop_words:[]
2019-04-24 10:23:46	DEBUG	lemmatization handler ==>> lemma_tokens:['show', '?', '?', '?'] and lemma_without_stop_words:[]
2019-04-24 10:23:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 10:23:46	DEBUG	Ngram handler ==>> unigram:['shows', '?', '?', '?'] == bigram:['shows ?', '? ?', '? ?'] == trigram:['shows ? ?', '? ? ?']
2019-04-24 10:33:09	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 10:33:09	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 10:33:09	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 10:33:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 10:33:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 10:33:09	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 10:33:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 10:33:09	DEBUG	Punctuation handler ==>> text to process:????
2019-04-24 10:33:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 10:33:09	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-24 10:33:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 10:33:09	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-04-24 10:33:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 10:33:13	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-04-24 10:33:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 10:33:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 10:33:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 10:33:13	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-04-24 11:36:27	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 11:36:27	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 11:36:27	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 11:36:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 11:36:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 11:36:27	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 11:36:27	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 11:36:27	DEBUG	Punctuation handler ==>> text to process:????
2019-04-24 11:36:27	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 11:36:27	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-24 11:36:27	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 11:36:27	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-04-24 11:36:27	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 11:36:31	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-04-24 11:36:31	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 11:36:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 11:36:31	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 11:36:31	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-04-24 11:36:36	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 11:36:36	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 11:36:36	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 11:36:36	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 11:36:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 11:36:36	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 11:36:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 11:36:37	DEBUG	Punctuation handler ==>> text to process:???
2019-04-24 11:36:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 11:36:37	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-24 11:36:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 11:36:37	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-04-24 11:36:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 11:36:37	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-04-24 11:36:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 11:36:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 11:36:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 11:36:37	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-04-24 11:41:45	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 11:41:45	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 11:41:45	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 11:41:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 11:41:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 11:41:45	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 11:41:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 11:41:46	DEBUG	Punctuation handler ==>> text to process:????
2019-04-24 11:41:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 11:41:46	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-24 11:41:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 11:41:46	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-04-24 11:41:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 11:41:46	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-04-24 11:41:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 11:41:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 11:41:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 11:41:46	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-04-24 11:47:18	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 11:47:18	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 11:47:18	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 11:47:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 11:47:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 11:47:18	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 11:48:51	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 11:48:51	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 11:48:51	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 11:48:51	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 11:48:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 11:48:51	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 11:49:09	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 11:49:09	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 11:49:09	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 11:49:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 11:49:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 11:49:09	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 11:49:22	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 11:49:22	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 11:49:22	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 11:49:22	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 11:49:22	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 11:49:22	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 11:50:26	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-04-24 11:50:26	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-04-24 11:50:26	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-04-24 11:50:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 11:50:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 11:50:26	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-04-24 11:51:49	DEBUG	Punctuation handler ==>> text to process:hello
2019-04-24 11:51:49	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-04-24 11:51:49	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-04-24 11:51:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 11:51:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 11:51:49	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-04-24 11:58:17	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 11:58:17	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 11:58:17	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 11:58:17	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 11:58:17	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 11:58:17	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 11:58:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 11:58:18	DEBUG	Punctuation handler ==>> text to process:???
2019-04-24 11:58:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 11:58:18	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-24 11:58:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 11:58:18	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-04-24 11:58:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 11:58:21	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-04-24 11:58:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 11:58:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 11:58:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 11:58:21	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-04-24 12:28:47	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 12:28:47	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 12:28:47	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 12:28:47	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 12:28:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 12:28:47	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 12:28:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 12:28:48	DEBUG	Punctuation handler ==>> text to process:????
2019-04-24 12:28:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 12:28:48	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-24 12:28:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 12:28:48	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-04-24 12:28:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 12:28:52	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-04-24 12:28:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 12:28:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 12:28:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 12:28:52	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-04-24 12:29:03	DEBUG	Punctuation handler ==>> text to process:can you recharg
2019-04-24 12:29:03	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharg'] and tokenize_without_stop_words:[]
2019-04-24 12:29:03	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg'] and stem_without_stop_words:[]
2019-04-24 12:29:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 12:29:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 12:29:03	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['you recharg'] == trigram:['can you recharg']
2019-04-24 12:32:49	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 12:32:49	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 12:32:49	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 12:32:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 12:32:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 12:32:49	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 12:32:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 12:32:50	DEBUG	Punctuation handler ==>> text to process:???
2019-04-24 12:32:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 12:32:50	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-24 12:32:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 12:32:50	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-04-24 12:32:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 12:32:53	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-04-24 12:32:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 12:32:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 12:32:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 12:32:53	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-04-24 13:53:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:55	DEBUG	Punctuation handler ==>> text to process:????
2019-04-24 13:53:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:56	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-24 13:53:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:56	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-04-24 13:53:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Punctuation handler ==>> text to process:???
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Punctuation handler ==>> text to process:()
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Tokenization handler ==>> takens:['(', ')'] and tokenize_without_stop_words:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')'] and stem_without_stop_words:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')'] and lemma_without_stop_words:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Ngram handler ==>> unigram:['(', ')'] == bigram:['( )'] == trigram:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:53:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:53:58	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-04-24 13:54:42	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 13:54:42	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 13:54:42	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 13:54:42	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 13:54:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:54:42	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 13:54:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:54:42	DEBUG	Punctuation handler ==>> text to process:?
2019-04-24 13:54:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:54:42	DEBUG	Tokenization handler ==>> takens:['?'] and tokenize_without_stop_words:[]
2019-04-24 13:54:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:54:42	DEBUG	Stemmer handler ==>> stem_tokens:['?'] and stem_without_stop_words:[]
2019-04-24 13:54:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:54:42	DEBUG	lemmatization handler ==>> lemma_tokens:['?'] and lemma_without_stop_words:[]
2019-04-24 13:54:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:54:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:54:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:54:42	DEBUG	Ngram handler ==>> unigram:['?'] == bigram:[] == trigram:[]
2019-04-24 13:54:52	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 13:54:52	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 13:54:52	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 13:54:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 13:54:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:54:52	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 13:54:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:54:53	DEBUG	Punctuation handler ==>> text to process:???
2019-04-24 13:54:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:54:53	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-24 13:54:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:54:53	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-04-24 13:54:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:54:53	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-04-24 13:54:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:54:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:54:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:54:53	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-04-24 13:54:57	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 13:54:57	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 13:54:57	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 13:54:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 13:54:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:54:57	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 13:54:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:54:57	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-04-24 13:54:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:54:57	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-04-24 13:54:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:54:57	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-04-24 13:54:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:54:57	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-04-24 13:54:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:54:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:54:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:54:57	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-04-24 13:55:05	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 13:55:05	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 13:55:05	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 13:55:05	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 13:55:05	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:55:05	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 13:55:05	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:55:05	DEBUG	Punctuation handler ==>> text to process:@@
2019-04-24 13:55:05	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:55:05	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-04-24 13:55:05	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:55:05	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-04-24 13:55:05	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:55:05	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-04-24 13:55:05	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:55:05	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:55:05	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:55:05	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-04-24 13:55:27	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 13:55:27	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 13:55:27	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 13:55:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 13:55:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:55:27	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 13:55:27	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:55:27	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-04-24 13:55:27	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:55:27	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-04-24 13:55:27	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:55:27	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-04-24 13:55:27	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:55:27	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-04-24 13:55:27	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:55:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:55:27	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:55:27	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-04-24 13:55:30	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 13:55:30	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 13:55:30	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 13:55:30	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 13:55:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:55:30	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 13:55:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:55:30	DEBUG	Punctuation handler ==>> text to process:@@
2019-04-24 13:55:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:55:30	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-04-24 13:55:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:55:30	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-04-24 13:55:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:55:30	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-04-24 13:55:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:55:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:55:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:55:30	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-04-24 13:55:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:55:51	DEBUG	Punctuation handler ==>> text to process:@@
2019-04-24 13:55:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:55:51	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-04-24 13:55:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:55:51	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-04-24 13:55:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:55:51	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-04-24 13:55:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:55:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:55:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:55:51	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Punctuation handler ==>> text to process:????
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Punctuation handler ==>> text to process:???
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Punctuation handler ==>> text to process:()
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Tokenization handler ==>> takens:['(', ')'] and tokenize_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')'] and stem_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')'] and lemma_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Ngram handler ==>> unigram:['(', ')'] == bigram:['( )'] == trigram:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Punctuation handler ==>> text to process:@@
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:56:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:07	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-04-24 13:56:19	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 13:56:19	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 13:56:19	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 13:56:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 13:56:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:56:19	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 13:56:19	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:19	DEBUG	Punctuation handler ==>> text to process:@@
2019-04-24 13:56:19	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:19	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-04-24 13:56:19	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:19	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-04-24 13:56:19	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:19	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-04-24 13:56:19	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:56:19	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:56:19	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-04-24 13:57:00	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 13:57:00	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 13:57:00	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 13:57:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 13:57:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:57:00	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 13:57:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:57:00	DEBUG	Punctuation handler ==>> text to process:@@
2019-04-24 13:57:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:57:00	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-04-24 13:57:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:57:00	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-04-24 13:57:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:57:00	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-04-24 13:57:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:57:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:57:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:57:00	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-04-24 13:57:06	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 13:57:06	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 13:57:06	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 13:57:06	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 13:57:06	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:57:06	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 13:57:06	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:57:06	DEBUG	Punctuation handler ==>> text to process:@
2019-04-24 13:57:06	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:57:06	DEBUG	Tokenization handler ==>> takens:['@'] and tokenize_without_stop_words:[]
2019-04-24 13:57:06	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:57:06	DEBUG	Stemmer handler ==>> stem_tokens:['@'] and stem_without_stop_words:[]
2019-04-24 13:57:06	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:57:06	DEBUG	lemmatization handler ==>> lemma_tokens:['@'] and lemma_without_stop_words:[]
2019-04-24 13:57:06	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:57:06	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:57:06	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:57:06	DEBUG	Ngram handler ==>> unigram:['@'] == bigram:[] == trigram:[]
2019-04-24 13:57:12	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 13:57:12	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 13:57:12	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 13:57:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 13:57:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:57:12	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 13:57:12	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:57:12	DEBUG	Punctuation handler ==>> text to process:@@
2019-04-24 13:57:12	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:57:12	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-04-24 13:57:12	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:57:12	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-04-24 13:57:12	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:57:12	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-04-24 13:57:12	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:57:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:57:12	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:57:12	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-04-24 13:57:18	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 13:57:18	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 13:57:18	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 13:57:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 13:57:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:57:18	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 13:57:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:57:18	DEBUG	Punctuation handler ==>> text to process:@
2019-04-24 13:57:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:57:18	DEBUG	Tokenization handler ==>> takens:['@'] and tokenize_without_stop_words:[]
2019-04-24 13:57:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:57:18	DEBUG	Stemmer handler ==>> stem_tokens:['@'] and stem_without_stop_words:[]
2019-04-24 13:57:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:57:18	DEBUG	lemmatization handler ==>> lemma_tokens:['@'] and lemma_without_stop_words:[]
2019-04-24 13:57:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:57:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:57:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:57:18	DEBUG	Ngram handler ==>> unigram:['@'] == bigram:[] == trigram:[]
2019-04-24 13:57:32	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 13:57:32	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 13:57:32	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 13:57:32	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 13:57:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:57:32	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 13:57:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:57:32	DEBUG	Punctuation handler ==>> text to process:(
2019-04-24 13:57:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:57:32	DEBUG	Tokenization handler ==>> takens:['('] and tokenize_without_stop_words:[]
2019-04-24 13:57:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:57:32	DEBUG	Stemmer handler ==>> stem_tokens:['('] and stem_without_stop_words:[]
2019-04-24 13:57:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:57:32	DEBUG	lemmatization handler ==>> lemma_tokens:['('] and lemma_without_stop_words:[]
2019-04-24 13:57:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:57:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:57:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:57:32	DEBUG	Ngram handler ==>> unigram:['('] == bigram:[] == trigram:[]
2019-04-24 13:58:17	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 13:58:17	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 13:58:17	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 13:58:17	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 13:58:17	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:58:17	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 13:58:17	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:17	DEBUG	Punctuation handler ==>> text to process:()
2019-04-24 13:58:17	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:17	DEBUG	Tokenization handler ==>> takens:['(', ')'] and tokenize_without_stop_words:[]
2019-04-24 13:58:17	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:17	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')'] and stem_without_stop_words:[]
2019-04-24 13:58:17	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:17	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')'] and lemma_without_stop_words:[]
2019-04-24 13:58:17	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:17	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:58:17	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:17	DEBUG	Ngram handler ==>> unigram:['(', ')'] == bigram:['( )'] == trigram:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Punctuation handler ==>> text to process:????
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Punctuation handler ==>> text to process:???
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Punctuation handler ==>> text to process:())
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Punctuation handler ==>> text to process:@@
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:58:29	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:29	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-04-24 13:58:34	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 13:58:34	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 13:58:34	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 13:58:34	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 13:58:34	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:58:34	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 13:58:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:34	DEBUG	Punctuation handler ==>> text to process:(
2019-04-24 13:58:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:34	DEBUG	Tokenization handler ==>> takens:['('] and tokenize_without_stop_words:[]
2019-04-24 13:58:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:34	DEBUG	Stemmer handler ==>> stem_tokens:['('] and stem_without_stop_words:[]
2019-04-24 13:58:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:34	DEBUG	lemmatization handler ==>> lemma_tokens:['('] and lemma_without_stop_words:[]
2019-04-24 13:58:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:34	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:58:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:34	DEBUG	Ngram handler ==>> unigram:['('] == bigram:[] == trigram:[]
2019-04-24 13:58:42	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 13:58:42	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 13:58:42	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 13:58:42	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 13:58:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:58:42	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 13:58:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:42	DEBUG	Punctuation handler ==>> text to process:()
2019-04-24 13:58:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:42	DEBUG	Tokenization handler ==>> takens:['(', ')'] and tokenize_without_stop_words:[]
2019-04-24 13:58:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:42	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')'] and stem_without_stop_words:[]
2019-04-24 13:58:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:42	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')'] and lemma_without_stop_words:[]
2019-04-24 13:58:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:58:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:58:42	DEBUG	Ngram handler ==>> unigram:['(', ')'] == bigram:['( )'] == trigram:[]
2019-04-24 13:59:01	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 13:59:01	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 13:59:01	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 13:59:01	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 13:59:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:59:01	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 13:59:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:59:01	DEBUG	Punctuation handler ==>> text to process:()
2019-04-24 13:59:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:59:01	DEBUG	Tokenization handler ==>> takens:['(', ')'] and tokenize_without_stop_words:[]
2019-04-24 13:59:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:59:01	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')'] and stem_without_stop_words:[]
2019-04-24 13:59:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:59:01	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')'] and lemma_without_stop_words:[]
2019-04-24 13:59:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:59:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:59:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:59:01	DEBUG	Ngram handler ==>> unigram:['(', ')'] == bigram:['( )'] == trigram:[]
2019-04-24 13:59:12	DEBUG	Punctuation handler ==>> text to process:
2019-04-24 13:59:12	DEBUG	Tokenization handler ==>> takens:[] and tokenize_without_stop_words:[]
2019-04-24 13:59:12	DEBUG	Stemmer handler ==>> stem_tokens:[] and stem_without_stop_words:[]
2019-04-24 13:59:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 13:59:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:59:12	DEBUG	Ngram handler ==>> unigram:[] == bigram:[] == trigram:[]
2019-04-24 13:59:12	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:59:12	DEBUG	Punctuation handler ==>> text to process:(
2019-04-24 13:59:12	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:59:12	DEBUG	Tokenization handler ==>> takens:['('] and tokenize_without_stop_words:[]
2019-04-24 13:59:12	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:59:12	DEBUG	Stemmer handler ==>> stem_tokens:['('] and stem_without_stop_words:[]
2019-04-24 13:59:12	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:59:12	DEBUG	lemmatization handler ==>> lemma_tokens:['('] and lemma_without_stop_words:[]
2019-04-24 13:59:12	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:59:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:59:12	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:59:12	DEBUG	Ngram handler ==>> unigram:['('] == bigram:[] == trigram:[]
2019-04-24 13:59:39	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:59:39	DEBUG	Punctuation handler ==>> text to process:(
2019-04-24 13:59:39	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:59:39	DEBUG	Tokenization handler ==>> takens:['('] and tokenize_without_stop_words:[]
2019-04-24 13:59:39	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:59:39	DEBUG	Stemmer handler ==>> stem_tokens:['('] and stem_without_stop_words:[]
2019-04-24 13:59:39	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:59:39	DEBUG	lemmatization handler ==>> lemma_tokens:['('] and lemma_without_stop_words:[]
2019-04-24 13:59:39	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:59:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 13:59:39	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 13:59:39	DEBUG	Ngram handler ==>> unigram:['('] == bigram:[] == trigram:[]
2019-04-24 14:01:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 14:01:32	DEBUG	Punctuation handler ==>> text to process:(
2019-04-24 14:01:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 14:01:32	DEBUG	Tokenization handler ==>> takens:['('] and tokenize_without_stop_words:[]
2019-04-24 14:01:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 14:01:32	DEBUG	Stemmer handler ==>> stem_tokens:['('] and stem_without_stop_words:[]
2019-04-24 14:01:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 14:01:37	DEBUG	lemmatization handler ==>> lemma_tokens:['('] and lemma_without_stop_words:[]
2019-04-24 14:01:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 14:01:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 14:01:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 14:01:37	DEBUG	Ngram handler ==>> unigram:['('] == bigram:[] == trigram:[]
2019-04-24 14:04:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 14:04:07	DEBUG	Punctuation handler ==>> text to process:(
2019-04-24 14:04:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 14:04:07	DEBUG	Tokenization handler ==>> takens:['('] and tokenize_without_stop_words:[]
2019-04-24 14:04:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 14:04:07	DEBUG	Stemmer handler ==>> stem_tokens:['('] and stem_without_stop_words:[]
2019-04-24 14:04:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 14:04:11	DEBUG	lemmatization handler ==>> lemma_tokens:['('] and lemma_without_stop_words:[]
2019-04-24 14:04:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 14:04:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 14:04:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 14:04:11	DEBUG	Ngram handler ==>> unigram:['('] == bigram:[] == trigram:[]
2019-04-24 14:05:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 14:05:26	DEBUG	Punctuation handler ==>> text to process:(
2019-04-24 14:05:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 14:05:26	DEBUG	Tokenization handler ==>> takens:['('] and tokenize_without_stop_words:[]
2019-04-24 14:05:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 14:05:26	DEBUG	Stemmer handler ==>> stem_tokens:['('] and stem_without_stop_words:[]
2019-04-24 14:05:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 14:05:30	DEBUG	lemmatization handler ==>> lemma_tokens:['('] and lemma_without_stop_words:[]
2019-04-24 14:05:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 14:05:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 14:05:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 14:05:30	DEBUG	Ngram handler ==>> unigram:['('] == bigram:[] == trigram:[]
2019-04-24 14:05:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 14:05:41	DEBUG	Punctuation handler ==>> text to process:(
2019-04-24 14:05:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 14:05:41	DEBUG	Tokenization handler ==>> takens:['('] and tokenize_without_stop_words:[]
2019-04-24 14:05:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 14:05:41	DEBUG	Stemmer handler ==>> stem_tokens:['('] and stem_without_stop_words:[]
2019-04-24 14:05:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 14:05:45	DEBUG	lemmatization handler ==>> lemma_tokens:['('] and lemma_without_stop_words:[]
2019-04-24 14:05:45	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 14:05:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 14:05:45	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 14:05:45	DEBUG	Ngram handler ==>> unigram:['('] == bigram:[] == trigram:[]
2019-04-24 14:38:52	DEBUG	Punctuation handler ==>> text to process:fgfdfgdfgdfg
2019-04-24 14:38:52	DEBUG	Tokenization handler ==>> takens:['fgfdfgdfgdfg'] and tokenize_without_stop_words:[]
2019-04-24 14:38:52	DEBUG	Stemmer handler ==>> stem_tokens:['fgfdfgdfgdfg'] and stem_without_stop_words:[]
2019-04-24 14:38:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 14:38:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 14:38:52	DEBUG	Ngram handler ==>> unigram:['fgfdfgdfgdfg'] == bigram:[] == trigram:[]
2019-04-24 14:38:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 14:38:53	DEBUG	Punctuation handler ==>> text to process:fgfdfgdfgdfg
2019-04-24 14:38:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 14:38:53	DEBUG	Tokenization handler ==>> takens:['fgfdfgdfgdfg'] and tokenize_without_stop_words:[]
2019-04-24 14:38:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 14:38:53	DEBUG	Stemmer handler ==>> stem_tokens:['fgfdfgdfgdfg'] and stem_without_stop_words:[]
2019-04-24 14:38:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 14:38:56	DEBUG	lemmatization handler ==>> lemma_tokens:['fgfdfgdfgdfg'] and lemma_without_stop_words:[]
2019-04-24 14:38:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 14:38:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 14:38:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-04-24 14:38:56	DEBUG	Ngram handler ==>> unigram:['fgfdfgdfgdfg'] == bigram:[] == trigram:[]
2019-04-24 14:39:15	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-04-24 14:39:15	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-04-24 14:39:15	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-04-24 14:39:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 14:39:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 14:39:15	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-04-24 16:09:25	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-04-24 16:09:25	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-04-24 16:09:25	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-04-24 16:09:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-24 16:09:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-24 16:09:25	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-04-26 14:56:25	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-04-26 14:56:25	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-04-26 14:56:25	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-04-26 14:56:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-26 14:56:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-26 14:56:25	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-04-26 14:56:25	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-04-26 14:56:25	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-04-26 14:56:25	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-04-26 14:56:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-26 14:56:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-26 14:56:25	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-04-26 14:56:25	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-04-26 14:56:25	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-04-26 14:56:25	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-04-26 14:56:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-26 14:56:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-26 14:56:25	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-04-26 14:56:25	DEBUG	Punctuation handler ==>> text to process:recharge
2019-04-26 14:56:25	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-04-26 14:56:25	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-04-26 14:56:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-26 14:56:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-26 14:56:25	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-04-26 14:56:25	DEBUG	Punctuation handler ==>> text to process:travel
2019-04-26 14:56:25	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-04-26 14:56:25	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-04-26 14:56:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-26 14:56:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-26 14:56:25	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-04-26 14:56:25	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-04-26 14:56:25	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-04-26 14:56:25	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-04-26 14:56:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-26 14:56:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-26 14:56:25	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-04-26 14:56:54	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-04-26 14:56:54	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-04-26 14:56:54	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-04-26 14:56:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-26 14:56:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-26 14:56:54	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-04-26 14:56:54	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-04-26 14:56:54	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-04-26 14:56:54	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-04-26 14:56:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-26 14:56:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-26 14:56:54	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-04-26 14:56:54	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-04-26 14:56:54	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-04-26 14:56:54	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-04-26 14:56:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-26 14:56:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-26 14:56:54	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-04-26 14:56:54	DEBUG	Punctuation handler ==>> text to process:recharge
2019-04-26 14:56:54	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-04-26 14:56:54	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-04-26 14:56:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-26 14:56:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-26 14:56:54	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-04-26 14:56:54	DEBUG	Punctuation handler ==>> text to process:travel
2019-04-26 14:56:54	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-04-26 14:56:54	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-04-26 14:56:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-26 14:56:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-26 14:56:54	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-04-26 14:56:54	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-04-26 14:56:54	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-04-26 14:56:54	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-04-26 14:56:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-04-26 14:56:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-04-26 14:56:54	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-05-08 15:51:11	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-05-08 15:51:11	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-05-08 15:51:11	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-05-08 15:51:11	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 15:51:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 15:51:11	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-05-08 15:51:11	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-05-08 15:51:11	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-05-08 15:51:11	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-05-08 15:51:11	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 15:51:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 15:51:11	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-05-08 15:51:11	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-05-08 15:51:11	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-05-08 15:51:11	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-05-08 15:51:11	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 15:51:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 15:51:11	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-05-08 15:51:11	DEBUG	Punctuation handler ==>> text to process:recharge
2019-05-08 15:51:11	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-05-08 15:51:11	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-05-08 15:51:11	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 15:51:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 15:51:11	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-05-08 15:51:11	DEBUG	Punctuation handler ==>> text to process:travel
2019-05-08 15:51:11	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-05-08 15:51:11	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-05-08 15:51:11	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 15:51:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 15:51:11	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-05-08 15:51:11	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-05-08 15:51:11	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-05-08 15:51:11	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-05-08 15:51:11	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 15:51:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 15:51:11	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-05-08 15:51:24	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-05-08 15:51:24	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-05-08 15:51:24	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-05-08 15:51:24	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 15:51:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 15:51:24	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-05-08 15:51:24	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-05-08 15:51:24	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-05-08 15:51:24	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-05-08 15:51:24	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 15:51:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 15:51:24	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-05-08 15:51:24	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-05-08 15:51:24	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-05-08 15:51:24	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-05-08 15:51:24	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 15:51:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 15:51:24	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-05-08 15:51:24	DEBUG	Punctuation handler ==>> text to process:recharge
2019-05-08 15:51:24	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-05-08 15:51:24	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-05-08 15:51:24	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 15:51:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 15:51:24	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-05-08 15:51:24	DEBUG	Punctuation handler ==>> text to process:travel
2019-05-08 15:51:24	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-05-08 15:51:24	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-05-08 15:51:24	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 15:51:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 15:51:24	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-05-08 15:51:24	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-05-08 15:51:24	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-05-08 15:51:24	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-05-08 15:51:24	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 15:51:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 15:51:24	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-05-08 15:51:24	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-05-08 15:51:24	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-05-08 15:51:24	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-05-08 15:51:24	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 15:51:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 15:51:24	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-05-08 15:51:24	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-05-08 15:51:24	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-05-08 15:51:24	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-05-08 15:51:24	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 15:51:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 15:51:24	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-05-08 15:51:52	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-05-08 15:51:52	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-05-08 15:51:52	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-05-08 15:51:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 15:51:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 15:51:52	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-05-08 15:51:52	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-05-08 15:51:52	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-05-08 15:51:52	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-05-08 15:51:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 15:51:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 15:51:52	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-05-08 15:51:52	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-05-08 15:51:52	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-05-08 15:51:52	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-05-08 15:51:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 15:51:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 15:51:52	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-05-08 15:51:52	DEBUG	Punctuation handler ==>> text to process:recharge
2019-05-08 15:51:52	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-05-08 15:51:52	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-05-08 15:51:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 15:51:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 15:51:52	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-05-08 15:51:52	DEBUG	Punctuation handler ==>> text to process:travel
2019-05-08 15:51:52	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-05-08 15:51:52	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-05-08 15:51:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 15:51:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 15:51:52	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-05-08 15:51:52	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-05-08 15:51:52	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-05-08 15:51:52	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-05-08 15:51:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 15:51:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 15:51:52	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-05-08 15:51:52	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-05-08 15:51:52	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-05-08 15:51:52	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-05-08 15:51:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 15:51:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 15:51:52	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-05-08 15:51:52	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-05-08 15:51:52	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-05-08 15:51:52	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-05-08 15:51:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 15:51:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 15:51:52	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-05-08 16:26:16	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-05-08 16:26:16	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-05-08 16:26:16	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-05-08 16:26:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 16:26:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 16:26:16	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-05-08 16:26:16	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-05-08 16:26:16	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-05-08 16:26:16	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-05-08 16:26:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 16:26:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 16:26:16	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-05-08 16:26:16	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-05-08 16:26:16	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-05-08 16:26:16	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-05-08 16:26:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 16:26:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 16:26:16	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-05-08 16:26:16	DEBUG	Punctuation handler ==>> text to process:recharge
2019-05-08 16:26:16	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-05-08 16:26:16	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-05-08 16:26:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 16:26:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 16:26:16	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-05-08 16:26:16	DEBUG	Punctuation handler ==>> text to process:travel
2019-05-08 16:26:16	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-05-08 16:26:16	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-05-08 16:26:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 16:26:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 16:26:16	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-05-08 16:26:16	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-05-08 16:26:16	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-05-08 16:26:16	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-05-08 16:26:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 16:26:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 16:26:16	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-05-08 16:26:16	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-05-08 16:26:16	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-05-08 16:26:16	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-05-08 16:26:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 16:26:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 16:26:16	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-05-08 16:26:16	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-05-08 16:26:16	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-05-08 16:26:16	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-05-08 16:26:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 16:26:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 16:26:16	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-05-08 16:27:37	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-05-08 16:27:37	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-05-08 16:27:37	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-05-08 16:27:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 16:27:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 16:27:37	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-05-08 16:27:37	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-05-08 16:27:37	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-05-08 16:27:37	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-05-08 16:27:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 16:27:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 16:27:37	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-05-08 16:27:37	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-05-08 16:27:37	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-05-08 16:27:37	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-05-08 16:27:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 16:27:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 16:27:37	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-05-08 16:27:37	DEBUG	Punctuation handler ==>> text to process:recharge
2019-05-08 16:27:37	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-05-08 16:27:37	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-05-08 16:27:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 16:27:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 16:27:37	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-05-08 16:27:37	DEBUG	Punctuation handler ==>> text to process:travel
2019-05-08 16:27:37	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-05-08 16:27:37	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-05-08 16:27:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 16:27:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 16:27:37	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-05-08 16:27:37	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-05-08 16:27:37	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-05-08 16:27:37	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-05-08 16:27:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 16:27:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 16:27:37	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-05-08 16:27:37	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-05-08 16:27:37	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-05-08 16:27:37	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-05-08 16:27:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 16:27:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 16:27:37	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-05-08 16:27:37	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-05-08 16:27:37	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-05-08 16:27:37	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-05-08 16:27:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-08 16:27:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 16:27:37	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-05-08 17:09:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:24	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 17:09:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:24	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:09:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:24	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:09:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:09:26	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:09:26	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:11:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:11:57	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 17:11:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:11:57	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:11:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:11:57	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:11:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:00	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:12:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:32	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 17:12:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:32	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:12:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:32	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:12:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:12:34	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:12:34	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:17:05	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:05	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 17:17:05	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:05	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:17:05	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:05	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:17:05	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:17:07	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:17:07	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:18:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:36	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 17:18:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:36	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:18:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:36	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:18:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:18:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:18:38	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:20:19	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:19	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 17:20:19	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:19	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:20:19	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:19	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:20:19	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:20:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:20:21	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:21:05	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:05	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 17:21:05	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:05	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:21:05	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:05	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:21:05	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:08	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:21:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:21:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:21:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:21:09	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:22:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:49	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 17:22:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:49	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:22:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:49	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:22:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:22:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:22:51	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:23:10	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:10	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 17:23:10	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:10	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:10	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:10	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:10	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:13	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:13	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:23:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:21	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 17:23:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:21	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:21	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:23	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:23:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:35	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 17:23:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:35	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:35	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:23:37	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:23:37	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:24:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:08	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:09	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:09	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:24:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:53	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 17:24:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:53	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:24:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:53	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:24:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:55	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:24:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:24:56	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:25:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:52	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 17:25:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:52	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:25:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:52	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:25:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:25:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:25:55	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:27:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:50	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 17:27:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:51	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:27:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:51	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:27:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:27:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:27:53	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:28:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:30	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 17:28:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:30	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:28:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:30	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:28:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:28:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:28:32	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:32:31	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:31	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 17:32:31	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:31	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:32:31	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:31	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:32:31	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:32:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:32:33	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:33:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:33:59	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 17:33:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:33:59	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:33:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:33:59	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:33:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:02	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:34:40	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:40	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 17:34:40	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:40	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:34:40	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:40	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:34:40	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:34:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:34:42	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:35:28	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:28	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 17:35:28	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:28	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:35:28	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:28	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:35:28	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:35:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:35:30	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:36:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:16	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 17:36:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:16	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:36:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:16	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:36:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:36:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:36:18	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:41:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:49	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 17:41:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:49	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:41:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:49	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:41:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:41:52	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:41:52	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:42:40	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:40	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 17:42:40	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:40	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:42:40	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:40	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:42:40	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:42:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:42:42	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:43:17	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:17	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 17:43:17	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:17	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:43:17	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:17	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:43:17	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:20	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:20	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:43:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:53	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 17:43:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:53	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:43:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:53	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:43:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:43:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:43:56	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:44:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:54	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 17:44:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:54	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:44:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:54	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:44:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:44:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:44:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:44:57	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:47:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:46	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 17:47:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:46	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:47:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:46	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:47:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:47:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:47:48	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:48:14	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:14	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 17:48:14	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:14	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:48:14	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:14	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:48:14	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:16	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:16	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:48:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:33	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 17:48:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:33	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:48:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:33	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:48:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:48:36	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:48:36	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:50:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:53	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 17:50:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:53	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:50:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:53	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:50:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 17:50:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 17:50:56	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 18:17:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:38	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 18:17:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:38	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:17:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:38	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 18:17:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:17:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:17:41	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 18:18:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:50	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 18:18:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:50	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:18:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:50	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 18:18:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:18:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:18:53	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 18:21:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:18	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 18:21:18	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:19	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:21:19	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:19	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 18:21:19	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:21:21	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:21:21	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 18:22:05	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:05	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 18:22:05	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:05	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:22:05	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:05	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 18:22:05	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:22:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:22:08	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 18:23:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:51	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 18:23:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:51	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:23:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:51	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 18:23:51	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:23:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:23:54	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 18:24:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:53	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 18:24:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:53	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:24:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:53	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 18:24:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:24:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:24:55	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 18:26:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:33	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 18:26:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:33	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:26:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:33	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 18:26:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:26:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:26:35	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 18:27:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:27:57	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 18:27:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:27:57	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:27:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:27:57	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 18:27:57	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:28:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:28:00	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 18:34:28	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:28	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 18:34:28	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:28	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:34:28	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:28	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 18:34:28	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:34:30	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:34:30	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 18:43:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:46	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 18:43:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:46	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:43:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:46	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 18:43:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:43:49	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:43:49	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 18:45:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:54	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 18:45:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:54	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:45:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:54	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 18:45:54	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 18:45:56	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 18:45:56	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 19:09:41	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:41	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 19:09:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:42	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:09:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:42	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 19:09:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:47	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 19:09:47	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:09:47	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:47	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 19:09:47	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:47	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 19:09:47	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:47	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:09:47	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:47	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 19:09:47	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:47	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 19:09:47	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:09:47	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:47	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 19:09:47	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:47	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 19:09:47	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:47	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 19:09:47	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:47	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 19:09:47	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:47	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 19:09:47	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:09:47	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:47	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 19:09:47	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:47	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 19:09:47	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:09:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:09:48	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 19:14:47	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:48	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 19:14:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:48	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:14:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:48	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 19:14:48	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:14:50	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:14:50	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 19:21:22	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:22	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 19:21:22	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:22	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:21:22	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:22	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 19:21:22	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:21:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:21:25	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 19:23:22	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:22	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 19:23:22	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:22	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:23:22	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:22	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 19:23:22	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:25	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:25	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 19:23:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:53	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 19:23:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:53	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:23:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:53	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 19:23:53	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:23:55	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:23:55	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 19:31:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:32	DEBUG	Punctuation handler ==>> text to process:????
2019-05-08 19:31:32	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:33	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:31:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:33	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 19:31:33	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Punctuation handler ==>> text to process:???
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Punctuation handler ==>> text to process:())
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-08 19:31:35	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-08 19:31:35	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-09 13:57:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:57:59	DEBUG	Punctuation handler ==>> text to process:????
2019-05-09 13:57:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:57:59	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-09 13:57:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:57:59	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-09 13:57:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	Punctuation handler ==>> text to process:???
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	Punctuation handler ==>> text to process:())
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-09 13:58:01	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:01	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:02	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Punctuation handler ==>> text to process:????
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Punctuation handler ==>> text to process:???
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Punctuation handler ==>> text to process:())
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-09 13:58:58	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:58	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 13:58:59	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 13:58:59	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-09 14:01:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:00	DEBUG	Punctuation handler ==>> text to process:????
2019-05-09 14:01:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:00	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:01:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:00	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-09 14:01:00	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Punctuation handler ==>> text to process:???
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Punctuation handler ==>> text to process:())
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:02	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:02	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-09 14:01:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:08	DEBUG	Punctuation handler ==>> text to process:????
2019-05-09 14:01:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:08	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:01:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:08	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-09 14:01:08	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Punctuation handler ==>> text to process:???
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Punctuation handler ==>> text to process:())
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:01:11	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:01:11	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-09 14:03:44	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:44	DEBUG	Punctuation handler ==>> text to process:????
2019-05-09 14:03:44	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:44	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:03:44	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:44	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-09 14:03:44	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Punctuation handler ==>> text to process:???
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Punctuation handler ==>> text to process:())
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:03:46	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:03:46	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-09 14:04:22	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:22	DEBUG	Punctuation handler ==>> text to process:????
2019-05-09 14:04:22	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:22	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:04:22	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:22	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-09 14:04:22	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Punctuation handler ==>> text to process:???
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Punctuation handler ==>> text to process:())
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:04:24	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:04:24	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Punctuation handler ==>> text to process:????
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Tokenization handler ==>> takens:['?', '?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?', '?'] and stem_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?', '?'] and lemma_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Ngram handler ==>> unigram:['?', '?', '?', '?'] == bigram:['? ?', '? ?', '? ?'] == trigram:['? ? ?', '? ? ?']
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Punctuation handler ==>> text to process:???
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Tokenization handler ==>> takens:['?', '?', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Stemmer handler ==>> stem_tokens:['?', '?', '?'] and stem_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	lemmatization handler ==>> lemma_tokens:['?', '?', '?'] and lemma_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Ngram handler ==>> unigram:['?', '?', '?'] == bigram:['? ?', '? ?'] == trigram:['? ? ?']
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Punctuation handler ==>> text to process:@@@######
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Tokenization handler ==>> takens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and tokenize_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and stem_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@', '@', '#', '#', '#', '#', '#', '#'] and lemma_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Ngram handler ==>> unigram:['@', '@', '@', '#', '#', '#', '#', '#', '#'] == bigram:['@ @', '@ @', '@ #', '# #', '# #', '# #', '# #', '# #'] == trigram:['@ @ @', '@ @ #', '@ # #', '# # #', '# # #', '# # #', '# # #']
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Punctuation handler ==>> text to process:!@#$%^
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Tokenization handler ==>> takens:['!', '@', '#', '$', '%', '^'] and tokenize_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Stemmer handler ==>> stem_tokens:['!', '@', '#', '$', '%', '^'] and stem_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	lemmatization handler ==>> lemma_tokens:['!', '@', '#', '$', '%', '^'] and lemma_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Ngram handler ==>> unigram:['!', '@', '#', '$', '%', '^'] == bigram:['! @', '@ #', '# $', '$ %', '% ^'] == trigram:['! @ #', '@ # $', '# $ %', '$ % ^']
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Punctuation handler ==>> text to process:())
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Tokenization handler ==>> takens:['(', ')', ')'] and tokenize_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Stemmer handler ==>> stem_tokens:['(', ')', ')'] and stem_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	lemmatization handler ==>> lemma_tokens:['(', ')', ')'] and lemma_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Ngram handler ==>> unigram:['(', ')', ')'] == bigram:['( )', ') )'] == trigram:['( ) )']
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Punctuation handler ==>> text to process:@@
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Tokenization handler ==>> takens:['@', '@'] and tokenize_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Stemmer handler ==>> stem_tokens:['@', '@'] and stem_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	lemmatization handler ==>> lemma_tokens:['@', '@'] and lemma_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Ngram handler ==>> unigram:['@', '@'] == bigram:['@ @'] == trigram:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Punctuation handler ==>> text to process:whats your name?
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Tokenization handler ==>> takens:['whats', 'your', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'your', 'name', '?'] and stem_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	lemmatization handler ==>> lemma_tokens:['whats', 'your', 'name', '?'] and lemma_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Ngram handler ==>> unigram:['whats', 'your', 'name', '?'] == bigram:['whats your', 'your name', 'name ?'] == trigram:['whats your name', 'your name ?']
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Punctuation handler ==>> text to process:what can i call you?
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Tokenization handler ==>> takens:['what', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Ngram handler ==>> unigram:['what', 'can', 'i', 'call', 'you', '?'] == bigram:['what can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['what can i', 'can i call', 'i call you', 'call you ?']
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Punctuation handler ==>> text to process:may i know what your name is?
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Tokenization handler ==>> takens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Stemmer handler ==>> stem_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and stem_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	lemmatization handler ==>> lemma_tokens:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] and lemma_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Ngram handler ==>> unigram:['may', 'i', 'know', 'what', 'your', 'name', 'is', '?'] == bigram:['may i', 'i know', 'know what', 'what your', 'your name', 'name is', 'is ?'] == trigram:['may i know', 'i know what', 'know what your', 'what your name', 'your name is', 'name is ?']
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Punctuation handler ==>> text to process:how can i call you?
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Tokenization handler ==>> takens:['how', 'can', 'i', 'call', 'you', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'can', 'i', 'call', 'you', '?'] and stem_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'can', 'i', 'call', 'you', '?'] and lemma_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Ngram handler ==>> unigram:['how', 'can', 'i', 'call', 'you', '?'] == bigram:['how can', 'can i', 'i call', 'call you', 'you ?'] == trigram:['how can i', 'can i call', 'i call you', 'call you ?']
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Punctuation handler ==>> text to process:what is your good name?
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'good', 'name', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'good', 'name', '?'] and stem_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	lemmatization handler ==>> lemma_tokens:['what', 'is', 'your', 'good', 'name', '?'] and lemma_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Ngram handler ==>> unigram:['what', 'is', 'your', 'good', 'name', '?'] == bigram:['what is', 'is your', 'your good', 'good name', 'name ?'] == trigram:['what is your', 'is your good', 'your good name', 'good name ?']
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Punctuation handler ==>> text to process:how do you preferred to be called?
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Tokenization handler ==>> takens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and tokenize_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Stemmer handler ==>> stem_tokens:['how', 'do', 'you', 'prefer', 'to', 'be', 'call', '?'] and stem_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	lemmatization handler ==>> lemma_tokens:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] and lemma_without_stop_words:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-09 14:08:23	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-09 14:08:23	DEBUG	Ngram handler ==>> unigram:['how', 'do', 'you', 'preferred', 'to', 'be', 'called', '?'] == bigram:['how do', 'do you', 'you preferred', 'preferred to', 'to be', 'be called', 'called ?'] == trigram:['how do you', 'do you preferred', 'you preferred to', 'preferred to be', 'to be called', 'be called ?']
2019-05-15 19:16:41	DEBUG	Punctuation handler ==>> text to process:hello
2019-05-15 19:16:41	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-05-15 19:16:41	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-05-15 19:16:41	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-15 19:16:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-15 19:16:41	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-05-15 19:18:48	DEBUG	Punctuation handler ==>> text to process:hello
2019-05-15 19:18:48	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-05-15 19:18:48	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-05-15 19:18:48	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-15 19:18:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-15 19:18:48	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-05-15 19:28:49	DEBUG	Punctuation handler ==>> text to process:hello
2019-05-15 19:28:49	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-05-15 19:28:49	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-05-15 19:28:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-15 19:28:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-15 19:28:49	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-05-15 19:29:35	DEBUG	Punctuation handler ==>> text to process:hello
2019-05-15 19:29:35	DEBUG	Tokenization handler ==>> takens:['hello'] and tokenize_without_stop_words:[]
2019-05-15 19:29:35	DEBUG	Stemmer handler ==>> stem_tokens:['hello'] and stem_without_stop_words:[]
2019-05-15 19:29:35	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-15 19:29:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-15 19:29:35	DEBUG	Ngram handler ==>> unigram:['hello'] == bigram:[] == trigram:[]
2019-05-23 12:19:51	DEBUG	Punctuation handler ==>> text to process:email address
2019-05-23 12:19:51	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-05-23 12:19:51	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-05-23 12:19:51	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-23 12:19:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-23 12:19:51	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-05-23 12:19:51	DEBUG	Punctuation handler ==>> text to process:email data
2019-05-23 12:19:51	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-05-23 12:19:51	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-05-23 12:19:51	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-23 12:19:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-23 12:19:51	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-05-23 12:19:51	DEBUG	Punctuation handler ==>> text to process:email address
2019-05-23 12:19:51	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-05-23 12:19:51	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-05-23 12:19:51	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-23 12:19:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-23 12:19:51	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-05-23 12:19:51	DEBUG	Punctuation handler ==>> text to process:username
2019-05-23 12:19:51	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-05-23 12:19:51	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-05-23 12:19:51	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-23 12:19:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-23 12:19:51	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-05-23 12:19:51	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-05-23 12:19:51	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-05-23 12:19:51	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-05-23 12:19:51	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-23 12:19:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-23 12:19:51	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-05-23 12:19:51	DEBUG	Punctuation handler ==>> text to process:name
2019-05-23 12:19:51	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-05-23 12:19:51	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-05-23 12:19:51	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-23 12:19:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-23 12:19:51	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-05-23 12:19:51	DEBUG	Punctuation handler ==>> text to process:text username
2019-05-23 12:19:51	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-05-23 12:19:51	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-05-23 12:19:51	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-23 12:19:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-23 12:19:51	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-05-23 12:19:57	DEBUG	Punctuation handler ==>> text to process:email address
2019-05-23 12:19:57	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-05-23 12:19:57	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-05-23 12:19:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-23 12:19:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-23 12:19:57	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-05-23 12:19:57	DEBUG	Punctuation handler ==>> text to process:email data
2019-05-23 12:19:57	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-05-23 12:19:57	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-05-23 12:19:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-23 12:19:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-23 12:19:57	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-05-23 12:19:57	DEBUG	Punctuation handler ==>> text to process:email address
2019-05-23 12:19:57	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-05-23 12:19:57	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-05-23 12:19:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-23 12:19:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-23 12:19:57	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-05-23 12:19:57	DEBUG	Punctuation handler ==>> text to process:username
2019-05-23 12:19:57	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-05-23 12:19:57	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-05-23 12:19:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-23 12:19:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-23 12:19:57	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-05-23 12:19:57	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-05-23 12:19:57	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-05-23 12:19:57	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-05-23 12:19:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-23 12:19:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-23 12:19:57	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-05-23 12:19:57	DEBUG	Punctuation handler ==>> text to process:name
2019-05-23 12:19:57	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-05-23 12:19:57	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-05-23 12:19:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-23 12:19:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-23 12:19:57	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-05-23 12:19:57	DEBUG	Punctuation handler ==>> text to process:text username
2019-05-23 12:19:57	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-05-23 12:19:57	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-05-23 12:19:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-23 12:19:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-23 12:19:57	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-05-23 12:21:30	DEBUG	Punctuation handler ==>> text to process:email
2019-05-23 12:21:32	DEBUG	Tokenization handler ==>> takens:['email'] and tokenize_without_stop_words:[]
2019-05-23 12:21:32	DEBUG	Stemmer handler ==>> stem_tokens:['email'] and stem_without_stop_words:[]
2019-05-23 12:21:32	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-23 12:21:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-23 12:21:32	DEBUG	Ngram handler ==>> unigram:['email'] == bigram:[] == trigram:[]
2019-05-23 12:37:36	DEBUG	Punctuation handler ==>> text to process:email
2019-05-23 12:37:36	DEBUG	Tokenization handler ==>> takens:['email'] and tokenize_without_stop_words:[]
2019-05-23 12:37:36	DEBUG	Stemmer handler ==>> stem_tokens:['email'] and stem_without_stop_words:[]
2019-05-23 12:37:36	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-23 12:37:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-23 12:37:36	DEBUG	Ngram handler ==>> unigram:['email'] == bigram:[] == trigram:[]
2019-05-23 12:37:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-23 12:37:38	DEBUG	Punctuation handler ==>> text to process:email
2019-05-23 12:37:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-23 12:37:38	DEBUG	Tokenization handler ==>> takens:['email'] and tokenize_without_stop_words:[]
2019-05-23 12:37:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-23 12:37:38	DEBUG	Stemmer handler ==>> stem_tokens:['email'] and stem_without_stop_words:[]
2019-05-23 12:37:38	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-23 12:37:42	DEBUG	lemmatization handler ==>> lemma_tokens:['email'] and lemma_without_stop_words:[]
2019-05-23 12:37:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-23 12:37:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-23 12:37:42	DEBUG	File not found in case of stop words:---/home/manish/Documents/workspace/bot/ml_engine/stopwords/_stopwords.csv
2019-05-23 12:37:42	DEBUG	Ngram handler ==>> unigram:['email'] == bigram:[] == trigram:[]
2019-05-23 12:40:52	DEBUG	Punctuation handler ==>> text to process:email address
2019-05-23 12:40:52	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-05-23 12:40:52	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-05-23 12:40:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-23 12:40:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-23 12:40:52	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-05-23 12:40:52	DEBUG	Punctuation handler ==>> text to process:email data
2019-05-23 12:40:52	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-05-23 12:40:52	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-05-23 12:40:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-23 12:40:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-23 12:40:52	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-05-23 12:40:52	DEBUG	Punctuation handler ==>> text to process:email address
2019-05-23 12:40:52	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-05-23 12:40:52	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-05-23 12:40:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-23 12:40:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-23 12:40:52	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-05-23 12:40:52	DEBUG	Punctuation handler ==>> text to process:username
2019-05-23 12:40:52	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-05-23 12:40:52	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-05-23 12:40:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-23 12:40:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-23 12:40:52	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-05-23 12:40:52	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-05-23 12:40:52	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-05-23 12:40:52	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-05-23 12:40:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-23 12:40:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-23 12:40:52	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-05-23 12:40:52	DEBUG	Punctuation handler ==>> text to process:name
2019-05-23 12:40:52	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-05-23 12:40:52	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-05-23 12:40:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-23 12:40:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-23 12:40:52	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-05-23 12:40:52	DEBUG	Punctuation handler ==>> text to process:text username
2019-05-23 12:40:52	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-05-23 12:40:52	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-05-23 12:40:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-23 12:40:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-23 12:40:52	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-05-23 12:41:27	DEBUG	Punctuation handler ==>> text to process:name
2019-05-23 12:41:27	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-05-23 12:41:27	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-05-23 12:41:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-23 12:41:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-23 12:41:27	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-05-24 19:03:15	DEBUG	Punctuation handler ==>> text to process:email address
2019-05-24 19:03:15	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-05-24 19:03:15	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-05-24 19:03:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-24 19:03:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-24 19:03:15	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-05-24 19:03:15	DEBUG	Punctuation handler ==>> text to process:email data
2019-05-24 19:03:15	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-05-24 19:03:15	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-05-24 19:03:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-24 19:03:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-24 19:03:15	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-05-24 19:03:15	DEBUG	Punctuation handler ==>> text to process:email address
2019-05-24 19:03:15	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-05-24 19:03:15	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-05-24 19:03:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-24 19:03:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-24 19:03:15	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-05-24 19:03:15	DEBUG	Punctuation handler ==>> text to process:username
2019-05-24 19:03:15	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-05-24 19:03:15	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-05-24 19:03:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-24 19:03:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-24 19:03:15	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-05-24 19:03:15	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-05-24 19:03:15	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-05-24 19:03:15	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-05-24 19:03:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-24 19:03:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-24 19:03:15	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-05-24 19:03:15	DEBUG	Punctuation handler ==>> text to process:name
2019-05-24 19:03:15	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-05-24 19:03:15	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-05-24 19:03:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-24 19:03:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-24 19:03:15	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-05-24 19:03:15	DEBUG	Punctuation handler ==>> text to process:text username
2019-05-24 19:03:15	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-05-24 19:03:15	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-05-24 19:03:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-24 19:03:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-24 19:03:15	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-05-24 19:05:17	DEBUG	Punctuation handler ==>> text to process:hi
2019-05-24 19:05:17	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-05-24 19:05:17	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-05-24 19:05:17	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-24 19:05:17	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-24 19:05:17	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-05-24 19:05:22	DEBUG	Punctuation handler ==>> text to process:hi
2019-05-24 19:05:22	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-05-24 19:05:22	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-05-24 19:05:22	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-24 19:05:22	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-24 19:05:22	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-05-24 19:05:27	DEBUG	Punctuation handler ==>> text to process:hi
2019-05-24 19:05:27	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-05-24 19:05:27	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-05-24 19:05:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-24 19:05:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-24 19:05:27	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-05-24 19:06:15	DEBUG	Punctuation handler ==>> text to process:hi
2019-05-24 19:06:15	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-05-24 19:06:15	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-05-24 19:06:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-24 19:06:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-24 19:06:15	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-05-24 19:06:19	DEBUG	Punctuation handler ==>> text to process:hi
2019-05-24 19:06:19	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-05-24 19:06:19	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-05-24 19:06:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-24 19:06:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-24 19:06:19	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-05-24 19:06:31	DEBUG	Punctuation handler ==>> text to process:hi
2019-05-24 19:06:31	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-05-24 19:06:31	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-05-24 19:06:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-24 19:06:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-24 19:06:31	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-05-24 19:07:13	DEBUG	Punctuation handler ==>> text to process:hi
2019-05-24 19:07:13	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-05-24 19:07:13	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-05-24 19:07:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-24 19:07:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-24 19:07:13	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-05-24 19:07:40	DEBUG	Punctuation handler ==>> text to process:hi
2019-05-24 19:07:40	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-05-24 19:07:40	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-05-24 19:07:40	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-24 19:07:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-24 19:07:40	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-05-27 10:32:54	DEBUG	Punctuation handler ==>> text to process:this is bot failed message
2019-05-27 10:32:54	DEBUG	Tokenization handler ==>> takens:['this', 'is', 'bot', 'failed', 'message'] and tokenize_without_stop_words:[]
2019-05-27 10:32:54	DEBUG	Stemmer handler ==>> stem_tokens:['thi', 'is', 'bot', 'fail', 'messag'] and stem_without_stop_words:[]
2019-05-27 10:32:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-27 10:32:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-27 10:32:54	DEBUG	Ngram handler ==>> unigram:['thi', 'bot', 'fail', 'messag'] == bigram:['thi is', 'is bot', 'bot fail', 'fail messag'] == trigram:['thi is bot', 'is bot fail', 'bot fail messag']
2019-05-27 10:32:54	DEBUG	Punctuation handler ==>> text to process:this is welcome message of twitter bot
2019-05-27 10:32:54	DEBUG	Tokenization handler ==>> takens:['this', 'is', 'welcome', 'message', 'of', 'twitter', 'bot'] and tokenize_without_stop_words:[]
2019-05-27 10:32:54	DEBUG	Stemmer handler ==>> stem_tokens:['thi', 'is', 'welcom', 'messag', 'of', 'twitter', 'bot'] and stem_without_stop_words:[]
2019-05-27 10:32:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-27 10:32:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-27 10:32:54	DEBUG	Ngram handler ==>> unigram:['thi', 'welcom', 'messag', 'twitter', 'bot'] == bigram:['thi is', 'is welcom', 'welcom messag', 'messag of', 'of twitter', 'twitter bot'] == trigram:['thi is welcom', 'is welcom messag', 'welcom messag of', 'messag of twitter', 'of twitter bot']
2019-05-27 10:32:54	DEBUG	Punctuation handler ==>> text to process:this is welcome message of twitter bot
2019-05-27 10:32:54	DEBUG	Tokenization handler ==>> takens:['this', 'is', 'welcome', 'message', 'of', 'twitter', 'bot'] and tokenize_without_stop_words:[]
2019-05-27 10:32:54	DEBUG	Stemmer handler ==>> stem_tokens:['thi', 'is', 'welcom', 'messag', 'of', 'twitter', 'bot'] and stem_without_stop_words:[]
2019-05-27 10:32:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-27 10:32:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-27 10:32:54	DEBUG	Ngram handler ==>> unigram:['thi', 'welcom', 'messag', 'twitter', 'bot'] == bigram:['thi is', 'is welcom', 'welcom messag', 'messag of', 'of twitter', 'twitter bot'] == trigram:['thi is welcom', 'is welcom messag', 'welcom messag of', 'messag of twitter', 'of twitter bot']
2019-05-27 10:33:01	DEBUG	Punctuation handler ==>> text to process:this is fallback intent
2019-05-27 10:33:01	DEBUG	Tokenization handler ==>> takens:['this', 'is', 'fallback', 'intent'] and tokenize_without_stop_words:[]
2019-05-27 10:33:01	DEBUG	Stemmer handler ==>> stem_tokens:['thi', 'is', 'fallback', 'intent'] and stem_without_stop_words:[]
2019-05-27 10:33:01	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-27 10:33:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-27 10:33:01	DEBUG	Ngram handler ==>> unigram:['thi', 'fallback', 'intent'] == bigram:['thi is', 'is fallback', 'fallback intent'] == trigram:['thi is fallback', 'is fallback intent']
2019-05-27 10:33:01	DEBUG	Punctuation handler ==>> text to process:this is fallback intent
2019-05-27 10:33:01	DEBUG	Tokenization handler ==>> takens:['this', 'is', 'fallback', 'intent'] and tokenize_without_stop_words:[]
2019-05-27 10:33:01	DEBUG	Stemmer handler ==>> stem_tokens:['thi', 'is', 'fallback', 'intent'] and stem_without_stop_words:[]
2019-05-27 10:33:01	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-27 10:33:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-27 10:33:01	DEBUG	Ngram handler ==>> unigram:['thi', 'fallback', 'intent'] == bigram:['thi is', 'is fallback', 'fallback intent'] == trigram:['thi is fallback', 'is fallback intent']
2019-05-27 10:33:02	DEBUG	Punctuation handler ==>> text to process:this is fallback intent
2019-05-27 10:33:02	DEBUG	Tokenization handler ==>> takens:['this', 'is', 'fallback', 'intent'] and tokenize_without_stop_words:[]
2019-05-27 10:33:02	DEBUG	Stemmer handler ==>> stem_tokens:['thi', 'is', 'fallback', 'intent'] and stem_without_stop_words:[]
2019-05-27 10:33:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-27 10:33:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-27 10:33:02	DEBUG	Ngram handler ==>> unigram:['thi', 'fallback', 'intent'] == bigram:['thi is', 'is fallback', 'fallback intent'] == trigram:['thi is fallback', 'is fallback intent']
2019-05-27 10:33:03	DEBUG	Punctuation handler ==>> text to process:this is bot failed message
2019-05-27 10:33:03	DEBUG	Tokenization handler ==>> takens:['this', 'is', 'bot', 'failed', 'message'] and tokenize_without_stop_words:[]
2019-05-27 10:33:03	DEBUG	Stemmer handler ==>> stem_tokens:['thi', 'is', 'bot', 'fail', 'messag'] and stem_without_stop_words:[]
2019-05-27 10:33:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-27 10:33:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-27 10:33:03	DEBUG	Ngram handler ==>> unigram:['thi', 'bot', 'fail', 'messag'] == bigram:['thi is', 'is bot', 'bot fail', 'fail messag'] == trigram:['thi is bot', 'is bot fail', 'bot fail messag']
2019-05-27 10:33:08	DEBUG	Punctuation handler ==>> text to process:this is fallback intent
2019-05-27 10:33:08	DEBUG	Tokenization handler ==>> takens:['this', 'is', 'fallback', 'intent'] and tokenize_without_stop_words:[]
2019-05-27 10:33:08	DEBUG	Stemmer handler ==>> stem_tokens:['thi', 'is', 'fallback', 'intent'] and stem_without_stop_words:[]
2019-05-27 10:33:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-27 10:33:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-27 10:33:08	DEBUG	Ngram handler ==>> unigram:['thi', 'fallback', 'intent'] == bigram:['thi is', 'is fallback', 'fallback intent'] == trigram:['thi is fallback', 'is fallback intent']
2019-05-27 10:33:08	DEBUG	Punctuation handler ==>> text to process:this is fallback intent
2019-05-27 10:33:08	DEBUG	Tokenization handler ==>> takens:['this', 'is', 'fallback', 'intent'] and tokenize_without_stop_words:[]
2019-05-27 10:33:08	DEBUG	Stemmer handler ==>> stem_tokens:['thi', 'is', 'fallback', 'intent'] and stem_without_stop_words:[]
2019-05-27 10:33:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-27 10:33:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-27 10:33:08	DEBUG	Ngram handler ==>> unigram:['thi', 'fallback', 'intent'] == bigram:['thi is', 'is fallback', 'fallback intent'] == trigram:['thi is fallback', 'is fallback intent']
2019-05-27 10:33:09	DEBUG	Punctuation handler ==>> text to process:this is fallback intent
2019-05-27 10:33:09	DEBUG	Tokenization handler ==>> takens:['this', 'is', 'fallback', 'intent'] and tokenize_without_stop_words:[]
2019-05-27 10:33:09	DEBUG	Stemmer handler ==>> stem_tokens:['thi', 'is', 'fallback', 'intent'] and stem_without_stop_words:[]
2019-05-27 10:33:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-27 10:33:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-27 10:33:09	DEBUG	Ngram handler ==>> unigram:['thi', 'fallback', 'intent'] == bigram:['thi is', 'is fallback', 'fallback intent'] == trigram:['thi is fallback', 'is fallback intent']
2019-05-27 10:33:09	DEBUG	Punctuation handler ==>> text to process:this is fallback intent
2019-05-27 10:33:09	DEBUG	Tokenization handler ==>> takens:['this', 'is', 'fallback', 'intent'] and tokenize_without_stop_words:[]
2019-05-27 10:33:09	DEBUG	Stemmer handler ==>> stem_tokens:['thi', 'is', 'fallback', 'intent'] and stem_without_stop_words:[]
2019-05-27 10:33:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-27 10:33:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-27 10:33:09	DEBUG	Ngram handler ==>> unigram:['thi', 'fallback', 'intent'] == bigram:['thi is', 'is fallback', 'fallback intent'] == trigram:['thi is fallback', 'is fallback intent']
2019-05-27 10:33:10	DEBUG	Punctuation handler ==>> text to process:this is bot failed message
2019-05-27 10:33:10	DEBUG	Tokenization handler ==>> takens:['this', 'is', 'bot', 'failed', 'message'] and tokenize_without_stop_words:[]
2019-05-27 10:33:10	DEBUG	Stemmer handler ==>> stem_tokens:['thi', 'is', 'bot', 'fail', 'messag'] and stem_without_stop_words:[]
2019-05-27 10:33:10	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-27 10:33:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-27 10:33:10	DEBUG	Ngram handler ==>> unigram:['thi', 'bot', 'fail', 'messag'] == bigram:['thi is', 'is bot', 'bot fail', 'fail messag'] == trigram:['thi is bot', 'is bot fail', 'bot fail messag']
2019-05-27 10:33:15	DEBUG	Punctuation handler ==>> text to process:this is fallback intent
2019-05-27 10:33:15	DEBUG	Tokenization handler ==>> takens:['this', 'is', 'fallback', 'intent'] and tokenize_without_stop_words:[]
2019-05-27 10:33:15	DEBUG	Stemmer handler ==>> stem_tokens:['thi', 'is', 'fallback', 'intent'] and stem_without_stop_words:[]
2019-05-27 10:33:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-27 10:33:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-27 10:33:15	DEBUG	Ngram handler ==>> unigram:['thi', 'fallback', 'intent'] == bigram:['thi is', 'is fallback', 'fallback intent'] == trigram:['thi is fallback', 'is fallback intent']
2019-05-27 10:33:15	DEBUG	Punctuation handler ==>> text to process:this is fallback intent
2019-05-27 10:33:15	DEBUG	Tokenization handler ==>> takens:['this', 'is', 'fallback', 'intent'] and tokenize_without_stop_words:[]
2019-05-27 10:33:15	DEBUG	Stemmer handler ==>> stem_tokens:['thi', 'is', 'fallback', 'intent'] and stem_without_stop_words:[]
2019-05-27 10:33:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-27 10:33:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-27 10:33:15	DEBUG	Ngram handler ==>> unigram:['thi', 'fallback', 'intent'] == bigram:['thi is', 'is fallback', 'fallback intent'] == trigram:['thi is fallback', 'is fallback intent']
2019-05-27 10:33:15	DEBUG	Punctuation handler ==>> text to process:this is fallback intent
2019-05-27 10:33:15	DEBUG	Tokenization handler ==>> takens:['this', 'is', 'fallback', 'intent'] and tokenize_without_stop_words:[]
2019-05-27 10:33:15	DEBUG	Stemmer handler ==>> stem_tokens:['thi', 'is', 'fallback', 'intent'] and stem_without_stop_words:[]
2019-05-27 10:33:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-27 10:33:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-27 10:33:15	DEBUG	Ngram handler ==>> unigram:['thi', 'fallback', 'intent'] == bigram:['thi is', 'is fallback', 'fallback intent'] == trigram:['thi is fallback', 'is fallback intent']
2019-05-27 10:33:16	DEBUG	Punctuation handler ==>> text to process:this is fallback intent
2019-05-27 10:33:16	DEBUG	Tokenization handler ==>> takens:['this', 'is', 'fallback', 'intent'] and tokenize_without_stop_words:[]
2019-05-27 10:33:16	DEBUG	Punctuation handler ==>> text to process:this is fallback intent
2019-05-27 10:33:16	DEBUG	Stemmer handler ==>> stem_tokens:['thi', 'is', 'fallback', 'intent'] and stem_without_stop_words:[]
2019-05-27 10:33:16	DEBUG	Tokenization handler ==>> takens:['this', 'is', 'fallback', 'intent'] and tokenize_without_stop_words:[]
2019-05-27 10:33:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-27 10:33:16	DEBUG	Stemmer handler ==>> stem_tokens:['thi', 'is', 'fallback', 'intent'] and stem_without_stop_words:[]
2019-05-27 10:33:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-27 10:33:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-27 10:33:16	DEBUG	Ngram handler ==>> unigram:['thi', 'fallback', 'intent'] == bigram:['thi is', 'is fallback', 'fallback intent'] == trigram:['thi is fallback', 'is fallback intent']
2019-05-27 10:33:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-27 10:33:16	DEBUG	Ngram handler ==>> unigram:['thi', 'fallback', 'intent'] == bigram:['thi is', 'is fallback', 'fallback intent'] == trigram:['thi is fallback', 'is fallback intent']
2019-05-27 10:33:21	DEBUG	Punctuation handler ==>> text to process:this is fallback intent
2019-05-27 10:33:21	DEBUG	Tokenization handler ==>> takens:['this', 'is', 'fallback', 'intent'] and tokenize_without_stop_words:[]
2019-05-27 10:33:21	DEBUG	Stemmer handler ==>> stem_tokens:['thi', 'is', 'fallback', 'intent'] and stem_without_stop_words:[]
2019-05-27 10:33:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-27 10:33:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-27 10:33:21	DEBUG	Ngram handler ==>> unigram:['thi', 'fallback', 'intent'] == bigram:['thi is', 'is fallback', 'fallback intent'] == trigram:['thi is fallback', 'is fallback intent']
2019-05-27 10:33:22	DEBUG	Punctuation handler ==>> text to process:this is fallback intent
2019-05-27 10:33:22	DEBUG	Tokenization handler ==>> takens:['this', 'is', 'fallback', 'intent'] and tokenize_without_stop_words:[]
2019-05-27 10:33:22	DEBUG	Stemmer handler ==>> stem_tokens:['thi', 'is', 'fallback', 'intent'] and stem_without_stop_words:[]
2019-05-27 10:33:22	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-27 10:33:22	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-27 10:33:22	DEBUG	Ngram handler ==>> unigram:['thi', 'fallback', 'intent'] == bigram:['thi is', 'is fallback', 'fallback intent'] == trigram:['thi is fallback', 'is fallback intent']
2019-05-27 10:33:22	DEBUG	Punctuation handler ==>> text to process:this is fallback intent
2019-05-27 10:33:22	DEBUG	Tokenization handler ==>> takens:['this', 'is', 'fallback', 'intent'] and tokenize_without_stop_words:[]
2019-05-27 10:33:22	DEBUG	Stemmer handler ==>> stem_tokens:['thi', 'is', 'fallback', 'intent'] and stem_without_stop_words:[]
2019-05-27 10:33:22	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-27 10:33:22	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-27 10:33:22	DEBUG	Ngram handler ==>> unigram:['thi', 'fallback', 'intent'] == bigram:['thi is', 'is fallback', 'fallback intent'] == trigram:['thi is fallback', 'is fallback intent']
2019-05-27 10:33:22	DEBUG	Punctuation handler ==>> text to process:this is fallback intent
2019-05-27 10:33:22	DEBUG	Tokenization handler ==>> takens:['this', 'is', 'fallback', 'intent'] and tokenize_without_stop_words:[]
2019-05-27 10:33:22	DEBUG	Stemmer handler ==>> stem_tokens:['thi', 'is', 'fallback', 'intent'] and stem_without_stop_words:[]
2019-05-27 10:33:22	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-27 10:33:22	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-27 10:33:22	DEBUG	Ngram handler ==>> unigram:['thi', 'fallback', 'intent'] == bigram:['thi is', 'is fallback', 'fallback intent'] == trigram:['thi is fallback', 'is fallback intent']
2019-05-27 10:33:23	DEBUG	Punctuation handler ==>> text to process:this is fallback intent
2019-05-27 10:33:23	DEBUG	Tokenization handler ==>> takens:['this', 'is', 'fallback', 'intent'] and tokenize_without_stop_words:[]
2019-05-27 10:33:23	DEBUG	Stemmer handler ==>> stem_tokens:['thi', 'is', 'fallback', 'intent'] and stem_without_stop_words:[]
2019-05-27 10:33:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-27 10:33:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-27 10:33:23	DEBUG	Ngram handler ==>> unigram:['thi', 'fallback', 'intent'] == bigram:['thi is', 'is fallback', 'fallback intent'] == trigram:['thi is fallback', 'is fallback intent']
2019-05-27 10:33:27	DEBUG	Punctuation handler ==>> text to process:this is fallback intent
2019-05-27 10:33:27	DEBUG	Tokenization handler ==>> takens:['this', 'is', 'fallback', 'intent'] and tokenize_without_stop_words:[]
2019-05-27 10:33:27	DEBUG	Stemmer handler ==>> stem_tokens:['thi', 'is', 'fallback', 'intent'] and stem_without_stop_words:[]
2019-05-27 10:33:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-27 10:33:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-27 10:33:27	DEBUG	Ngram handler ==>> unigram:['thi', 'fallback', 'intent'] == bigram:['thi is', 'is fallback', 'fallback intent'] == trigram:['thi is fallback', 'is fallback intent']
2019-05-27 10:33:28	DEBUG	Punctuation handler ==>> text to process:this is fallback intent
2019-05-27 10:33:28	DEBUG	Tokenization handler ==>> takens:['this', 'is', 'fallback', 'intent'] and tokenize_without_stop_words:[]
2019-05-27 10:33:28	DEBUG	Stemmer handler ==>> stem_tokens:['thi', 'is', 'fallback', 'intent'] and stem_without_stop_words:[]
2019-05-27 10:33:28	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-27 10:33:28	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-27 10:33:28	DEBUG	Ngram handler ==>> unigram:['thi', 'fallback', 'intent'] == bigram:['thi is', 'is fallback', 'fallback intent'] == trigram:['thi is fallback', 'is fallback intent']
2019-05-27 10:35:46	DEBUG	Punctuation handler ==>> text to process:hi
2019-05-27 10:35:46	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-05-27 10:35:46	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-05-27 10:35:46	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-27 10:35:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-27 10:35:46	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-05-28 11:36:57	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-05-28 11:36:57	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-05-28 11:36:57	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-05-28 11:36:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-28 11:36:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-28 11:36:57	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-05-28 11:36:57	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-05-28 11:36:57	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-05-28 11:36:57	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-05-28 11:36:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-28 11:36:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-28 11:36:57	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-05-28 11:36:57	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-05-28 11:36:57	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-05-28 11:36:57	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-05-28 11:36:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-28 11:36:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-28 11:36:57	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-05-28 11:36:57	DEBUG	Punctuation handler ==>> text to process:recharge
2019-05-28 11:36:57	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-05-28 11:36:57	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-05-28 11:36:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-28 11:36:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-28 11:36:57	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-05-28 11:36:57	DEBUG	Punctuation handler ==>> text to process:travel
2019-05-28 11:36:57	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-05-28 11:36:57	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-05-28 11:36:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-28 11:36:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-28 11:36:57	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-05-28 11:36:57	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-05-28 11:36:57	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-05-28 11:36:57	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-05-28 11:36:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-28 11:36:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-28 11:36:57	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-05-28 11:36:57	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-05-28 11:36:57	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-05-28 11:36:57	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-05-28 11:36:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-28 11:36:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-28 11:36:57	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-05-28 11:36:57	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-05-28 11:36:57	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-05-28 11:36:57	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-05-28 11:36:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-28 11:36:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-28 11:36:57	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-05-28 11:38:30	DEBUG	Punctuation handler ==>> text to process:can you rechrage
2019-05-28 11:38:30	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'rechrage'] and tokenize_without_stop_words:[]
2019-05-28 11:38:30	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'rechrag'] and stem_without_stop_words:[]
2019-05-28 11:38:30	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-28 11:38:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-28 11:38:30	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['you rechrag'] == trigram:['can you rechrag']
2019-05-28 11:38:46	DEBUG	Punctuation handler ==>> text to process:rechrage
2019-05-28 11:38:46	DEBUG	Tokenization handler ==>> takens:['rechrage'] and tokenize_without_stop_words:[]
2019-05-28 11:38:46	DEBUG	Stemmer handler ==>> stem_tokens:['rechrag'] and stem_without_stop_words:[]
2019-05-28 11:38:46	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-28 11:38:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-28 11:38:46	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:[] == trigram:[]
2019-05-28 11:40:34	DEBUG	Punctuation handler ==>> text to process:hi
2019-05-28 11:40:34	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-05-28 11:40:34	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-05-28 11:40:34	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-28 11:40:34	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-28 11:40:34	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-05-28 11:44:10	DEBUG	Punctuation handler ==>> text to process:hi
2019-05-28 11:44:10	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-05-28 11:44:10	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-05-28 11:44:10	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-28 11:44:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-28 11:44:10	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-05-28 11:47:59	DEBUG	Punctuation handler ==>> text to process:hi
2019-05-28 11:47:59	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-05-28 11:47:59	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-05-28 11:47:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-28 11:47:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-28 11:47:59	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-05-28 11:49:12	DEBUG	Punctuation handler ==>> text to process:hi
2019-05-28 11:49:12	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-05-28 11:49:12	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-05-28 11:49:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-28 11:49:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-28 11:49:12	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-05-28 11:49:50	DEBUG	Punctuation handler ==>> text to process:hi
2019-05-28 11:49:50	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-05-28 11:49:50	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-05-28 11:49:50	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-28 11:49:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-28 11:49:50	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-05-28 11:51:46	DEBUG	Punctuation handler ==>> text to process:hi
2019-05-28 11:51:46	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-05-28 11:51:46	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-05-28 11:51:46	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-28 11:51:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-28 11:51:46	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-05-28 11:57:50	DEBUG	Punctuation handler ==>> text to process:hi
2019-05-28 11:57:50	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-05-28 11:57:50	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-05-28 11:57:50	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-28 11:57:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-28 11:57:50	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-05-28 11:58:42	DEBUG	Punctuation handler ==>> text to process:hi
2019-05-28 11:58:42	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-05-28 11:58:42	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-05-28 11:58:42	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-28 11:58:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-28 11:58:42	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-05-28 12:02:57	DEBUG	Punctuation handler ==>> text to process:hi
2019-05-28 12:02:57	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-05-28 12:02:57	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-05-28 12:02:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-28 12:02:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-28 12:02:57	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-05-28 12:06:32	DEBUG	Punctuation handler ==>> text to process:hi
2019-05-28 12:06:32	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-05-28 12:06:32	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-05-28 12:06:32	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-28 12:06:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-28 12:06:32	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-05-28 12:08:36	DEBUG	Punctuation handler ==>> text to process:hi
2019-05-28 12:08:36	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-05-28 12:08:36	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-05-28 12:08:36	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-28 12:08:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-28 12:08:36	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-05-28 12:09:15	DEBUG	Punctuation handler ==>> text to process:hi
2019-05-28 12:09:15	DEBUG	Tokenization handler ==>> takens:['hi'] and tokenize_without_stop_words:[]
2019-05-28 12:09:15	DEBUG	Stemmer handler ==>> stem_tokens:['hi'] and stem_without_stop_words:[]
2019-05-28 12:09:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-28 12:09:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-28 12:09:15	DEBUG	Ngram handler ==>> unigram:['hi'] == bigram:[] == trigram:[]
2019-05-29 11:39:31	DEBUG	Punctuation handler ==>> text to process:email address
2019-05-29 11:39:31	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-05-29 11:39:31	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-05-29 11:39:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-29 11:39:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-29 11:39:31	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-05-29 11:39:31	DEBUG	Punctuation handler ==>> text to process:email data
2019-05-29 11:39:31	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-05-29 11:39:31	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-05-29 11:39:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-29 11:39:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-29 11:39:31	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-05-29 11:39:31	DEBUG	Punctuation handler ==>> text to process:email address
2019-05-29 11:39:31	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-05-29 11:39:31	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-05-29 11:39:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-29 11:39:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-29 11:39:31	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-05-29 11:39:31	DEBUG	Punctuation handler ==>> text to process:name
2019-05-29 11:39:31	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-05-29 11:39:31	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-05-29 11:39:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-29 11:39:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-29 11:39:31	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-05-29 11:39:31	DEBUG	Punctuation handler ==>> text to process:username
2019-05-29 11:39:31	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-05-29 11:39:31	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-05-29 11:39:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-29 11:39:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-29 11:39:31	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-05-29 11:39:31	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-05-29 11:39:31	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-05-29 11:39:31	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-05-29 11:39:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-29 11:39:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-29 11:39:31	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-05-29 11:39:31	DEBUG	Punctuation handler ==>> text to process:text username
2019-05-29 11:39:31	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-05-29 11:39:31	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-05-29 11:39:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-29 11:39:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-29 11:39:31	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-05-29 11:40:39	DEBUG	Punctuation handler ==>> text to process:email address
2019-05-29 11:40:39	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-05-29 11:40:39	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-05-29 11:40:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-29 11:40:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-29 11:40:39	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-05-29 11:40:39	DEBUG	Punctuation handler ==>> text to process:email data
2019-05-29 11:40:39	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-05-29 11:40:39	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-05-29 11:40:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-29 11:40:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-29 11:40:39	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-05-29 11:40:39	DEBUG	Punctuation handler ==>> text to process:email address
2019-05-29 11:40:39	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-05-29 11:40:39	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-05-29 11:40:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-29 11:40:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-29 11:40:39	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-05-29 11:40:39	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-05-29 11:40:39	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-05-29 11:40:39	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-05-29 11:40:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-29 11:40:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-29 11:40:39	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-05-29 11:40:39	DEBUG	Punctuation handler ==>> text to process:username
2019-05-29 11:40:39	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-05-29 11:40:39	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-05-29 11:40:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-29 11:40:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-29 11:40:39	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-05-29 11:40:39	DEBUG	Punctuation handler ==>> text to process:name
2019-05-29 11:40:39	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-05-29 11:40:39	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-05-29 11:40:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-29 11:40:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-29 11:40:39	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-05-29 11:40:39	DEBUG	Punctuation handler ==>> text to process:text username
2019-05-29 11:40:39	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-05-29 11:40:39	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-05-29 11:40:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-05-29 11:40:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-05-29 11:40:39	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-04 17:25:49	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-04 17:25:49	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-04 17:25:49	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-04 17:25:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-04 17:25:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-04 17:25:49	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-04 17:25:49	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-04 17:25:49	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-04 17:25:49	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-04 17:25:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-04 17:25:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-04 17:25:49	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-04 17:25:49	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-04 17:25:49	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-04 17:25:49	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-04 17:25:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-04 17:25:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-04 17:25:49	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-04 17:25:49	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-04 17:25:49	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-04 17:25:49	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-04 17:25:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-04 17:25:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-04 17:25:49	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-04 17:25:49	DEBUG	Punctuation handler ==>> text to process:username
2019-06-04 17:25:49	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-04 17:25:49	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-04 17:25:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-04 17:25:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-04 17:25:49	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-04 17:25:49	DEBUG	Punctuation handler ==>> text to process:name
2019-06-04 17:25:49	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-04 17:25:49	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-04 17:25:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-04 17:25:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-04 17:25:49	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-04 17:25:49	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-04 17:25:49	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-04 17:25:49	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-04 17:25:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-04 17:25:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-04 17:25:49	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-04 17:25:57	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-04 17:25:57	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-04 17:25:57	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-04 17:25:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-04 17:25:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-04 17:25:57	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-04 17:25:57	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-04 17:25:57	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-04 17:25:57	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-04 17:25:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-04 17:25:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-04 17:25:57	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-04 17:25:57	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-04 17:25:57	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-04 17:25:57	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-04 17:25:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-04 17:25:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-04 17:25:57	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-04 17:25:57	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-04 17:25:57	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-04 17:25:57	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-04 17:25:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-04 17:25:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-04 17:25:57	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-04 17:25:57	DEBUG	Punctuation handler ==>> text to process:username
2019-06-04 17:25:57	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-04 17:25:57	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-04 17:25:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-04 17:25:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-04 17:25:57	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-04 17:25:57	DEBUG	Punctuation handler ==>> text to process:name
2019-06-04 17:25:57	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-04 17:25:57	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-04 17:25:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-04 17:25:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-04 17:25:57	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-04 17:25:57	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-04 17:25:57	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-04 17:25:57	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-04 17:25:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-04 17:25:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-04 17:25:57	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-04 17:27:24	DEBUG	Punctuation handler ==>> text to process:manish welcome message
2019-06-04 17:27:24	DEBUG	Tokenization handler ==>> takens:['manish', 'welcome', 'message'] and tokenize_without_stop_words:[]
2019-06-04 17:27:24	DEBUG	Stemmer handler ==>> stem_tokens:['manish', 'welcom', 'messag'] and stem_without_stop_words:[]
2019-06-04 17:27:24	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-04 17:27:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-04 17:27:24	DEBUG	Ngram handler ==>> unigram:['manish', 'welcom', 'messag'] == bigram:['manish welcom', 'welcom messag'] == trigram:['manish welcom messag']
2019-06-04 17:27:42	DEBUG	Punctuation handler ==>> text to process:manish welcome message
2019-06-04 17:27:42	DEBUG	Tokenization handler ==>> takens:['manish', 'welcome', 'message'] and tokenize_without_stop_words:[]
2019-06-04 17:27:42	DEBUG	Stemmer handler ==>> stem_tokens:['manish', 'welcom', 'messag'] and stem_without_stop_words:[]
2019-06-04 17:27:42	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-04 17:27:42	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-04 17:27:42	DEBUG	Ngram handler ==>> unigram:['manish', 'welcom', 'messag'] == bigram:['manish welcom', 'welcom messag'] == trigram:['manish welcom messag']
2019-06-04 17:28:57	DEBUG	Punctuation handler ==>> text to process:manish welcome message
2019-06-04 17:28:57	DEBUG	Tokenization handler ==>> takens:['manish', 'welcome', 'message'] and tokenize_without_stop_words:[]
2019-06-04 17:28:57	DEBUG	Stemmer handler ==>> stem_tokens:['manish', 'welcom', 'messag'] and stem_without_stop_words:[]
2019-06-04 17:28:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-04 17:28:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-04 17:28:57	DEBUG	Ngram handler ==>> unigram:['manish', 'welcom', 'messag'] == bigram:['manish welcom', 'welcom messag'] == trigram:['manish welcom messag']
2019-06-04 17:35:35	DEBUG	Punctuation handler ==>> text to process:manish welcome message
2019-06-04 17:35:35	DEBUG	Tokenization handler ==>> takens:['manish', 'welcome', 'message'] and tokenize_without_stop_words:[]
2019-06-04 17:35:35	DEBUG	Stemmer handler ==>> stem_tokens:['manish', 'welcom', 'messag'] and stem_without_stop_words:[]
2019-06-04 17:35:35	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-04 17:35:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-04 17:35:35	DEBUG	Ngram handler ==>> unigram:['manish', 'welcom', 'messag'] == bigram:['manish welcom', 'welcom messag'] == trigram:['manish welcom messag']
2019-06-07 18:30:37	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-07 18:30:37	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-07 18:30:37	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-07 18:30:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:30:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:30:37	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-07 18:30:37	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-07 18:30:37	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-07 18:30:37	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-07 18:30:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:30:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:30:37	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-07 18:30:37	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-07 18:30:37	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-07 18:30:37	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-07 18:30:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:30:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:30:37	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-07 18:30:37	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-07 18:30:37	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-07 18:30:37	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-07 18:30:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:30:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:30:37	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-07 18:30:37	DEBUG	Punctuation handler ==>> text to process:username
2019-06-07 18:30:37	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-07 18:30:37	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-07 18:30:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:30:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:30:37	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-07 18:30:37	DEBUG	Punctuation handler ==>> text to process:name
2019-06-07 18:30:37	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-07 18:30:37	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-07 18:30:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:30:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:30:38	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-07 18:30:38	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-07 18:30:38	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-07 18:30:38	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-07 18:30:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:30:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:30:38	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-07 18:30:38	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-07 18:30:38	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-07 18:30:38	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:30:39	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-07 18:30:39	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-07 18:30:39	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:30:39	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-07 18:30:39	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-07 18:30:39	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:30:39	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-07 18:30:39	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-07 18:30:39	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:30:39	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-07 18:30:39	DEBUG	Punctuation handler ==>> text to process:username
2019-06-07 18:30:39	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:30:39	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-07 18:30:39	DEBUG	Punctuation handler ==>> text to process:name
2019-06-07 18:30:39	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:30:39	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-07 18:30:39	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-07 18:30:39	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:30:39	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-07 18:30:39	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-07 18:30:39	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:30:39	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-07 18:30:39	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-07 18:30:39	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:30:39	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-07 18:30:39	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-07 18:30:39	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:30:39	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-07 18:30:39	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-07 18:30:39	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:30:39	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-07 18:30:39	DEBUG	Punctuation handler ==>> text to process:username
2019-06-07 18:30:39	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:30:39	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-07 18:30:39	DEBUG	Punctuation handler ==>> text to process:name
2019-06-07 18:30:39	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:30:39	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-07 18:30:39	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-07 18:30:39	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:30:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:30:39	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-07 18:31:07	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-07 18:31:07	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-07 18:31:07	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-07 18:31:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:31:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:31:07	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-07 18:31:07	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-07 18:31:07	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-07 18:31:07	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-07 18:31:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:31:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:31:07	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-07 18:31:07	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-07 18:31:07	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-07 18:31:07	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-07 18:31:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:31:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:31:07	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-07 18:31:07	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-07 18:31:07	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-07 18:31:07	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-07 18:31:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:31:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:31:07	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-07 18:31:07	DEBUG	Punctuation handler ==>> text to process:username
2019-06-07 18:31:07	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-07 18:31:07	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-07 18:31:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:31:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:31:07	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-07 18:31:07	DEBUG	Punctuation handler ==>> text to process:name
2019-06-07 18:31:07	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-07 18:31:07	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-07 18:31:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:31:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:31:07	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-07 18:31:07	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-07 18:31:07	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-07 18:31:07	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-07 18:31:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:31:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:31:07	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-07 18:31:08	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-07 18:31:08	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:31:08	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-07 18:31:08	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-07 18:31:08	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:31:08	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-07 18:31:08	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-07 18:31:08	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:31:08	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-07 18:31:08	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-07 18:31:08	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:31:08	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-07 18:31:08	DEBUG	Punctuation handler ==>> text to process:username
2019-06-07 18:31:08	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:31:08	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-07 18:31:08	DEBUG	Punctuation handler ==>> text to process:name
2019-06-07 18:31:08	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:31:08	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-07 18:31:08	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-07 18:31:08	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:31:08	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-07 18:31:08	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-07 18:31:08	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:31:08	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-07 18:31:08	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-07 18:31:08	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:31:08	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-07 18:31:08	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-07 18:31:08	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:31:08	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-07 18:31:08	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-07 18:31:08	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:31:08	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-07 18:31:08	DEBUG	Punctuation handler ==>> text to process:username
2019-06-07 18:31:08	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:31:08	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-07 18:31:08	DEBUG	Punctuation handler ==>> text to process:name
2019-06-07 18:31:08	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:31:08	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-07 18:31:08	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-07 18:31:08	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:31:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:31:08	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-07 18:37:54	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-07 18:37:54	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-07 18:37:54	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-07 18:37:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:37:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:37:54	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-07 18:37:54	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-07 18:37:54	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-07 18:37:54	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-07 18:37:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:37:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:37:54	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-07 18:37:54	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-07 18:37:54	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-07 18:37:54	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-07 18:37:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:37:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:37:54	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-07 18:37:54	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-07 18:37:54	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-07 18:37:54	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-07 18:37:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:37:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:37:54	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-07 18:37:54	DEBUG	Punctuation handler ==>> text to process:username
2019-06-07 18:37:54	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-07 18:37:54	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-07 18:37:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:37:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:37:54	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-07 18:37:54	DEBUG	Punctuation handler ==>> text to process:name
2019-06-07 18:37:54	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-07 18:37:54	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-07 18:37:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:37:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:37:54	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-07 18:37:54	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-07 18:37:54	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-07 18:37:54	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-07 18:37:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:37:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:37:54	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-07 18:38:28	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-07 18:38:28	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-07 18:38:28	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-07 18:38:28	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:38:28	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:38:28	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-07 18:38:28	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-07 18:38:28	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-07 18:38:28	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-07 18:38:28	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:38:28	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:38:28	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-07 18:38:28	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-07 18:38:28	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-07 18:38:28	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-07 18:38:28	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:38:28	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:38:28	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-07 18:38:28	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-07 18:38:28	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-07 18:38:28	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-07 18:38:28	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:38:28	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:38:28	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-07 18:38:28	DEBUG	Punctuation handler ==>> text to process:username
2019-06-07 18:38:28	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-07 18:38:28	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-07 18:38:28	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:38:28	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:38:28	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-07 18:38:28	DEBUG	Punctuation handler ==>> text to process:name
2019-06-07 18:38:28	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-07 18:38:28	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-07 18:38:28	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:38:28	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:38:28	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-07 18:38:28	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-07 18:38:28	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-07 18:38:28	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-07 18:38:28	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:38:28	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:38:28	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-07 18:38:30	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-07 18:38:30	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-07 18:38:30	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-07 18:38:30	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:38:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:38:30	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-07 18:38:30	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-07 18:38:30	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-07 18:38:30	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-07 18:38:30	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:38:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:38:30	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-07 18:38:30	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-07 18:38:30	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-07 18:38:30	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-07 18:38:30	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:38:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:38:30	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-07 18:38:30	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-07 18:38:30	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-07 18:38:30	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-07 18:38:30	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:38:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:38:30	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-07 18:38:30	DEBUG	Punctuation handler ==>> text to process:username
2019-06-07 18:38:30	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-07 18:38:30	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-07 18:38:30	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:38:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:38:30	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-07 18:38:30	DEBUG	Punctuation handler ==>> text to process:name
2019-06-07 18:38:30	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-07 18:38:30	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-07 18:38:30	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:38:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:38:30	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-07 18:38:30	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-07 18:38:30	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-07 18:38:30	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-07 18:38:30	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:38:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:38:30	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-07 18:41:16	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-07 18:41:16	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-07 18:41:16	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-07 18:41:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:41:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:41:16	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-07 18:41:16	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-07 18:41:16	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-07 18:41:16	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-07 18:41:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:41:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:41:16	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-07 18:41:16	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-07 18:41:16	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-07 18:41:16	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-07 18:41:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:41:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:41:16	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-07 18:41:16	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-07 18:41:16	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-07 18:41:16	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-07 18:41:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:41:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:41:16	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-07 18:41:16	DEBUG	Punctuation handler ==>> text to process:username
2019-06-07 18:41:16	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-07 18:41:16	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-07 18:41:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:41:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:41:16	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-07 18:41:16	DEBUG	Punctuation handler ==>> text to process:name
2019-06-07 18:41:16	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-07 18:41:16	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-07 18:41:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:41:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:41:16	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-07 18:41:16	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-07 18:41:16	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-07 18:41:16	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-07 18:41:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:41:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:41:16	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-07 18:41:18	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-07 18:41:18	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-07 18:41:18	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-07 18:41:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:41:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:41:18	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-07 18:41:18	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-07 18:41:18	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-07 18:41:18	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-07 18:41:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:41:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:41:18	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-07 18:41:18	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-07 18:41:18	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-07 18:41:18	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-07 18:41:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:41:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:41:18	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-07 18:41:18	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-07 18:41:18	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-07 18:41:18	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-07 18:41:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:41:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:41:18	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-07 18:41:18	DEBUG	Punctuation handler ==>> text to process:username
2019-06-07 18:41:18	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-07 18:41:18	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-07 18:41:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:41:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:41:18	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-07 18:41:18	DEBUG	Punctuation handler ==>> text to process:name
2019-06-07 18:41:18	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-07 18:41:18	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-07 18:41:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:41:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:41:18	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-07 18:41:18	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-07 18:41:18	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-07 18:41:18	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-07 18:41:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:41:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:41:18	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-07 18:42:31	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-07 18:42:31	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-07 18:42:31	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-07 18:42:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:42:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:42:31	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-07 18:42:31	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-07 18:42:31	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-07 18:42:31	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-07 18:42:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:42:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:42:31	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-07 18:42:31	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-07 18:42:31	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-07 18:42:31	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-07 18:42:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:42:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:42:31	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-07 18:42:31	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-07 18:42:31	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-07 18:42:31	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-07 18:42:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:42:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:42:31	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-07 18:42:31	DEBUG	Punctuation handler ==>> text to process:username
2019-06-07 18:42:31	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-07 18:42:31	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-07 18:42:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:42:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:42:31	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-07 18:42:31	DEBUG	Punctuation handler ==>> text to process:name
2019-06-07 18:42:31	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-07 18:42:31	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-07 18:42:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:42:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:42:31	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-07 18:42:31	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-07 18:42:31	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-07 18:42:31	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-07 18:42:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:42:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:42:31	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-07 18:42:33	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-07 18:42:33	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-07 18:42:33	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-07 18:42:33	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:42:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:42:33	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-07 18:42:33	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-07 18:42:33	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-07 18:42:33	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-07 18:42:33	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:42:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:42:33	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-07 18:42:33	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-07 18:42:33	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-07 18:42:33	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-07 18:42:33	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:42:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:42:33	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-07 18:42:33	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-07 18:42:33	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-07 18:42:33	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-07 18:42:33	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:42:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:42:33	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-07 18:42:33	DEBUG	Punctuation handler ==>> text to process:username
2019-06-07 18:42:33	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-07 18:42:33	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-07 18:42:33	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:42:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:42:33	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-07 18:42:33	DEBUG	Punctuation handler ==>> text to process:name
2019-06-07 18:42:33	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-07 18:42:33	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-07 18:42:33	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:42:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:42:33	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-07 18:42:33	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-07 18:42:33	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-07 18:42:33	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-07 18:42:33	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 18:42:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 18:42:33	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-07 19:00:18	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-07 19:00:18	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-07 19:00:18	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-07 19:00:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 19:00:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 19:00:18	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-07 19:00:18	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-07 19:00:18	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-07 19:00:18	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-07 19:00:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 19:00:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 19:00:18	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-07 19:00:18	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-07 19:00:18	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-07 19:00:18	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-07 19:00:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 19:00:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 19:00:18	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-07 19:00:18	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-07 19:00:18	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-07 19:00:18	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-07 19:00:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 19:00:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 19:00:18	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-07 19:00:18	DEBUG	Punctuation handler ==>> text to process:username
2019-06-07 19:00:18	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-07 19:00:18	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-07 19:00:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 19:00:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 19:00:18	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-07 19:00:18	DEBUG	Punctuation handler ==>> text to process:name
2019-06-07 19:00:18	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-07 19:00:18	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-07 19:00:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 19:00:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 19:00:18	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-07 19:00:18	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-07 19:00:18	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-07 19:00:18	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-07 19:00:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-07 19:00:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-07 19:00:18	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-10 11:33:57	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-10 11:33:57	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-10 11:33:57	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-10 11:33:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:33:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:33:57	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-10 11:33:57	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-10 11:33:57	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-10 11:33:57	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-10 11:33:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:33:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:33:57	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-10 11:33:57	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-10 11:33:57	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-10 11:33:57	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-10 11:33:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:33:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:33:57	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-10 11:33:57	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-10 11:33:57	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-10 11:33:57	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-10 11:33:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:33:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:33:57	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-10 11:33:57	DEBUG	Punctuation handler ==>> text to process:username
2019-06-10 11:33:57	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-10 11:33:57	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-10 11:33:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:33:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:33:57	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-10 11:33:57	DEBUG	Punctuation handler ==>> text to process:name
2019-06-10 11:33:57	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-10 11:33:57	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-10 11:33:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:33:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:33:57	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-10 11:33:57	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-10 11:33:57	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-10 11:33:57	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-10 11:33:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:33:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:33:57	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-10 11:42:43	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-10 11:42:43	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:42:43	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-10 11:42:43	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-10 11:42:43	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:42:43	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-10 11:42:43	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-10 11:42:43	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:42:43	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-10 11:42:43	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-10 11:42:43	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:42:43	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-10 11:42:43	DEBUG	Punctuation handler ==>> text to process:username
2019-06-10 11:42:43	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:42:43	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-10 11:42:43	DEBUG	Punctuation handler ==>> text to process:name
2019-06-10 11:42:43	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:42:43	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-10 11:42:43	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-10 11:42:43	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:42:43	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-10 11:42:43	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-10 11:42:43	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:42:43	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-10 11:42:43	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-10 11:42:43	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:42:43	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-10 11:42:43	DEBUG	Punctuation handler ==>> text to process:email address
2019-06-10 11:42:43	DEBUG	Tokenization handler ==>> takens:['email', 'address'] and tokenize_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'address'] and stem_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:42:43	DEBUG	Ngram handler ==>> unigram:['email', 'address'] == bigram:['email address'] == trigram:[]
2019-06-10 11:42:43	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-10 11:42:43	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:42:43	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-10 11:42:43	DEBUG	Punctuation handler ==>> text to process:username
2019-06-10 11:42:43	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:42:43	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-10 11:42:43	DEBUG	Punctuation handler ==>> text to process:name
2019-06-10 11:42:43	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:42:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:42:43	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-10 11:42:43	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-10 11:42:43	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-10 11:42:44	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-10 11:42:44	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:42:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:42:44	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-10 11:59:09	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-10 11:59:09	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-10 11:59:09	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-10 11:59:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:59:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:59:09	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-10 11:59:09	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-10 11:59:09	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-10 11:59:09	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-10 11:59:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:59:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:59:09	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-10 11:59:09	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-10 11:59:09	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-10 11:59:09	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-10 11:59:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:59:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:59:09	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-10 11:59:09	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-10 11:59:09	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-10 11:59:09	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-10 11:59:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:59:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:59:09	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-10 11:59:09	DEBUG	Punctuation handler ==>> text to process:username
2019-06-10 11:59:09	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-10 11:59:09	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-10 11:59:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:59:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:59:09	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-10 11:59:09	DEBUG	Punctuation handler ==>> text to process:name
2019-06-10 11:59:09	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-10 11:59:09	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-10 11:59:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:59:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:59:09	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-10 11:59:09	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-10 11:59:09	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-10 11:59:09	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-10 11:59:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:59:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:59:09	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-10 11:59:10	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-10 11:59:10	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-10 11:59:10	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-10 11:59:10	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:59:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:59:10	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-10 11:59:10	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-10 11:59:10	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-10 11:59:10	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-10 11:59:10	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:59:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:59:10	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-10 11:59:10	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-10 11:59:10	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-10 11:59:10	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-10 11:59:10	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:59:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:59:10	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-10 11:59:10	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-10 11:59:10	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-10 11:59:10	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-10 11:59:10	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:59:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:59:10	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-10 11:59:10	DEBUG	Punctuation handler ==>> text to process:username
2019-06-10 11:59:10	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-10 11:59:10	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-10 11:59:10	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:59:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:59:10	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-10 11:59:10	DEBUG	Punctuation handler ==>> text to process:name
2019-06-10 11:59:10	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-10 11:59:10	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-10 11:59:10	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:59:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:59:10	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-10 11:59:10	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-10 11:59:10	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-10 11:59:10	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-10 11:59:10	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 11:59:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 11:59:10	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-10 12:05:58	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-10 12:05:58	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-10 12:05:58	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-10 12:05:58	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 12:05:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 12:05:58	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-10 12:05:58	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-10 12:05:58	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-10 12:05:58	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-10 12:05:58	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 12:05:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 12:05:58	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-10 12:05:58	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-10 12:05:58	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-10 12:05:58	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-10 12:05:58	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 12:05:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 12:05:58	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-10 12:05:58	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-10 12:05:58	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-10 12:05:58	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-10 12:05:58	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 12:05:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 12:05:58	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-10 12:05:58	DEBUG	Punctuation handler ==>> text to process:username
2019-06-10 12:05:58	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-10 12:05:58	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-10 12:05:58	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 12:05:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 12:05:58	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-10 12:05:58	DEBUG	Punctuation handler ==>> text to process:name
2019-06-10 12:05:58	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-10 12:05:58	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-10 12:05:58	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 12:05:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 12:05:58	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-10 12:05:58	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-10 12:05:58	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-10 12:05:58	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-10 12:05:58	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 12:05:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 12:05:58	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-10 12:05:59	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-10 12:05:59	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-10 12:05:59	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-10 12:05:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 12:05:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 12:05:59	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-10 12:05:59	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-10 12:05:59	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-10 12:05:59	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-10 12:05:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 12:05:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 12:05:59	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-10 12:05:59	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-10 12:05:59	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-10 12:05:59	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-10 12:05:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 12:05:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 12:05:59	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-10 12:05:59	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-10 12:05:59	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-10 12:05:59	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-10 12:05:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 12:05:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 12:05:59	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-10 12:05:59	DEBUG	Punctuation handler ==>> text to process:username
2019-06-10 12:05:59	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-10 12:05:59	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-10 12:05:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 12:05:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 12:05:59	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-10 12:05:59	DEBUG	Punctuation handler ==>> text to process:name
2019-06-10 12:05:59	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-10 12:05:59	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-10 12:05:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 12:06:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 12:06:00	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-10 12:06:00	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-10 12:06:00	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-10 12:06:00	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-10 12:06:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 12:06:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 12:06:00	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-10 17:10:56	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-10 17:10:56	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-10 17:10:56	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-10 17:10:56	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 17:10:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 17:10:56	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-10 17:10:56	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-10 17:10:56	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-10 17:10:56	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-10 17:10:56	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 17:10:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 17:10:56	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-10 17:10:56	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-10 17:10:56	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-10 17:10:56	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-10 17:10:56	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 17:10:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 17:10:56	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-10 17:10:56	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-10 17:10:56	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-10 17:10:57	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-10 17:10:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 17:10:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 17:10:57	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-10 17:10:57	DEBUG	Punctuation handler ==>> text to process:username
2019-06-10 17:10:57	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-10 17:10:57	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-10 17:10:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 17:10:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 17:10:57	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-10 17:10:57	DEBUG	Punctuation handler ==>> text to process:name
2019-06-10 17:10:57	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-10 17:10:57	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-10 17:10:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 17:10:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 17:10:57	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-10 17:10:57	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-10 17:10:57	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-10 17:10:57	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-10 17:10:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 17:10:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 17:10:57	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-10 18:19:41	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-10 18:19:41	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-10 18:19:41	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-10 18:19:41	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 18:19:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 18:19:41	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-10 18:19:41	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-10 18:19:41	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-10 18:19:41	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-10 18:19:41	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 18:19:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 18:19:41	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-10 18:19:41	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-10 18:19:41	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-10 18:19:41	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-10 18:19:41	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 18:19:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 18:19:41	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-10 18:19:41	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-10 18:19:41	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-10 18:19:41	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-10 18:19:41	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 18:19:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 18:19:41	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-10 18:19:41	DEBUG	Punctuation handler ==>> text to process:username
2019-06-10 18:19:41	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-10 18:19:41	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-10 18:19:41	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 18:19:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 18:19:41	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-10 18:19:41	DEBUG	Punctuation handler ==>> text to process:name
2019-06-10 18:19:41	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-10 18:19:41	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-10 18:19:41	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 18:19:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 18:19:41	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-10 18:19:41	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-10 18:19:41	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-10 18:19:41	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-10 18:19:41	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-10 18:19:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-10 18:19:41	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-11 11:50:05	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-11 11:50:05	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-11 11:50:05	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-11 11:50:05	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-11 11:50:05	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-11 11:50:05	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-11 11:50:05	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-11 11:50:05	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-11 11:50:05	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-11 11:50:05	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-11 11:50:05	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-11 11:50:05	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-11 11:50:05	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-11 11:50:05	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-11 11:50:05	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-11 11:50:05	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-11 11:50:05	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-11 11:50:05	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-11 11:50:05	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-11 11:50:05	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-11 11:50:05	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-11 11:50:05	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-11 11:50:05	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-11 11:50:05	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-11 11:50:05	DEBUG	Punctuation handler ==>> text to process:username
2019-06-11 11:50:05	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-11 11:50:05	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-11 11:50:05	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-11 11:50:05	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-11 11:50:05	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-11 11:50:05	DEBUG	Punctuation handler ==>> text to process:name
2019-06-11 11:50:05	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-11 11:50:05	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-11 11:50:05	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-11 11:50:05	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-11 11:50:05	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-11 11:50:05	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-11 11:50:05	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-11 11:50:05	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-11 11:50:05	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-11 11:50:05	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-11 11:50:05	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-11 19:17:12	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-11 19:17:12	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-11 19:17:12	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-11 19:17:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-11 19:17:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-11 19:17:12	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-11 19:17:12	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-11 19:17:12	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-11 19:17:12	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-11 19:17:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-11 19:17:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-11 19:17:12	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-11 19:17:12	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-11 19:17:12	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-11 19:17:12	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-11 19:17:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-11 19:17:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-11 19:17:12	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-11 19:17:12	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-11 19:17:12	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-11 19:17:12	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-11 19:17:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-11 19:17:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-11 19:17:12	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-11 19:17:12	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-11 19:17:12	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-11 19:17:12	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-11 19:17:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-11 19:17:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-11 19:17:12	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-11 19:17:13	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-11 19:17:13	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-11 19:17:13	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-11 19:17:13	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-11 19:17:13	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-11 19:17:13	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-11 19:17:13	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-11 19:17:13	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-11 19:17:13	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-11 19:17:13	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-11 19:17:13	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-11 19:17:13	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-11 19:17:13	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-11 19:17:13	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-11 19:17:13	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-11 19:17:13	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-11 19:17:13	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-11 19:17:13	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-11 19:17:13	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-11 19:17:13	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-11 19:17:13	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-11 19:17:13	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-11 19:17:13	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-11 19:17:13	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-11 19:17:13	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-11 19:17:13	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-11 19:17:13	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-11 19:17:13	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-11 19:17:13	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-11 19:17:13	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-11 19:17:13	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-11 19:17:13	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-11 19:17:13	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-11 19:17:13	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-11 19:17:13	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-11 19:17:13	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-11 19:17:13	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-11 19:17:13	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-11 19:17:13	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-11 19:17:13	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-11 19:17:13	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-11 19:17:13	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-11 19:17:13	DEBUG	Punctuation handler ==>> text to process:username
2019-06-11 19:17:13	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-11 19:17:13	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-11 19:17:13	DEBUG	Punctuation handler ==>> text to process:name
2019-06-11 19:17:13	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-11 19:17:13	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-11 19:17:13	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-11 19:17:13	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-11 19:17:13	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-11 19:17:13	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-11 19:17:13	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-11 19:17:13	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-11 19:17:13	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-11 19:17:13	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-11 19:17:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-11 19:17:13	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 10:22:26	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 10:22:26	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:22:26	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 10:22:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:22:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:22:26	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 10:22:26	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 10:22:26	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 10:22:26	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 10:22:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:22:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:22:26	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 10:22:26	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 10:22:26	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 10:22:26	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 10:22:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:22:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:22:26	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 10:22:26	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 10:22:26	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 10:22:26	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 10:22:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:22:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:22:26	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 10:22:26	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 10:22:26	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 10:22:26	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 10:22:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:22:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:22:26	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 10:22:27	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 10:22:27	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:22:27	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 10:22:27	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 10:22:27	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:22:27	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 10:22:27	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 10:22:27	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:22:27	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 10:22:27	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 10:22:27	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:22:27	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 10:22:27	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 10:22:27	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:22:27	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 10:22:27	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 10:22:27	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:22:27	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 10:22:27	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 10:22:27	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:22:27	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 10:22:27	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 10:22:27	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:22:27	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 10:22:27	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 10:22:27	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:22:27	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 10:22:27	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 10:22:27	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:22:27	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 10:22:27	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 10:22:27	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:22:27	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 10:22:27	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 10:22:27	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:22:27	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 10:22:27	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 10:22:27	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:22:27	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 10:22:27	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 10:22:27	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:22:27	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 10:22:27	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 10:22:27	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:22:27	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 10:22:27	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 10:22:27	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:22:27	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 10:22:27	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 10:22:27	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:22:27	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 10:22:27	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 10:22:27	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:22:27	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 10:22:27	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 10:22:27	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:22:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:22:27	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 10:32:52	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 10:32:52	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:32:52	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 10:32:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:32:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:32:52	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 10:32:52	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 10:32:52	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 10:32:52	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 10:32:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:32:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:32:52	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 10:32:52	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 10:32:52	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 10:32:52	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 10:32:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:32:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:32:52	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 10:32:52	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 10:32:52	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 10:32:52	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 10:32:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:32:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:32:52	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 10:32:52	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 10:32:52	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 10:32:52	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 10:32:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:32:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:32:52	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 10:32:54	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 10:32:54	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:32:54	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 10:32:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:32:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:32:54	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 10:32:54	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 10:32:54	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 10:32:54	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 10:32:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:32:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:32:54	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 10:32:54	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 10:32:54	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 10:32:54	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 10:32:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:32:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:32:54	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 10:32:54	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 10:32:54	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 10:32:54	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 10:32:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:32:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:32:54	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 10:32:54	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 10:32:54	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 10:32:54	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 10:32:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:32:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:32:54	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 10:32:54	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 10:32:54	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 10:32:54	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 10:32:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:32:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:32:54	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 10:32:54	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 10:32:54	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 10:32:54	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 10:32:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:32:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:32:54	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 10:32:54	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 10:32:54	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 10:32:54	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 10:32:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:32:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:32:54	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 10:32:54	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 10:32:54	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 10:32:54	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 10:32:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:32:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:32:54	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 10:32:54	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 10:32:54	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 10:32:54	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 10:32:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:32:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:32:54	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 10:32:55	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 10:32:55	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 10:32:55	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 10:32:55	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:32:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:32:55	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 10:32:55	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 10:32:55	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 10:32:55	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 10:32:55	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:32:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:32:55	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 10:32:55	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 10:32:55	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 10:32:55	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 10:32:55	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:32:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:32:55	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 10:32:55	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 10:32:55	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:32:55	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 10:32:55	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:32:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:32:55	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 10:32:55	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 10:32:55	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 10:32:55	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 10:32:55	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:32:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:32:55	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 10:32:55	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 10:32:55	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 10:32:55	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 10:32:55	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:32:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:32:55	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 10:32:55	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 10:32:55	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 10:32:55	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 10:32:55	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:32:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:32:55	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 10:32:55	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 10:32:55	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:32:55	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 10:32:55	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:32:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:32:55	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 10:32:55	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 10:32:55	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 10:32:55	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 10:32:55	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:32:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:32:55	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 10:33:18	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 10:33:18	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:33:18	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 10:33:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:18	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 10:33:18	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 10:33:18	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 10:33:18	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 10:33:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:18	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 10:33:18	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 10:33:18	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 10:33:18	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 10:33:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:18	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 10:33:18	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 10:33:18	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 10:33:18	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 10:33:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:18	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 10:33:18	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 10:33:18	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 10:33:18	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 10:33:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:18	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 10:33:20	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 10:33:20	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:33:20	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 10:33:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:20	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 10:33:20	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 10:33:20	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 10:33:20	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 10:33:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:20	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 10:33:20	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 10:33:20	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 10:33:20	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 10:33:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:20	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 10:33:20	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 10:33:20	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 10:33:20	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 10:33:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:20	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 10:33:20	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 10:33:20	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 10:33:20	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 10:33:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:20	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 10:33:20	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 10:33:20	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 10:33:20	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 10:33:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:20	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 10:33:20	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 10:33:20	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 10:33:20	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 10:33:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:20	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 10:33:20	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 10:33:20	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 10:33:20	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 10:33:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:20	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 10:33:20	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 10:33:20	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 10:33:20	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 10:33:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:20	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 10:33:20	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 10:33:20	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 10:33:20	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 10:33:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:20	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 10:33:21	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 10:33:21	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 10:33:21	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 10:33:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:21	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 10:33:21	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 10:33:21	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 10:33:21	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 10:33:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:21	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 10:33:21	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 10:33:21	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 10:33:21	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 10:33:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:21	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 10:33:21	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 10:33:21	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:33:21	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 10:33:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:21	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 10:33:21	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 10:33:21	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 10:33:21	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 10:33:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:21	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 10:33:21	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 10:33:21	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 10:33:21	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 10:33:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:21	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 10:33:21	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 10:33:21	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 10:33:21	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 10:33:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:21	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 10:33:21	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 10:33:21	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:33:21	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 10:33:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:21	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 10:33:21	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 10:33:21	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 10:33:21	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 10:33:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:21	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 10:33:48	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 10:33:48	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:33:48	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 10:33:48	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:49	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 10:33:49	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 10:33:49	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:49	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 10:33:49	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 10:33:49	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:49	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 10:33:49	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 10:33:49	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:49	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 10:33:49	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 10:33:49	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:49	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 10:33:49	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 10:33:49	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:49	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 10:33:49	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 10:33:49	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:49	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 10:33:49	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 10:33:49	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:49	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 10:33:49	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 10:33:49	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:49	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 10:33:49	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 10:33:49	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:49	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 10:33:49	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 10:33:49	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:49	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 10:33:49	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 10:33:49	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:49	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 10:33:49	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 10:33:49	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:49	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 10:33:49	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 10:33:49	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:49	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 10:33:49	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 10:33:49	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:49	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 10:33:49	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 10:33:49	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:49	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 10:33:49	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 10:33:49	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:49	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 10:33:49	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 10:33:49	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:49	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 10:33:49	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 10:33:49	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:49	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 10:33:49	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 10:33:49	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:49	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 10:33:49	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 10:33:49	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:49	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 10:33:49	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 10:33:49	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:49	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 10:33:49	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 10:33:49	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:49	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 10:33:49	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 10:33:49	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:33:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:33:49	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 10:40:35	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 10:40:35	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:40:35	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 10:40:35	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 10:40:35	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:40:35	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 10:40:35	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 10:40:35	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:40:35	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 10:40:35	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 10:40:35	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:40:35	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 10:40:35	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 10:40:35	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:40:35	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 10:40:35	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 10:40:35	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:40:35	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 10:40:35	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 10:40:35	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:40:35	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 10:40:35	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 10:40:35	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:40:35	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 10:40:35	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 10:40:35	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:40:35	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 10:40:35	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 10:40:35	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:40:35	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 10:40:35	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 10:40:35	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:40:35	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 10:40:35	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 10:40:35	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:40:35	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 10:40:35	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 10:40:35	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:40:35	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 10:40:35	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 10:40:35	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:40:35	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 10:40:35	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 10:40:35	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:40:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:40:35	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 10:40:36	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 10:40:36	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 10:40:36	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 10:40:36	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:40:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:40:36	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 10:40:36	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 10:40:36	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 10:40:36	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 10:40:36	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:40:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:40:36	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 10:40:36	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 10:40:36	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 10:40:36	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 10:40:36	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:40:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:40:36	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 10:40:36	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 10:40:36	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:40:36	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 10:40:36	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:40:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:40:36	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 10:40:36	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 10:40:36	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 10:40:36	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 10:40:36	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:40:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:40:36	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 10:40:36	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 10:40:36	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 10:40:36	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 10:40:36	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:40:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:40:36	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 10:40:36	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 10:40:36	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 10:40:36	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 10:40:36	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:40:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:40:37	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 10:40:37	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 10:40:37	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:40:37	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 10:40:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:40:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:40:37	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 10:40:37	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 10:40:37	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 10:40:37	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 10:40:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:40:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:40:37	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 10:41:05	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 10:41:05	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:41:05	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 10:41:05	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:41:05	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:41:05	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 10:41:05	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 10:41:05	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 10:41:05	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 10:41:05	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:41:05	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:41:05	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 10:41:05	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 10:41:05	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 10:41:05	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 10:41:05	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:41:05	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:41:05	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 10:41:05	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 10:41:05	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 10:41:05	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 10:41:05	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:41:05	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:41:05	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 10:41:05	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 10:41:05	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 10:41:05	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 10:41:05	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:41:05	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:41:05	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 10:41:07	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 10:41:07	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:41:07	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 10:41:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:41:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:41:07	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 10:41:07	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 10:41:07	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 10:41:07	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 10:41:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:41:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:41:07	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 10:41:07	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 10:41:07	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 10:41:07	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 10:41:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:41:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:41:07	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 10:41:07	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 10:41:07	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 10:41:07	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 10:41:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:41:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:41:07	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 10:41:07	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 10:41:07	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 10:41:07	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 10:41:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:41:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:41:07	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 10:41:07	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 10:41:07	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 10:41:07	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 10:41:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:41:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:41:07	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 10:41:07	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 10:41:07	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 10:41:07	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 10:41:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:41:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:41:07	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 10:41:07	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 10:41:07	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 10:41:07	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 10:41:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:41:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:41:07	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 10:41:07	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 10:41:07	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 10:41:07	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 10:41:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:41:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:41:07	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 10:41:07	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 10:41:07	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 10:41:07	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 10:41:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:41:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:41:07	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 10:41:08	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 10:41:08	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 10:41:08	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 10:41:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:41:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:41:08	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 10:41:08	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 10:41:08	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 10:41:08	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 10:41:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:41:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:41:08	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 10:41:08	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 10:41:08	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 10:41:08	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 10:41:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:41:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:41:08	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 10:41:08	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 10:41:08	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:41:08	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 10:41:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:41:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:41:08	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 10:41:08	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 10:41:08	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 10:41:08	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 10:41:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:41:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:41:08	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 10:41:08	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 10:41:08	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 10:41:08	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 10:41:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:41:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:41:08	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 10:41:08	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 10:41:08	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 10:41:08	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 10:41:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:41:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:41:08	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 10:41:08	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 10:41:08	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:41:08	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 10:41:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:41:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:41:08	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 10:41:08	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 10:41:08	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 10:41:08	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 10:41:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:41:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:41:08	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 10:42:10	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 10:42:10	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:42:10	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 10:42:10	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:10	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 10:42:10	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 10:42:10	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 10:42:10	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 10:42:10	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:10	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 10:42:10	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 10:42:10	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 10:42:10	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 10:42:10	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:10	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 10:42:10	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 10:42:10	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 10:42:10	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 10:42:10	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:10	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 10:42:10	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 10:42:10	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 10:42:10	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 10:42:10	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:10	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:10	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 10:42:11	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 10:42:11	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:42:11	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 10:42:11	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:11	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 10:42:11	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 10:42:11	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 10:42:11	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 10:42:11	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:11	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 10:42:11	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 10:42:11	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 10:42:11	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 10:42:11	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:11	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 10:42:11	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 10:42:11	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 10:42:11	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 10:42:11	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:11	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 10:42:11	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 10:42:11	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 10:42:11	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 10:42:11	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:11	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 10:42:11	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 10:42:11	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 10:42:11	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 10:42:11	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:11	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 10:42:11	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 10:42:11	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 10:42:11	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 10:42:11	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:12	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 10:42:12	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 10:42:12	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 10:42:12	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 10:42:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:12	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 10:42:12	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 10:42:12	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 10:42:12	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 10:42:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:12	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 10:42:12	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 10:42:12	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 10:42:12	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 10:42:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:12	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 10:42:12	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 10:42:12	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 10:42:12	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 10:42:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:12	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 10:42:12	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 10:42:12	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 10:42:12	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 10:42:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:12	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 10:42:12	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 10:42:12	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 10:42:12	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 10:42:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:12	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 10:42:12	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 10:42:12	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:42:12	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 10:42:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:12	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 10:42:12	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 10:42:12	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 10:42:12	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 10:42:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:12	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 10:42:12	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 10:42:12	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 10:42:12	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 10:42:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:12	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 10:42:12	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 10:42:12	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 10:42:12	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 10:42:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:13	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 10:42:13	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 10:42:13	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:42:13	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 10:42:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:13	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 10:42:13	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 10:42:13	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 10:42:13	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 10:42:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:13	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 10:42:38	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 10:42:38	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:42:38	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 10:42:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:38	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 10:42:38	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 10:42:38	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 10:42:38	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 10:42:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:38	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 10:42:38	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 10:42:38	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 10:42:38	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 10:42:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:38	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 10:42:38	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 10:42:38	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 10:42:38	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 10:42:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:38	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 10:42:38	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 10:42:38	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 10:42:38	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 10:42:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:38	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 10:42:40	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 10:42:40	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:42:40	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 10:42:40	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:40	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 10:42:40	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 10:42:40	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 10:42:40	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 10:42:40	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:40	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 10:42:40	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 10:42:40	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 10:42:40	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 10:42:40	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:40	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 10:42:40	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 10:42:40	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 10:42:40	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 10:42:40	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:40	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 10:42:40	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 10:42:40	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 10:42:40	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 10:42:40	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:40	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 10:42:40	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 10:42:40	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 10:42:40	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 10:42:40	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:40	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 10:42:40	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 10:42:40	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 10:42:40	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 10:42:40	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:40	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 10:42:40	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 10:42:40	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 10:42:40	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 10:42:40	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:40	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 10:42:40	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 10:42:40	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 10:42:40	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 10:42:40	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:40	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 10:42:40	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 10:42:40	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 10:42:40	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 10:42:40	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:40	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 10:42:41	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 10:42:41	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 10:42:41	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 10:42:41	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:41	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 10:42:41	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 10:42:41	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 10:42:41	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 10:42:41	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:41	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 10:42:41	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 10:42:41	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 10:42:41	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 10:42:41	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:41	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 10:42:41	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 10:42:41	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:42:41	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 10:42:41	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:41	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 10:42:41	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 10:42:41	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 10:42:41	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 10:42:41	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:41	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 10:42:41	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 10:42:41	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 10:42:41	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 10:42:41	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:41	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 10:42:41	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 10:42:41	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 10:42:41	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 10:42:41	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:41	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 10:42:41	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 10:42:41	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:42:41	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 10:42:41	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:41	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 10:42:41	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 10:42:41	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 10:42:41	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 10:42:41	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:42:41	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:42:41	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 10:44:44	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 10:44:44	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 10:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:44:44	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 10:44:44	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 10:44:44	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 10:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 10:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:44:44	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 10:44:44	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 10:44:44	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 10:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 10:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:44:44	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 10:44:44	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 10:44:44	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 10:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 10:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:44:44	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 10:44:44	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 10:44:44	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 10:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 10:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:44:44	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 10:44:44	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 10:44:44	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 10:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:44:44	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 10:44:44	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 10:44:44	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 10:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 10:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:44:44	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 10:44:44	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 10:44:44	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 10:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 10:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:44:44	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 10:44:44	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 10:44:44	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 10:44:44	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 10:44:44	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:44:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:44:44	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 10:44:44	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 10:44:45	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:44:45	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 10:44:45	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 10:44:45	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:44:45	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 10:44:45	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 10:44:45	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:44:45	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 10:44:45	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 10:44:45	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:44:45	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 10:44:45	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 10:44:45	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:44:45	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 10:44:45	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 10:44:45	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:44:45	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 10:44:45	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 10:44:45	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:44:45	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 10:44:45	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 10:44:45	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:44:45	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 10:44:45	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 10:44:45	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:44:45	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 10:44:45	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 10:44:45	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:44:45	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 10:44:45	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 10:44:45	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:44:45	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 10:44:45	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 10:44:45	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:44:45	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 10:44:45	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 10:44:45	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:44:45	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 10:44:45	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 10:44:45	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:44:45	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 10:44:45	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 10:44:45	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 10:44:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 10:44:45	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 11:07:49	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 11:07:49	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:07:49	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 11:07:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:07:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:07:49	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 11:07:50	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 11:07:50	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 11:07:50	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 11:07:50	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:07:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:07:50	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 11:07:51	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 11:07:51	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 11:07:51	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 11:07:51	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:07:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:07:51	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 11:07:52	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 11:07:52	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 11:07:52	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 11:07:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:07:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:07:52	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 11:07:54	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 11:07:54	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 11:07:54	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 11:07:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:07:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:07:54	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 11:07:55	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 11:07:55	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:07:55	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 11:07:55	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:07:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:07:55	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 11:07:55	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 11:07:55	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 11:07:55	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 11:07:55	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:07:55	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:07:55	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 11:07:56	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 11:07:56	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 11:07:56	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 11:07:56	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:07:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:07:56	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 11:07:57	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 11:07:57	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 11:07:57	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 11:07:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:07:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:07:57	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 11:07:58	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 11:07:58	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 11:07:58	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 11:07:58	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:07:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:07:58	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 11:07:58	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 11:07:58	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 11:07:58	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 11:07:58	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:07:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:07:58	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 11:07:59	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 11:07:59	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 11:07:59	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 11:07:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:07:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:07:59	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 11:07:59	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 11:07:59	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 11:07:59	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 11:07:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:07:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:07:59	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 11:08:00	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 11:08:00	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 11:08:00	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 11:08:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:08:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:08:00	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 11:08:00	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 11:08:00	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 11:08:00	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 11:08:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:08:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:08:00	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 11:08:00	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 11:08:00	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 11:08:00	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 11:08:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:08:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:08:00	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 11:08:01	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 11:08:01	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 11:08:01	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 11:08:01	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:08:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:08:01	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 11:08:01	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 11:08:01	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 11:08:01	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 11:08:01	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:08:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:08:01	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 11:08:02	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 11:08:02	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:08:02	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 11:08:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:08:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:08:02	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 11:08:02	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 11:08:02	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 11:08:02	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 11:08:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:08:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:08:02	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 11:08:02	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 11:08:02	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 11:08:02	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 11:08:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:08:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:08:02	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 11:08:03	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 11:08:03	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 11:08:03	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 11:08:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:08:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:08:03	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 11:08:04	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 11:08:04	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:08:04	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 11:08:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:08:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:08:04	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 11:08:06	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 11:08:06	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 11:08:06	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 11:08:06	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:08:06	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:08:06	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 11:13:07	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 11:13:07	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:13:07	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 11:13:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:13:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:13:07	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 11:13:07	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 11:13:07	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 11:13:07	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 11:13:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:13:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:13:07	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 11:13:07	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 11:13:07	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 11:13:07	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 11:13:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:13:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:13:07	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 11:13:07	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 11:13:07	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 11:13:07	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 11:13:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:13:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:13:07	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 11:13:07	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 11:13:07	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 11:13:07	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 11:13:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:13:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:13:07	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 11:13:08	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 11:13:08	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:13:08	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 11:13:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:13:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:13:08	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 11:13:08	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 11:13:08	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 11:13:08	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 11:13:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:13:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:13:08	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 11:13:08	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 11:13:08	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 11:13:08	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 11:13:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:13:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:13:08	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 11:13:08	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 11:13:08	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 11:13:08	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 11:13:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:13:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:13:08	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 11:13:08	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 11:13:08	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 11:13:08	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 11:13:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:13:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:13:08	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 11:13:08	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 11:13:08	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 11:13:08	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 11:13:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:13:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:13:08	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 11:13:08	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 11:13:08	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 11:13:08	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 11:13:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:13:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:13:08	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 11:13:08	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 11:13:08	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 11:13:08	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 11:13:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:13:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:13:08	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 11:13:08	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 11:13:08	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 11:13:08	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 11:13:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:13:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:13:08	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 11:13:08	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 11:13:08	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 11:13:08	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 11:13:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:13:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:13:08	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 11:13:09	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 11:13:09	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 11:13:09	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 11:13:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:13:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:13:09	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 11:13:09	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 11:13:09	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 11:13:09	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 11:13:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:13:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:13:09	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 11:13:09	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 11:13:09	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 11:13:09	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 11:13:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:13:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:13:09	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 11:13:09	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 11:13:09	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:13:09	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 11:13:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:13:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:13:09	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 11:13:09	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 11:13:09	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 11:13:09	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 11:13:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:13:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:13:09	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 11:13:09	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 11:13:09	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 11:13:09	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 11:13:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:13:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:13:09	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 11:13:09	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 11:13:09	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 11:13:09	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 11:13:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:13:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:13:09	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 11:13:09	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 11:13:09	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:13:09	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 11:13:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:13:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:13:09	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 11:13:09	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 11:13:09	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 11:13:09	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 11:13:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:13:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:13:09	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 11:14:04	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 11:14:04	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:14:04	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 11:14:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:04	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 11:14:04	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 11:14:04	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 11:14:04	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 11:14:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:04	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 11:14:04	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 11:14:04	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 11:14:04	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 11:14:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:04	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 11:14:04	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 11:14:04	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 11:14:04	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 11:14:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:04	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 11:14:04	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 11:14:04	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 11:14:04	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 11:14:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:04	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 11:14:06	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 11:14:06	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:14:06	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 11:14:06	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:06	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:06	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 11:14:06	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 11:14:06	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 11:14:06	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 11:14:06	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:06	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:06	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 11:14:06	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 11:14:06	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 11:14:06	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 11:14:06	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:06	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:06	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 11:14:06	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 11:14:06	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 11:14:06	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 11:14:06	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:06	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:06	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 11:14:06	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 11:14:06	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 11:14:06	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 11:14:06	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:06	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:06	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 11:14:06	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 11:14:06	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 11:14:06	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 11:14:06	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:06	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:06	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 11:14:06	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 11:14:06	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 11:14:06	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 11:14:06	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:06	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:06	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 11:14:06	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 11:14:06	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 11:14:06	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 11:14:06	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:06	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:06	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 11:14:06	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 11:14:06	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 11:14:06	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 11:14:06	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:06	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:06	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 11:14:06	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 11:14:06	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 11:14:06	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 11:14:06	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:06	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:06	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 11:14:07	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 11:14:07	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 11:14:07	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 11:14:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:07	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 11:14:07	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 11:14:07	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 11:14:07	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 11:14:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:07	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 11:14:07	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 11:14:07	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 11:14:07	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 11:14:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:07	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 11:14:07	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 11:14:07	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:14:07	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 11:14:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:07	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 11:14:07	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 11:14:07	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 11:14:07	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 11:14:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:07	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 11:14:07	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 11:14:07	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 11:14:07	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 11:14:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:07	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 11:14:07	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 11:14:07	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 11:14:07	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 11:14:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:07	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 11:14:07	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 11:14:07	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:14:07	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 11:14:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:07	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 11:14:07	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 11:14:07	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 11:14:07	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 11:14:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:07	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 11:14:25	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 11:14:25	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:14:25	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 11:14:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:25	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 11:14:25	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 11:14:25	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 11:14:25	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 11:14:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:25	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 11:14:25	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 11:14:25	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 11:14:25	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 11:14:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:25	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 11:14:25	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 11:14:25	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 11:14:25	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 11:14:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:25	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 11:14:25	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 11:14:25	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 11:14:25	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 11:14:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:25	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 11:14:26	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 11:14:26	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:14:26	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 11:14:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:26	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 11:14:26	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 11:14:26	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 11:14:27	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 11:14:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:27	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 11:14:27	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 11:14:27	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 11:14:27	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 11:14:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:27	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 11:14:27	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 11:14:27	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 11:14:27	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 11:14:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:27	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 11:14:27	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 11:14:27	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 11:14:27	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 11:14:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:27	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 11:14:27	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 11:14:27	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 11:14:27	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 11:14:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:27	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 11:14:27	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 11:14:27	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 11:14:27	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 11:14:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:27	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 11:14:27	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 11:14:27	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 11:14:27	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 11:14:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:27	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 11:14:27	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 11:14:27	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 11:14:27	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 11:14:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:27	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 11:14:27	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 11:14:27	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 11:14:27	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 11:14:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:27	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 11:14:28	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 11:14:28	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 11:14:28	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 11:14:28	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:28	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:28	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 11:14:28	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 11:14:28	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 11:14:28	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 11:14:28	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:28	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:28	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 11:14:28	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 11:14:28	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 11:14:28	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 11:14:28	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:28	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:28	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 11:14:28	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 11:14:28	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:14:28	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 11:14:28	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:28	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:28	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 11:14:28	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 11:14:28	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 11:14:28	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 11:14:28	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:28	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:28	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 11:14:28	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 11:14:28	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 11:14:28	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 11:14:28	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:28	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:28	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 11:14:28	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 11:14:28	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 11:14:28	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 11:14:28	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:28	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:28	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 11:14:28	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 11:14:28	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:14:28	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 11:14:28	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:28	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:28	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 11:14:28	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 11:14:28	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 11:14:28	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 11:14:28	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:14:28	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:14:28	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 11:18:25	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 11:18:25	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:18:25	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 11:18:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:18:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:18:25	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 11:18:25	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 11:18:25	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 11:18:25	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 11:18:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:18:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:18:25	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 11:18:25	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 11:18:25	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 11:18:25	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 11:18:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:18:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:18:25	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 11:18:25	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 11:18:25	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 11:18:25	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 11:18:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:18:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:18:25	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 11:18:25	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 11:18:25	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 11:18:25	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 11:18:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:18:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:18:25	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 11:18:26	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 11:18:26	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:18:26	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 11:18:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:18:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:18:26	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 11:18:26	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 11:18:26	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 11:18:26	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 11:18:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:18:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:18:26	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 11:18:26	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 11:18:26	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 11:18:26	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 11:18:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:18:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:18:26	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 11:18:27	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 11:18:27	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:18:27	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 11:18:27	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 11:18:27	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:18:27	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 11:18:27	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 11:18:27	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:18:27	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 11:18:27	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 11:18:27	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:18:27	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 11:18:27	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 11:18:27	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:18:27	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 11:18:27	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 11:18:27	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:18:27	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 11:18:27	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 11:18:27	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:18:27	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 11:18:27	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 11:18:27	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:18:27	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 11:18:27	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 11:18:27	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:18:27	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 11:18:27	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 11:18:27	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:18:27	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 11:18:27	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 11:18:27	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:18:27	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 11:18:27	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 11:18:27	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:18:27	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 11:18:27	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 11:18:27	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:18:27	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 11:18:27	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 11:18:27	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:18:27	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 11:18:27	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 11:18:27	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:18:27	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 11:18:27	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 11:18:27	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:18:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:18:27	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 11:19:39	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 11:19:39	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:19:39	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 11:19:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:19:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:19:39	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 11:19:39	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 11:19:39	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 11:19:39	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 11:19:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:19:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:19:39	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 11:19:39	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 11:19:39	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 11:19:39	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 11:19:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:19:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:19:39	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 11:19:39	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 11:19:39	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 11:19:39	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 11:19:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:19:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:19:39	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 11:19:39	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 11:19:39	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 11:19:39	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 11:19:39	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:19:39	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:19:39	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 11:19:45	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 11:19:45	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:19:45	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 11:19:45	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 11:19:45	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:19:45	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 11:19:45	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 11:19:45	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:19:45	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 11:19:45	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 11:19:45	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:19:45	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 11:19:45	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 11:19:45	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:19:45	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 11:19:45	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 11:19:45	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:19:45	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 11:19:45	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 11:19:45	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:19:45	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 11:19:45	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 11:19:45	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:19:45	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 11:19:45	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 11:19:45	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:19:45	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 11:19:45	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 11:19:45	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:19:45	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 11:19:45	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 11:19:45	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:19:45	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 11:19:45	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 11:19:45	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:19:45	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 11:19:45	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 11:19:45	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:19:45	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 11:19:45	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 11:19:45	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:19:45	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 11:19:45	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 11:19:45	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:19:45	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 11:19:45	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 11:19:45	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:19:45	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 11:19:45	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 11:19:45	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:19:45	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 11:19:45	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 11:19:45	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:19:45	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 11:19:45	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 11:19:45	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:19:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:19:45	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 11:27:21	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 11:27:21	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:27:21	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 11:27:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:27:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:27:21	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 11:27:21	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 11:27:21	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 11:27:21	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 11:27:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:27:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:27:21	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 11:27:21	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 11:27:21	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 11:27:21	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 11:27:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:27:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:27:21	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 11:27:21	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 11:27:21	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 11:27:21	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 11:27:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:27:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:27:21	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 11:27:21	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 11:27:21	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 11:27:21	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 11:27:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:27:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:27:21	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 11:27:23	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 11:27:23	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:27:23	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 11:27:23	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 11:27:23	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:27:23	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 11:27:23	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 11:27:23	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:27:23	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 11:27:23	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 11:27:23	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:27:23	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 11:27:23	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 11:27:23	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:27:23	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 11:27:23	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 11:27:23	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:27:23	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 11:27:23	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 11:27:23	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:27:23	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 11:27:23	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 11:27:23	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:27:23	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 11:27:23	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 11:27:23	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:27:23	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 11:27:23	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 11:27:23	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:27:23	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 11:27:23	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 11:27:23	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:27:23	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 11:27:23	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 11:27:23	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:27:23	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 11:27:23	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 11:27:23	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:27:23	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 11:27:23	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 11:27:23	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:27:23	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 11:27:23	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 11:27:23	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:27:23	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 11:27:23	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 11:27:23	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:27:23	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 11:27:23	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 11:27:23	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:27:23	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 11:27:23	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 11:27:23	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:27:23	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 11:27:23	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 11:27:23	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 11:27:23	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 11:27:24	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:27:24	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:27:24	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 11:41:47	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 11:41:47	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:41:47	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 11:41:47	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:41:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:41:47	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 11:41:47	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 11:41:47	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 11:41:47	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 11:41:47	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:41:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:41:47	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 11:41:47	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 11:41:47	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 11:41:47	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 11:41:47	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:41:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:41:47	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 11:41:47	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 11:41:47	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 11:41:47	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 11:41:47	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:41:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:41:47	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 11:41:47	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 11:41:47	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 11:41:47	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 11:41:47	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:41:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:41:47	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 11:41:48	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 11:41:48	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:41:48	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 11:41:48	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 11:41:48	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:41:48	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 11:41:48	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 11:41:48	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:41:48	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 11:41:48	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 11:41:48	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:41:48	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 11:41:48	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 11:41:48	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:41:48	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 11:41:48	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 11:41:48	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:41:48	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 11:41:48	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 11:41:48	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:41:48	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 11:41:48	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 11:41:48	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:41:48	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 11:41:48	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 11:41:48	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:41:48	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 11:41:48	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 11:41:48	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:41:48	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 11:41:48	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 11:41:48	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:41:48	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 11:41:48	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 11:41:48	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:41:48	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 11:41:48	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 11:41:48	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:41:48	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 11:41:48	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 11:41:48	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:41:48	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 11:41:48	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 11:41:48	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 11:41:48	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:41:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:41:49	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 11:41:49	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 11:41:49	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 11:41:49	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 11:41:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:41:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:41:49	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 11:41:49	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 11:41:49	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 11:41:49	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 11:41:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:41:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:41:49	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 11:41:49	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 11:41:49	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 11:41:49	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 11:41:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:41:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:41:49	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 11:41:49	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 11:41:49	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 11:41:49	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 11:41:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 11:41:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 11:41:49	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 12:15:13	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 12:15:13	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 12:15:13	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 12:15:14	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:15:14	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:15:14	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 12:15:14	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 12:15:14	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 12:15:14	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 12:15:14	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:15:14	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:15:14	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 12:15:14	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 12:15:14	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 12:15:14	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 12:15:14	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:15:14	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:15:14	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 12:15:14	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 12:15:14	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 12:15:14	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 12:15:14	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:15:14	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:15:14	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 12:15:14	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 12:15:14	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 12:15:14	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 12:15:14	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:15:14	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:15:14	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 12:15:14	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 12:15:15	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:15:15	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 12:15:15	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 12:15:15	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:15:15	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 12:15:15	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 12:15:15	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:15:15	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 12:15:15	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 12:15:15	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:15:15	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 12:15:15	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 12:15:15	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:15:15	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 12:15:15	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 12:15:15	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:15:15	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 12:15:15	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 12:15:15	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:15:15	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 12:15:15	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 12:15:15	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:15:15	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 12:15:15	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 12:15:15	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:15:15	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 12:15:15	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 12:15:15	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:15:15	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 12:15:15	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 12:15:15	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:15:15	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 12:15:15	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 12:15:15	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:15:15	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 12:15:15	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 12:15:15	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:15:15	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 12:15:15	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 12:15:15	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:15:15	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 12:15:15	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 12:15:15	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:15:15	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 12:15:15	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 12:15:15	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:15:15	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 12:15:15	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 12:15:15	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:15:15	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 12:15:15	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 12:15:15	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:15:15	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 12:15:15	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 12:15:15	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:15:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:15:15	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 12:22:02	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 12:22:02	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 12:22:02	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 12:22:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:22:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:22:02	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 12:22:02	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 12:22:02	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 12:22:02	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 12:22:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:22:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:22:02	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 12:22:02	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 12:22:02	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 12:22:02	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 12:22:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:22:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:22:02	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 12:22:02	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 12:22:02	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 12:22:02	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 12:22:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:22:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:22:02	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 12:22:02	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 12:22:02	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 12:22:02	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 12:22:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:22:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:22:03	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 12:22:03	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 12:22:03	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 12:22:03	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 12:22:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:22:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:22:03	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 12:22:03	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 12:22:03	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 12:22:03	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 12:22:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:22:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:22:03	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 12:22:03	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 12:22:03	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 12:22:03	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 12:22:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:22:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:22:03	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 12:22:03	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 12:22:03	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 12:22:03	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 12:22:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:22:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:22:03	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 12:22:03	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 12:22:03	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 12:22:03	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 12:22:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:22:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:22:03	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 12:22:03	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 12:22:03	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 12:22:03	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 12:22:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:22:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:22:03	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 12:22:03	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 12:22:03	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:22:04	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 12:22:04	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 12:22:04	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:22:04	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 12:22:04	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 12:22:04	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:22:04	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 12:22:04	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 12:22:04	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:22:04	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 12:22:04	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 12:22:04	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:22:04	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 12:22:04	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 12:22:04	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:22:04	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 12:22:04	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 12:22:04	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:22:04	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 12:22:04	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 12:22:04	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:22:04	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 12:22:04	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 12:22:04	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:22:04	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 12:22:04	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 12:22:04	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:22:04	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 12:22:04	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 12:22:04	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:22:04	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 12:22:04	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 12:22:04	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:22:04	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 12:22:04	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 12:22:04	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:22:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:22:04	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 12:30:19	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 12:30:19	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 12:30:19	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 12:30:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:30:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:30:19	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 12:30:19	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 12:30:19	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 12:30:19	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 12:30:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:30:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:30:19	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 12:30:19	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 12:30:19	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 12:30:19	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 12:30:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:30:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:30:19	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 12:30:19	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 12:30:19	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 12:30:19	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 12:30:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:30:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:30:19	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 12:30:19	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 12:30:19	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 12:30:19	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 12:30:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:30:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:30:19	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 12:30:20	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 12:30:20	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 12:30:20	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 12:30:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:30:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:30:20	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 12:30:20	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 12:30:20	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 12:30:20	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 12:30:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:30:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:30:20	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 12:30:20	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 12:30:20	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 12:30:20	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 12:30:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:30:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:30:20	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 12:30:20	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 12:30:20	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 12:30:20	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 12:30:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:30:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:30:20	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 12:30:20	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 12:30:20	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 12:30:20	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 12:30:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:30:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:30:20	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 12:30:20	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 12:30:21	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:30:21	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 12:30:21	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 12:30:21	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:30:21	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 12:30:21	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 12:30:21	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:30:21	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 12:30:21	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 12:30:21	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:30:21	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 12:30:21	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 12:30:21	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:30:21	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 12:30:21	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 12:30:21	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:30:21	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 12:30:21	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 12:30:21	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:30:21	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 12:30:21	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 12:30:21	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:30:21	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 12:30:21	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 12:30:21	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:30:21	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 12:30:21	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 12:30:21	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:30:21	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 12:30:21	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 12:30:21	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:30:21	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 12:30:21	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 12:30:21	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:30:21	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 12:30:21	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 12:30:21	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:30:21	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 12:30:21	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 12:30:21	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:30:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:30:21	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 12:31:21	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 12:31:21	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 12:31:21	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 12:31:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:21	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 12:31:21	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 12:31:21	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 12:31:21	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 12:31:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:21	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 12:31:21	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 12:31:21	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 12:31:21	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 12:31:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:21	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 12:31:21	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 12:31:21	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 12:31:21	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 12:31:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:21	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 12:31:21	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 12:31:21	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 12:31:21	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 12:31:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:21	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 12:31:38	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 12:31:38	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:38	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 12:31:38	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 12:31:38	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:38	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 12:31:38	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 12:31:38	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:38	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 12:31:38	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 12:31:38	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:38	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 12:31:38	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 12:31:38	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:38	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 12:31:38	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 12:31:38	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:38	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 12:31:38	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 12:31:38	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:38	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 12:31:38	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 12:31:38	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:38	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 12:31:38	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 12:31:38	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:38	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 12:31:38	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 12:31:38	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:38	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 12:31:38	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 12:31:38	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:38	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 12:31:38	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 12:31:38	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:38	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 12:31:38	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 12:31:38	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:38	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 12:31:38	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 12:31:38	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:38	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 12:31:38	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 12:31:38	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:38	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 12:31:38	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 12:31:38	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:38	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 12:31:38	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 12:31:38	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:38	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 12:31:38	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 12:31:38	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:38	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 12:31:38	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 12:31:38	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:38	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 12:31:59	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 12:31:59	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:59	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 12:31:59	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 12:31:59	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:59	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 12:31:59	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 12:31:59	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:59	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 12:31:59	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 12:31:59	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:59	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 12:31:59	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 12:31:59	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:59	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 12:31:59	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 12:31:59	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:59	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 12:31:59	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 12:31:59	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:59	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 12:31:59	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 12:31:59	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:59	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 12:31:59	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 12:31:59	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:59	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 12:31:59	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 12:31:59	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:59	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 12:31:59	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 12:31:59	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:59	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 12:31:59	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 12:31:59	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:59	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 12:31:59	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 12:31:59	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:59	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 12:31:59	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 12:31:59	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:59	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 12:31:59	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 12:31:59	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:59	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 12:31:59	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 12:31:59	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:31:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:31:59	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 12:32:00	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 12:32:00	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 12:32:00	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 12:32:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:32:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:32:00	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 12:32:00	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 12:32:00	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 12:32:00	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 12:32:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:32:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:32:00	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 12:32:00	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 12:32:00	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 12:32:00	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 12:32:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:32:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:32:00	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 12:32:00	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 12:32:00	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 12:32:00	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 12:32:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:32:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:32:00	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 12:32:00	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 12:32:00	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 12:32:00	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 12:32:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:32:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:32:00	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 12:32:00	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 12:32:00	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 12:32:00	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 12:32:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:32:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:32:00	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 12:32:00	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 12:32:00	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 12:32:00	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 12:32:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:32:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:32:00	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 12:32:00	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 12:32:00	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 12:32:00	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 12:32:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:32:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:32:00	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 12:47:03	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 12:47:03	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 12:47:03	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 12:47:03	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:03	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 12:47:03	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 12:47:03	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:03	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 12:47:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:03	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 12:47:03	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 12:47:03	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 12:47:03	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 12:47:03	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 12:47:03	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 12:47:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:03	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 12:47:03	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 12:47:03	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 12:47:03	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 12:47:03	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 12:47:03	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:03	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 12:47:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:03	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 12:47:03	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 12:47:03	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 12:47:03	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 12:47:03	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 12:47:03	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:03	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 12:47:03	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 12:47:03	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 12:47:03	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 12:47:03	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 12:47:03	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:03	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 12:47:03	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 12:47:03	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 12:47:03	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 12:47:03	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 12:47:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:03	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 12:47:03	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 12:47:03	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 12:47:03	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:03	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 12:47:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 12:47:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:03	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 12:47:03	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 12:47:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:03	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 12:47:03	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 12:47:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:03	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 12:47:03	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 12:47:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:03	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 12:47:03	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:03	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 12:47:03	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 12:47:03	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:03	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 12:47:12	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 12:47:12	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 12:47:12	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 12:47:12	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:12	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 12:47:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 12:47:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:12	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 12:47:12	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 12:47:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 12:47:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:12	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 12:47:12	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 12:47:12	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 12:47:12	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 12:47:12	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 12:47:12	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 12:47:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:12	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 12:47:12	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 12:47:12	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 12:47:12	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 12:47:12	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 12:47:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:12	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 12:47:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 12:47:12	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 12:47:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:12	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 12:47:12	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 12:47:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 12:47:12	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:12	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 12:47:12	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 12:47:12	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 12:47:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:12	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 12:47:12	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:12	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 12:47:12	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 12:47:12	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 12:47:12	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:12	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 12:47:12	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 12:47:12	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 12:47:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:12	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 12:47:12	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 12:47:12	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 12:47:12	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:12	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 12:47:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 12:47:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:12	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 12:47:12	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 12:47:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:12	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 12:47:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:12	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 12:47:12	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 12:47:12	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 12:47:12	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 12:47:12	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 12:47:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 12:47:12	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 13:18:21	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 13:18:21	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 13:18:21	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 13:18:21	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:18:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 13:18:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:18:21	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 13:18:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:18:21	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 13:18:21	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 13:18:21	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 13:18:21	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 13:18:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:18:21	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 13:18:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 13:18:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:18:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:18:21	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 13:18:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 13:18:21	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 13:18:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:18:21	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 13:18:21	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 13:18:21	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 13:18:21	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:18:21	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 13:18:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:18:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:18:21	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 13:18:21	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 13:18:21	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 13:18:21	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 13:18:21	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 13:18:21	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:18:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 13:18:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:18:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:18:21	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 13:18:21	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 13:18:21	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 13:18:21	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 13:18:21	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 13:18:21	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:18:21	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 13:18:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:18:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 13:18:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:18:21	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 13:18:21	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 13:18:21	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 13:18:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:18:21	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 13:18:21	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 13:18:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:18:21	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 13:18:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:18:21	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 13:18:21	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 13:18:21	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 13:18:21	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:18:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:18:21	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 13:18:21	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 13:18:21	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 13:18:21	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 13:18:21	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:18:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:18:21	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 13:18:21	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 13:18:21	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 13:18:21	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:18:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:18:21	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 13:20:15	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 13:20:15	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 13:20:15	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 13:20:15	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:15	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 13:20:15	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 13:20:15	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 13:20:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:15	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 13:20:15	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 13:20:15	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 13:20:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:15	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 13:20:15	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 13:20:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:15	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 13:20:15	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 13:20:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:15	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 13:20:15	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 13:20:15	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 13:20:15	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 13:20:15	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 13:20:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:15	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 13:20:15	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 13:20:15	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 13:20:15	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 13:20:15	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 13:20:15	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:15	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 13:20:15	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 13:20:15	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 13:20:15	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 13:20:15	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 13:20:15	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 13:20:15	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 13:20:15	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 13:20:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:15	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 13:20:15	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 13:20:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 13:20:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:15	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 13:20:15	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 13:20:15	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:15	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 13:20:15	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 13:20:15	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 13:20:15	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:15	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 13:20:15	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 13:20:15	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:15	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 13:20:15	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 13:20:15	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:15	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 13:20:15	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 13:20:15	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:15	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 13:20:15	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 13:20:15	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:15	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:15	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 13:20:20	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 13:20:20	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:20	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 13:20:20	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 13:20:20	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:20	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 13:20:20	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 13:20:20	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:20	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 13:20:20	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 13:20:20	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:20	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 13:20:20	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 13:20:20	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:20	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 13:20:20	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 13:20:20	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:20	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 13:20:20	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 13:20:20	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:20	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 13:20:20	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 13:20:20	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:20	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 13:20:20	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 13:20:20	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:20	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 13:20:20	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 13:20:20	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:20	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 13:20:20	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 13:20:20	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:20	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 13:20:20	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 13:20:20	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:20	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 13:20:20	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 13:20:20	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:20	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 13:20:20	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 13:20:20	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:20	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 13:20:20	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 13:20:20	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:20	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:20	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 13:20:22	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 13:20:22	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 13:20:22	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 13:20:22	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:22	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:22	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 13:20:22	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 13:20:22	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 13:20:22	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 13:20:22	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:22	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:22	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 13:20:22	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 13:20:22	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 13:20:22	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 13:20:22	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:22	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:22	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 13:20:22	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 13:20:22	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:20:22	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 13:20:22	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:22	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:22	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 13:20:22	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 13:20:22	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 13:20:22	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 13:20:22	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:22	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:22	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 13:20:22	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 13:20:22	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 13:20:22	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 13:20:22	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:22	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:22	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 13:20:22	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 13:20:22	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 13:20:22	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 13:20:22	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:22	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:22	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 13:20:22	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 13:20:22	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:20:22	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 13:20:22	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:22	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:22	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 13:20:22	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 13:20:22	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 13:20:22	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 13:20:22	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:20:22	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:20:22	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 13:34:25	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 13:34:25	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 13:34:25	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 13:34:25	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:34:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:34:25	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 13:34:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:34:25	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 13:34:25	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 13:34:25	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 13:34:25	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 13:34:25	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 13:34:25	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:34:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:34:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:34:25	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 13:34:25	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 13:34:25	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 13:34:25	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 13:34:25	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 13:34:25	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 13:34:25	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:34:25	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:34:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 13:34:25	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 13:34:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:34:25	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 13:34:25	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 13:34:25	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 13:34:25	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 13:34:25	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:34:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:34:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:34:25	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 13:34:25	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 13:34:25	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 13:34:25	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 13:34:25	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 13:34:25	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 13:34:25	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:34:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:34:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:34:25	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 13:34:25	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 13:34:25	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 13:34:25	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 13:34:25	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 13:34:25	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:34:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:34:25	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 13:34:25	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 13:34:25	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 13:34:25	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 13:34:25	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:34:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:34:25	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 13:34:25	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 13:34:25	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 13:34:25	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 13:34:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:34:25	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 13:34:25	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 13:34:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:34:25	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 13:34:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:34:25	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 13:34:25	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 13:34:25	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:34:25	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 13:34:25	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 13:34:25	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:34:25	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:34:25	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 13:36:37	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 13:36:37	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 13:36:37	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 13:36:37	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:37	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 13:36:37	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 13:36:37	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:37	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 13:36:37	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 13:36:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 13:36:37	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:37	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 13:36:37	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 13:36:37	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 13:36:37	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:37	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 13:36:37	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 13:36:37	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:37	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 13:36:37	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 13:36:37	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 13:36:37	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 13:36:37	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 13:36:37	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 13:36:37	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:37	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 13:36:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:37	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 13:36:37	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 13:36:37	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 13:36:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:37	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 13:36:37	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 13:36:37	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:37	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 13:36:37	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 13:36:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:37	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 13:36:37	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:37	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 13:36:37	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 13:36:37	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 13:36:37	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 13:36:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:37	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 13:36:37	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 13:36:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:37	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 13:36:37	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 13:36:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:37	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 13:36:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 13:36:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:37	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 13:36:37	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 13:36:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:37	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 13:36:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:37	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 13:36:37	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 13:36:37	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:37	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 13:36:37	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 13:36:37	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:37	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 13:36:37	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 13:36:37	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:37	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 13:36:49	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 13:36:49	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 13:36:49	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 13:36:49	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:49	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 13:36:49	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 13:36:49	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 13:36:49	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 13:36:49	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 13:36:49	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 13:36:49	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 13:36:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:49	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 13:36:49	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 13:36:49	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 13:36:49	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 13:36:49	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 13:36:49	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:49	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 13:36:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 13:36:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:49	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 13:36:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:49	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 13:36:49	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 13:36:49	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 13:36:49	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:49	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 13:36:49	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 13:36:49	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 13:36:49	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 13:36:49	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:49	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 13:36:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:49	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 13:36:49	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 13:36:49	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 13:36:49	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 13:36:49	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:49	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 13:36:49	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 13:36:49	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 13:36:49	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 13:36:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:49	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 13:36:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:49	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 13:36:49	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 13:36:49	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 13:36:49	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:49	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 13:36:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:49	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 13:36:49	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 13:36:49	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 13:36:49	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:49	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 13:36:49	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 13:36:49	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 13:36:49	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:49	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 13:36:49	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 13:36:49	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:36:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:36:49	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 13:37:00	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 13:37:00	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:37:00	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 13:37:00	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 13:37:00	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 13:37:00	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 13:37:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:37:00	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:37:00	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 13:37:00	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 13:37:00	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 13:37:00	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 13:37:00	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:37:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:37:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 13:37:00	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 13:37:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:37:00	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 13:37:00	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 13:37:00	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 13:37:00	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 13:37:00	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:37:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:37:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 13:37:00	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 13:37:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:37:00	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 13:37:00	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 13:37:00	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 13:37:00	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 13:37:00	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:37:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:37:00	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 13:37:00	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 13:37:00	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 13:37:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:37:00	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 13:37:00	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 13:37:00	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:37:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:37:00	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 13:37:00	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 13:37:00	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 13:37:00	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 13:37:00	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:37:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 13:37:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:37:00	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 13:37:00	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 13:37:00	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 13:37:00	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:37:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 13:37:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:37:00	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 13:37:00	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 13:37:00	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 13:37:00	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:37:00	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 13:37:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 13:37:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:37:00	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 13:37:00	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 13:37:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:37:00	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 13:37:00	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:37:00	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 13:37:00	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 13:37:00	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:37:00	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 13:37:00	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 13:37:00	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:37:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:37:00	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 13:43:18	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 13:43:18	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 13:43:18	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 13:43:19	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:43:19	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 13:43:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 13:43:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:43:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:43:19	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 13:43:19	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 13:43:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 13:43:19	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 13:43:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:43:19	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 13:43:19	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 13:43:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:43:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:43:19	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 13:43:19	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 13:43:19	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 13:43:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:43:19	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 13:43:19	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 13:43:19	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 13:43:19	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:43:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:43:19	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 13:43:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:43:19	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 13:43:19	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 13:43:19	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 13:43:19	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 13:43:19	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 13:43:19	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:43:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:43:19	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 13:43:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 13:43:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:43:19	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 13:43:19	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 13:43:19	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 13:43:19	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:43:19	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 13:43:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 13:43:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:43:19	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 13:43:19	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 13:43:19	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:43:19	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 13:43:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 13:43:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:43:19	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 13:43:19	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 13:43:19	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:43:19	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 13:43:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 13:43:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:43:19	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 13:43:19	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 13:43:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:43:19	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 13:43:19	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 13:43:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:43:19	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 13:43:19	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 13:43:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:43:19	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 13:43:19	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:43:19	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 13:43:19	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 13:43:19	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 13:43:19	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 13:43:19	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 14:51:25	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 14:51:25	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 14:51:25	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 14:51:26	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 14:51:26	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 14:51:26	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 14:51:26	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 14:51:26	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 14:51:26	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Punctuation handler ==>> text to process:i want to rechrage
2019-06-12 14:51:26	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'rechrage'] and tokenize_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 14:51:26	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'rechrag'] and stem_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 14:51:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 14:51:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 14:51:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 14:51:26	DEBUG	Ngram handler ==>> unigram:['rechrag'] == bigram:['to rechrag'] == trigram:['want to rechrag']
2019-06-12 14:51:26	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 14:51:26	DEBUG	Punctuation handler ==>> text to process:i want to recharge
2019-06-12 14:51:26	DEBUG	Punctuation handler ==>> text to process:email data
2019-06-12 14:51:26	DEBUG	Tokenization handler ==>> takens:['i', 'want', 'to', 'recharge'] and tokenize_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Stemmer handler ==>> stem_tokens:['i', 'want', 'to', 'recharg'] and stem_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Tokenization handler ==>> takens:['email', 'data'] and tokenize_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Stemmer handler ==>> stem_tokens:['email', 'data'] and stem_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 14:51:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 14:51:26	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-12 14:51:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:['to recharg'] == trigram:['want to recharg']
2019-06-12 14:51:26	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-12 14:51:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 14:51:26	DEBUG	Punctuation handler ==>> text to process:can you recharge postpaid
2019-06-12 14:51:26	DEBUG	Ngram handler ==>> unigram:['email', 'data'] == bigram:['email data'] == trigram:[]
2019-06-12 14:51:26	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Tokenization handler ==>> takens:['can', 'you', 'recharge', 'postpaid'] and tokenize_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Punctuation handler ==>> text to process:text repeat this intent email address
2019-06-12 14:51:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Stemmer handler ==>> stem_tokens:['can', 'you', 'recharg', 'postpaid'] and stem_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 14:51:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Tokenization handler ==>> takens:['text', 'repeat', 'this', 'intent', 'email', 'address'] and tokenize_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 14:51:26	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-12 14:51:26	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'repeat', 'thi', 'intent', 'email', 'address'] and stem_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-12 14:51:26	DEBUG	Ngram handler ==>> unigram:['recharg', 'postpaid'] == bigram:['you recharg', 'recharg postpaid'] == trigram:['can you recharg', 'you recharg postpaid']
2019-06-12 14:51:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Punctuation handler ==>> text to process:recharge
2019-06-12 14:51:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 14:51:26	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Tokenization handler ==>> takens:['recharge'] and tokenize_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Ngram handler ==>> unigram:['text', 'repeat', 'thi', 'intent', 'email', 'address'] == bigram:['text repeat', 'repeat thi', 'thi intent', 'intent email', 'email address'] == trigram:['text repeat thi', 'repeat thi intent', 'thi intent email', 'intent email address']
2019-06-12 14:51:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 14:51:26	DEBUG	Stemmer handler ==>> stem_tokens:['recharg'] and stem_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Punctuation handler ==>> text to process:what is your name
2019-06-12 14:51:26	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-12 14:51:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Punctuation handler ==>> text to process:mcq hindi
2019-06-12 14:51:26	DEBUG	Tokenization handler ==>> takens:['what', 'is', 'your', 'name'] and tokenize_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Tokenization handler ==>> takens:['mcq', 'hindi'] and tokenize_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 14:51:26	DEBUG	Ngram handler ==>> unigram:['recharg'] == bigram:[] == trigram:[]
2019-06-12 14:51:26	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'hindi'] and stem_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Stemmer handler ==>> stem_tokens:['what', 'is', 'your', 'name'] and stem_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Punctuation handler ==>> text to process:travel
2019-06-12 14:51:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 14:51:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 14:51:26	DEBUG	Tokenization handler ==>> takens:['travel'] and tokenize_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Stemmer handler ==>> stem_tokens:['travel'] and stem_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Ngram handler ==>> unigram:['mcq', 'hindi'] == bigram:['mcq hindi'] == trigram:[]
2019-06-12 14:51:26	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:['your name'] == trigram:['is your name']
2019-06-12 14:51:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Punctuation handler ==>> text to process:username
2019-06-12 14:51:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 14:51:26	DEBUG	Ngram handler ==>> unigram:['travel'] == bigram:[] == trigram:[]
2019-06-12 14:51:26	DEBUG	Tokenization handler ==>> takens:['username'] and tokenize_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Punctuation handler ==>> text to process:fetch data
2019-06-12 14:51:26	DEBUG	Stemmer handler ==>> stem_tokens:['usernam'] and stem_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Tokenization handler ==>> takens:['fetch', 'data'] and tokenize_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Stemmer handler ==>> stem_tokens:['fetch', 'data'] and stem_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 14:51:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Ngram handler ==>> unigram:['usernam'] == bigram:[] == trigram:[]
2019-06-12 14:51:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 14:51:26	DEBUG	Punctuation handler ==>> text to process:name
2019-06-12 14:51:26	DEBUG	Ngram handler ==>> unigram:['fetch', 'data'] == bigram:['fetch data'] == trigram:[]
2019-06-12 14:51:26	DEBUG	Tokenization handler ==>> takens:['name'] and tokenize_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Punctuation handler ==>> text to process:dfgdfg
2019-06-12 14:51:26	DEBUG	Stemmer handler ==>> stem_tokens:['name'] and stem_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Tokenization handler ==>> takens:['dfgdfg'] and tokenize_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfg'] and stem_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 14:51:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Ngram handler ==>> unigram:['name'] == bigram:[] == trigram:[]
2019-06-12 14:51:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 14:51:26	DEBUG	Punctuation handler ==>> text to process:text username
2019-06-12 14:51:26	DEBUG	Ngram handler ==>> unigram:['dfgdfg'] == bigram:[] == trigram:[]
2019-06-12 14:51:26	DEBUG	Tokenization handler ==>> takens:['text', 'username'] and tokenize_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Punctuation handler ==>> text to process:rechargepostpaid or prepaid
2019-06-12 14:51:26	DEBUG	Stemmer handler ==>> stem_tokens:['text', 'usernam'] and stem_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Tokenization handler ==>> takens:['rechargepostpaid', 'or', 'prepaid'] and tokenize_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 14:51:26	DEBUG	Stemmer handler ==>> stem_tokens:['rechargepostpaid', 'or', 'prepaid'] and stem_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Ngram handler ==>> unigram:['text', 'usernam'] == bigram:['text usernam'] == trigram:[]
2019-06-12 14:51:26	DEBUG	Punctuation handler ==>> text to process:cityt name
2019-06-12 14:51:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 14:51:26	DEBUG	Ngram handler ==>> unigram:['rechargepostpaid', 'prepaid'] == bigram:['rechargepostpaid or', 'or prepaid'] == trigram:['rechargepostpaid or prepaid']
2019-06-12 14:51:26	DEBUG	Tokenization handler ==>> takens:['cityt', 'name'] and tokenize_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Stemmer handler ==>> stem_tokens:['cityt', 'name'] and stem_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 14:51:26	DEBUG	Ngram handler ==>> unigram:['cityt', 'name'] == bigram:['cityt name'] == trigram:[]
2019-06-12 14:51:26	DEBUG	Punctuation handler ==>> text to process:ask to user from city
2019-06-12 14:51:26	DEBUG	Tokenization handler ==>> takens:['ask', 'to', 'user', 'from', 'city'] and tokenize_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	Stemmer handler ==>> stem_tokens:['ask', 'to', 'user', 'from', 'citi'] and stem_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-12 14:51:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-12 14:51:26	DEBUG	Ngram handler ==>> unigram:['user', 'citi'] == bigram:['to user', 'user from', 'from citi'] == trigram:['ask to user', 'to user from', 'user from citi']
2019-06-13 13:24:33	DEBUG	Punctuation handler ==>> text to process:where vln number is written in acknowledgement
2019-06-13 13:24:33	DEBUG	Tokenization handler ==>> takens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledgement'] and tokenize_without_stop_words:[]
2019-06-13 13:24:33	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledg'] and stem_without_stop_words:[]
2019-06-13 13:24:33	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-13 13:24:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-13 13:24:33	DEBUG	Ngram handler ==>> unigram:['vln', 'written', 'acknowledg'] == bigram:['where vln', 'vln number', 'is written', 'written in', 'in acknowledg'] == trigram:['where vln number', 'vln number is', 'number is written', 'is written in', 'written in acknowledg']
2019-06-13 13:25:11	DEBUG	Punctuation handler ==>> text to process:where vln number is written in acknowledgement
2019-06-13 13:25:11	DEBUG	Tokenization handler ==>> takens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledgement'] and tokenize_without_stop_words:[]
2019-06-13 13:25:11	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledg'] and stem_without_stop_words:[]
2019-06-13 13:25:11	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-13 13:25:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-13 13:25:11	DEBUG	Ngram handler ==>> unigram:['vln', 'written', 'acknowledg'] == bigram:['where vln', 'vln number', 'is written', 'written in', 'in acknowledg'] == trigram:['where vln number', 'vln number is', 'number is written', 'is written in', 'written in acknowledg']
2019-06-13 13:28:34	DEBUG	Punctuation handler ==>> text to process:where vln number is written in acknowledgement
2019-06-13 13:28:34	DEBUG	Tokenization handler ==>> takens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledgement'] and tokenize_without_stop_words:[]
2019-06-13 13:28:34	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledg'] and stem_without_stop_words:[]
2019-06-13 13:28:34	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-13 13:28:34	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-13 13:28:34	DEBUG	Ngram handler ==>> unigram:['vln', 'written', 'acknowledg'] == bigram:['where vln', 'vln number', 'is written', 'written in', 'in acknowledg'] == trigram:['where vln number', 'vln number is', 'number is written', 'is written in', 'written in acknowledg']
2019-06-13 13:36:06	DEBUG	Punctuation handler ==>> text to process:where vln number is written in acknowledgement
2019-06-13 13:36:06	DEBUG	Tokenization handler ==>> takens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledgement'] and tokenize_without_stop_words:[]
2019-06-13 13:36:06	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledg'] and stem_without_stop_words:[]
2019-06-13 13:36:06	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-13 13:36:06	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-13 13:36:06	DEBUG	Ngram handler ==>> unigram:['vln', 'written', 'acknowledg'] == bigram:['where vln', 'vln number', 'is written', 'written in', 'in acknowledg'] == trigram:['where vln number', 'vln number is', 'number is written', 'is written in', 'written in acknowledg']
2019-06-13 13:44:04	DEBUG	Punctuation handler ==>> text to process:where vln number is written in acknowledgement
2019-06-13 13:44:04	DEBUG	Tokenization handler ==>> takens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledgement'] and tokenize_without_stop_words:[]
2019-06-13 13:44:04	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledg'] and stem_without_stop_words:[]
2019-06-13 13:44:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-13 13:44:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-13 13:44:04	DEBUG	Ngram handler ==>> unigram:['vln', 'written', 'acknowledg'] == bigram:['where vln', 'vln number', 'is written', 'written in', 'in acknowledg'] == trigram:['where vln number', 'vln number is', 'number is written', 'is written in', 'written in acknowledg']
2019-06-13 13:52:07	DEBUG	Punctuation handler ==>> text to process:where vln number is written in acknowledgement
2019-06-13 13:52:07	DEBUG	Tokenization handler ==>> takens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledgement'] and tokenize_without_stop_words:[]
2019-06-13 13:52:07	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledg'] and stem_without_stop_words:[]
2019-06-13 13:52:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-13 13:52:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-13 13:52:07	DEBUG	Ngram handler ==>> unigram:['vln', 'written', 'acknowledg'] == bigram:['where vln', 'vln number', 'is written', 'written in', 'in acknowledg'] == trigram:['where vln number', 'vln number is', 'number is written', 'is written in', 'written in acknowledg']
2019-06-13 13:52:56	DEBUG	Punctuation handler ==>> text to process:where vln number is written in acknowledgement
2019-06-13 13:52:56	DEBUG	Tokenization handler ==>> takens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledgement'] and tokenize_without_stop_words:[]
2019-06-13 13:52:56	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledg'] and stem_without_stop_words:[]
2019-06-13 13:52:56	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-13 13:52:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-13 13:52:56	DEBUG	Ngram handler ==>> unigram:['vln', 'written', 'acknowledg'] == bigram:['where vln', 'vln number', 'is written', 'written in', 'in acknowledg'] == trigram:['where vln number', 'vln number is', 'number is written', 'is written in', 'written in acknowledg']
2019-06-13 14:27:01	DEBUG	Punctuation handler ==>> text to process:where vln number is written in acknowledgement
2019-06-13 14:27:01	DEBUG	Tokenization handler ==>> takens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledgement'] and tokenize_without_stop_words:[]
2019-06-13 14:27:01	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledg'] and stem_without_stop_words:[]
2019-06-13 14:27:01	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-13 14:27:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-13 14:27:01	DEBUG	Ngram handler ==>> unigram:['vln', 'written', 'acknowledg'] == bigram:['where vln', 'vln number', 'is written', 'written in', 'in acknowledg'] == trigram:['where vln number', 'vln number is', 'number is written', 'is written in', 'written in acknowledg']
2019-06-13 14:35:13	DEBUG	Punctuation handler ==>> text to process:where vln number is written in acknowledgement
2019-06-13 14:35:13	DEBUG	Tokenization handler ==>> takens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledgement'] and tokenize_without_stop_words:[]
2019-06-13 14:35:13	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledg'] and stem_without_stop_words:[]
2019-06-13 14:35:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-13 14:35:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-13 14:35:13	DEBUG	Ngram handler ==>> unigram:['vln', 'written', 'acknowledg'] == bigram:['where vln', 'vln number', 'is written', 'written in', 'in acknowledg'] == trigram:['where vln number', 'vln number is', 'number is written', 'is written in', 'written in acknowledg']
2019-06-13 14:39:53	DEBUG	Punctuation handler ==>> text to process:where vln number is written in acknowledgement
2019-06-13 14:39:53	DEBUG	Tokenization handler ==>> takens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledgement'] and tokenize_without_stop_words:[]
2019-06-13 14:39:53	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledg'] and stem_without_stop_words:[]
2019-06-13 14:39:53	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-13 14:39:53	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-13 14:39:53	DEBUG	Ngram handler ==>> unigram:['vln', 'written', 'acknowledg'] == bigram:['where vln', 'vln number', 'is written', 'written in', 'in acknowledg'] == trigram:['where vln number', 'vln number is', 'number is written', 'is written in', 'written in acknowledg']
2019-06-13 14:43:52	DEBUG	Punctuation handler ==>> text to process:where vln number is written in acknowledgement
2019-06-13 14:43:52	DEBUG	Tokenization handler ==>> takens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledgement'] and tokenize_without_stop_words:[]
2019-06-13 14:43:52	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledg'] and stem_without_stop_words:[]
2019-06-13 14:43:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-13 14:43:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-13 14:43:52	DEBUG	Ngram handler ==>> unigram:['vln', 'written', 'acknowledg'] == bigram:['where vln', 'vln number', 'is written', 'written in', 'in acknowledg'] == trigram:['where vln number', 'vln number is', 'number is written', 'is written in', 'written in acknowledg']
2019-06-13 15:02:35	DEBUG	Punctuation handler ==>> text to process:where vln number is written in acknowledgement
2019-06-13 15:02:35	DEBUG	Tokenization handler ==>> takens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledgement'] and tokenize_without_stop_words:[]
2019-06-13 15:02:35	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledg'] and stem_without_stop_words:[]
2019-06-13 15:02:35	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-13 15:02:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-13 15:02:35	DEBUG	Ngram handler ==>> unigram:['vln', 'written', 'acknowledg'] == bigram:['where vln', 'vln number', 'is written', 'written in', 'in acknowledg'] == trigram:['where vln number', 'vln number is', 'number is written', 'is written in', 'written in acknowledg']
2019-06-13 15:02:58	DEBUG	Punctuation handler ==>> text to process:where vln number is written in acknowledgement
2019-06-13 15:02:58	DEBUG	Tokenization handler ==>> takens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledgement'] and tokenize_without_stop_words:[]
2019-06-13 15:02:58	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledg'] and stem_without_stop_words:[]
2019-06-13 15:02:58	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-13 15:02:58	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-13 15:02:58	DEBUG	Ngram handler ==>> unigram:['vln', 'written', 'acknowledg'] == bigram:['where vln', 'vln number', 'is written', 'written in', 'in acknowledg'] == trigram:['where vln number', 'vln number is', 'number is written', 'is written in', 'written in acknowledg']
2019-06-13 15:03:44	DEBUG	Punctuation handler ==>> text to process:where vln number is written in acknowledgement
2019-06-13 15:03:44	DEBUG	Tokenization handler ==>> takens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledgement'] and tokenize_without_stop_words:[]
2019-06-13 15:03:44	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledg'] and stem_without_stop_words:[]
2019-06-13 15:03:44	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-13 15:03:44	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-13 15:03:44	DEBUG	Ngram handler ==>> unigram:['vln', 'written', 'acknowledg'] == bigram:['where vln', 'vln number', 'is written', 'written in', 'in acknowledg'] == trigram:['where vln number', 'vln number is', 'number is written', 'is written in', 'written in acknowledg']
2019-06-13 15:04:59	DEBUG	Punctuation handler ==>> text to process:where vln number is written in acknowledgement
2019-06-13 15:04:59	DEBUG	Tokenization handler ==>> takens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledgement'] and tokenize_without_stop_words:[]
2019-06-13 15:04:59	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledg'] and stem_without_stop_words:[]
2019-06-13 15:04:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-13 15:04:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-13 15:04:59	DEBUG	Ngram handler ==>> unigram:['vln', 'written', 'acknowledg'] == bigram:['where vln', 'vln number', 'is written', 'written in', 'in acknowledg'] == trigram:['where vln number', 'vln number is', 'number is written', 'is written in', 'written in acknowledg']
2019-06-13 15:14:14	DEBUG	Punctuation handler ==>> text to process:where vln number is written in acknowledgement
2019-06-13 15:14:14	DEBUG	Tokenization handler ==>> takens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledgement'] and tokenize_without_stop_words:[]
2019-06-13 15:14:14	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledg'] and stem_without_stop_words:[]
2019-06-13 15:14:14	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-13 15:14:14	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-13 15:14:14	DEBUG	Ngram handler ==>> unigram:['vln', 'written', 'acknowledg'] == bigram:['where vln', 'vln number', 'is written', 'written in', 'in acknowledg'] == trigram:['where vln number', 'vln number is', 'number is written', 'is written in', 'written in acknowledg']
2019-06-13 15:14:43	DEBUG	Punctuation handler ==>> text to process:where vln number is written in acknowledgement
2019-06-13 15:14:43	DEBUG	Tokenization handler ==>> takens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledgement'] and tokenize_without_stop_words:[]
2019-06-13 15:14:43	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledg'] and stem_without_stop_words:[]
2019-06-13 15:14:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-13 15:14:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-13 15:14:43	DEBUG	Ngram handler ==>> unigram:['vln', 'written', 'acknowledg'] == bigram:['where vln', 'vln number', 'is written', 'written in', 'in acknowledg'] == trigram:['where vln number', 'vln number is', 'number is written', 'is written in', 'written in acknowledg']
2019-06-13 15:15:36	DEBUG	Punctuation handler ==>> text to process:where vln number is written in acknowledgement
2019-06-13 15:15:36	DEBUG	Tokenization handler ==>> takens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledgement'] and tokenize_without_stop_words:[]
2019-06-13 15:15:36	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledg'] and stem_without_stop_words:[]
2019-06-13 15:15:36	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-13 15:15:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-13 15:15:36	DEBUG	Ngram handler ==>> unigram:['vln', 'written', 'acknowledg'] == bigram:['where vln', 'vln number', 'is written', 'written in', 'in acknowledg'] == trigram:['where vln number', 'vln number is', 'number is written', 'is written in', 'written in acknowledg']
2019-06-13 15:17:33	DEBUG	Punctuation handler ==>> text to process:where vln number is written in acknowledgement
2019-06-13 15:17:33	DEBUG	Tokenization handler ==>> takens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledgement'] and tokenize_without_stop_words:[]
2019-06-13 15:17:33	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledg'] and stem_without_stop_words:[]
2019-06-13 15:17:33	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-13 15:17:33	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-13 15:17:33	DEBUG	Ngram handler ==>> unigram:['vln', 'written', 'acknowledg'] == bigram:['where vln', 'vln number', 'is written', 'written in', 'in acknowledg'] == trigram:['where vln number', 'vln number is', 'number is written', 'is written in', 'written in acknowledg']
2019-06-13 15:19:09	DEBUG	Punctuation handler ==>> text to process:where vln number is written in acknowledgement
2019-06-13 15:19:09	DEBUG	Tokenization handler ==>> takens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledgement'] and tokenize_without_stop_words:[]
2019-06-13 15:19:09	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledg'] and stem_without_stop_words:[]
2019-06-13 15:19:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-13 15:19:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-13 15:19:09	DEBUG	Ngram handler ==>> unigram:['vln', 'written', 'acknowledg'] == bigram:['where vln', 'vln number', 'is written', 'written in', 'in acknowledg'] == trigram:['where vln number', 'vln number is', 'number is written', 'is written in', 'written in acknowledg']
2019-06-13 15:21:00	DEBUG	Punctuation handler ==>> text to process:where vln number is written in acknowledgement
2019-06-13 15:21:00	DEBUG	Tokenization handler ==>> takens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledgement'] and tokenize_without_stop_words:[]
2019-06-13 15:21:00	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledg'] and stem_without_stop_words:[]
2019-06-13 15:21:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-13 15:21:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-13 15:21:00	DEBUG	Ngram handler ==>> unigram:['vln', 'written', 'acknowledg'] == bigram:['where vln', 'vln number', 'is written', 'written in', 'in acknowledg'] == trigram:['where vln number', 'vln number is', 'number is written', 'is written in', 'written in acknowledg']
2019-06-13 15:22:52	DEBUG	Punctuation handler ==>> text to process:where vln number is written in acknowledgement
2019-06-13 15:22:52	DEBUG	Tokenization handler ==>> takens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledgement'] and tokenize_without_stop_words:[]
2019-06-13 15:22:52	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledg'] and stem_without_stop_words:[]
2019-06-13 15:22:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-13 15:22:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-13 15:22:52	DEBUG	Ngram handler ==>> unigram:['vln', 'written', 'acknowledg'] == bigram:['where vln', 'vln number', 'is written', 'written in', 'in acknowledg'] == trigram:['where vln number', 'vln number is', 'number is written', 'is written in', 'written in acknowledg']
2019-06-13 15:25:38	DEBUG	Punctuation handler ==>> text to process:where vln number is written in acknowledgement
2019-06-13 15:25:38	DEBUG	Tokenization handler ==>> takens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledgement'] and tokenize_without_stop_words:[]
2019-06-13 15:25:38	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledg'] and stem_without_stop_words:[]
2019-06-13 15:25:38	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-13 15:25:38	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-13 15:25:38	DEBUG	Ngram handler ==>> unigram:['vln', 'written', 'acknowledg'] == bigram:['where vln', 'vln number', 'is written', 'written in', 'in acknowledg'] == trigram:['where vln number', 'vln number is', 'number is written', 'is written in', 'written in acknowledg']
2019-06-13 15:26:36	DEBUG	Punctuation handler ==>> text to process:where vln number is written in acknowledgement
2019-06-13 15:26:36	DEBUG	Tokenization handler ==>> takens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledgement'] and tokenize_without_stop_words:[]
2019-06-13 15:26:36	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledg'] and stem_without_stop_words:[]
2019-06-13 15:26:36	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-13 15:26:36	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-13 15:26:36	DEBUG	Ngram handler ==>> unigram:['vln', 'written', 'acknowledg'] == bigram:['where vln', 'vln number', 'is written', 'written in', 'in acknowledg'] == trigram:['where vln number', 'vln number is', 'number is written', 'is written in', 'written in acknowledg']
2019-06-13 15:27:31	DEBUG	Punctuation handler ==>> text to process:where vln number is written in acknowledgement
2019-06-13 15:27:31	DEBUG	Tokenization handler ==>> takens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledgement'] and tokenize_without_stop_words:[]
2019-06-13 15:27:31	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledg'] and stem_without_stop_words:[]
2019-06-13 15:27:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-13 15:27:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-13 15:27:31	DEBUG	Ngram handler ==>> unigram:['vln', 'written', 'acknowledg'] == bigram:['where vln', 'vln number', 'is written', 'written in', 'in acknowledg'] == trigram:['where vln number', 'vln number is', 'number is written', 'is written in', 'written in acknowledg']
2019-06-13 15:28:13	DEBUG	Punctuation handler ==>> text to process:where vln number is written in acknowledgement
2019-06-13 15:28:13	DEBUG	Tokenization handler ==>> takens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledgement'] and tokenize_without_stop_words:[]
2019-06-13 15:28:13	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledg'] and stem_without_stop_words:[]
2019-06-13 15:28:13	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-13 15:28:13	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-13 15:28:13	DEBUG	Ngram handler ==>> unigram:['vln', 'written', 'acknowledg'] == bigram:['where vln', 'vln number', 'is written', 'written in', 'in acknowledg'] == trigram:['where vln number', 'vln number is', 'number is written', 'is written in', 'written in acknowledg']
2019-06-13 15:29:07	DEBUG	Punctuation handler ==>> text to process:where vln number is written in acknowledgement
2019-06-13 15:29:07	DEBUG	Tokenization handler ==>> takens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledgement'] and tokenize_without_stop_words:[]
2019-06-13 15:29:07	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledg'] and stem_without_stop_words:[]
2019-06-13 15:29:07	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-13 15:29:07	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-13 15:29:07	DEBUG	Ngram handler ==>> unigram:['vln', 'written', 'acknowledg'] == bigram:['where vln', 'vln number', 'is written', 'written in', 'in acknowledg'] == trigram:['where vln number', 'vln number is', 'number is written', 'is written in', 'written in acknowledg']
2019-06-13 15:30:03	DEBUG	Punctuation handler ==>> text to process:where vln number is written in acknowledgement
2019-06-13 15:30:03	DEBUG	Tokenization handler ==>> takens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledgement'] and tokenize_without_stop_words:[]
2019-06-13 15:30:03	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledg'] and stem_without_stop_words:[]
2019-06-13 15:30:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-13 15:30:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-13 15:30:03	DEBUG	Ngram handler ==>> unigram:['vln', 'written', 'acknowledg'] == bigram:['where vln', 'vln number', 'is written', 'written in', 'in acknowledg'] == trigram:['where vln number', 'vln number is', 'number is written', 'is written in', 'written in acknowledg']
2019-06-13 15:30:23	DEBUG	Punctuation handler ==>> text to process:where vln number is written in acknowledgement
2019-06-13 15:30:23	DEBUG	Tokenization handler ==>> takens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledgement'] and tokenize_without_stop_words:[]
2019-06-13 15:30:23	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledg'] and stem_without_stop_words:[]
2019-06-13 15:30:23	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-13 15:30:23	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-13 15:30:23	DEBUG	Ngram handler ==>> unigram:['vln', 'written', 'acknowledg'] == bigram:['where vln', 'vln number', 'is written', 'written in', 'in acknowledg'] == trigram:['where vln number', 'vln number is', 'number is written', 'is written in', 'written in acknowledg']
2019-06-13 15:33:34	DEBUG	Punctuation handler ==>> text to process:teesting
2019-06-13 15:33:34	DEBUG	Tokenization handler ==>> takens:['teesting'] and tokenize_without_stop_words:[]
2019-06-13 15:33:34	DEBUG	Stemmer handler ==>> stem_tokens:['teest'] and stem_without_stop_words:[]
2019-06-13 15:33:34	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-13 15:33:34	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-13 15:33:34	DEBUG	Ngram handler ==>> unigram:['teest'] == bigram:[] == trigram:[]
2019-06-13 15:33:43	DEBUG	Punctuation handler ==>> text to process:where vln number is written in acknowledgement
2019-06-13 15:33:43	DEBUG	Tokenization handler ==>> takens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledgement'] and tokenize_without_stop_words:[]
2019-06-13 15:33:43	DEBUG	Stemmer handler ==>> stem_tokens:['where', 'vln', 'number', 'is', 'written', 'in', 'acknowledg'] and stem_without_stop_words:[]
2019-06-13 15:33:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-13 15:33:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-13 15:33:43	DEBUG	Ngram handler ==>> unigram:['vln', 'written', 'acknowledg'] == bigram:['where vln', 'vln number', 'is written', 'written in', 'in acknowledg'] == trigram:['where vln number', 'vln number is', 'number is written', 'is written in', 'written in acknowledg']
2019-06-14 15:48:00	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-14 15:48:00	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-14 15:48:00	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-14 15:48:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 15:48:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 15:48:00	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-14 15:48:00	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-14 15:48:00	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-14 15:48:00	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-14 15:48:00	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 15:48:00	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 15:48:00	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-14 15:49:51	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-14 15:49:51	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-14 15:49:51	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-14 15:49:51	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 15:49:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 15:49:51	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-14 15:49:51	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-14 15:49:51	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-14 15:49:51	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-14 15:49:51	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 15:49:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 15:49:51	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-14 15:50:09	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-14 15:50:09	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-14 15:50:09	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-14 15:50:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 15:50:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 15:50:09	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-14 15:50:09	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-14 15:50:09	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-14 15:50:09	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-14 15:50:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 15:50:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 15:50:09	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-14 15:50:37	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-14 15:50:37	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-14 15:50:37	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-14 15:50:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 15:50:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 15:50:37	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-14 15:50:37	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-14 15:50:37	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-14 15:50:37	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-14 15:50:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 15:50:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 15:50:37	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-14 15:51:35	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-14 15:51:35	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-14 15:51:35	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-14 15:51:35	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 15:51:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 15:51:35	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-14 15:51:35	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-14 15:51:35	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-14 15:51:35	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-14 15:51:35	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 15:51:35	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 15:51:35	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-14 15:51:37	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-14 15:51:37	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-14 15:51:37	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-14 15:51:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 15:51:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 15:51:37	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-14 15:51:37	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-14 15:51:37	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-14 15:51:37	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-14 15:51:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 15:51:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 15:51:37	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-14 15:52:31	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-14 15:52:31	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-14 15:52:31	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-14 15:52:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 15:52:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 15:52:31	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-14 15:52:31	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-14 15:52:31	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-14 15:52:31	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-14 15:52:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 15:52:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 15:52:31	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-14 15:54:34	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-14 15:54:34	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-14 15:54:34	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-14 15:54:34	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 15:54:34	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 15:54:34	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-14 15:54:34	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-14 15:54:34	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-14 15:54:34	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-14 15:54:34	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 15:54:34	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 15:54:34	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-14 15:56:54	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-14 15:56:54	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-14 15:56:54	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-14 15:56:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 15:56:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 15:56:54	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-14 15:56:54	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-14 15:56:54	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-14 15:56:54	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-14 15:56:54	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 15:56:54	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 15:56:54	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-14 15:58:49	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-14 15:58:49	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-14 15:58:49	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-14 15:58:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 15:58:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 15:58:49	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-14 15:58:49	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-14 15:58:49	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-14 15:58:49	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-14 15:58:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 15:58:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 15:58:49	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-14 15:59:47	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-14 15:59:47	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-14 15:59:47	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-14 15:59:47	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 15:59:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 15:59:47	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-14 15:59:47	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-14 15:59:47	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-14 15:59:47	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-14 15:59:47	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 15:59:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 15:59:47	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-14 16:02:29	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-14 16:02:29	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-14 16:02:29	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-14 16:02:29	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:02:29	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:02:29	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-14 16:02:29	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-14 16:02:29	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:02:29	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-14 16:02:29	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:02:29	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:02:29	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-14 16:05:30	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 16:05:30	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:05:30	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 16:05:30	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:05:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:05:30	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 16:05:30	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-14 16:05:30	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-14 16:05:30	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-14 16:05:30	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:05:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:05:30	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-14 16:05:30	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-14 16:05:30	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:05:30	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-14 16:05:30	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:05:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:05:30	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-14 16:05:30	DEBUG	Punctuation handler ==>> text to process:dfsdfsdfsdfdsfsdf
2019-06-14 16:05:30	DEBUG	Tokenization handler ==>> takens:['dfsdfsdfsdfdsfsdf'] and tokenize_without_stop_words:[]
2019-06-14 16:05:30	DEBUG	Stemmer handler ==>> stem_tokens:['dfsdfsdfsdfdsfsdf'] and stem_without_stop_words:[]
2019-06-14 16:05:30	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:05:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:05:30	DEBUG	Ngram handler ==>> unigram:['dfsdfsdfsdfdsfsdf'] == bigram:[] == trigram:[]
2019-06-14 16:05:30	DEBUG	Punctuation handler ==>> text to process:fgdfgdfg
2019-06-14 16:05:30	DEBUG	Tokenization handler ==>> takens:['fgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:05:30	DEBUG	Stemmer handler ==>> stem_tokens:['fgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:05:30	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:05:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:05:30	DEBUG	Ngram handler ==>> unigram:['fgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:05:30	DEBUG	Punctuation handler ==>> text to process:dfgdfgdffgdfgdfg
2019-06-14 16:05:30	DEBUG	Tokenization handler ==>> takens:['dfgdfgdffgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:05:30	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfgdffgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:05:30	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:05:30	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:05:30	DEBUG	Ngram handler ==>> unigram:['dfgdfgdffgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:05:32	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 16:05:32	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:05:32	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 16:05:32	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:05:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:05:32	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 16:05:32	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-14 16:05:32	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-14 16:05:32	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-14 16:05:32	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:05:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:05:32	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-14 16:05:32	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-14 16:05:32	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:05:32	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-14 16:05:32	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:05:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:05:32	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-14 16:05:32	DEBUG	Punctuation handler ==>> text to process:dfsdfsdfsdfdsfsdf
2019-06-14 16:05:32	DEBUG	Tokenization handler ==>> takens:['dfsdfsdfsdfdsfsdf'] and tokenize_without_stop_words:[]
2019-06-14 16:05:32	DEBUG	Stemmer handler ==>> stem_tokens:['dfsdfsdfsdfdsfsdf'] and stem_without_stop_words:[]
2019-06-14 16:05:32	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:05:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:05:32	DEBUG	Ngram handler ==>> unigram:['dfsdfsdfsdfdsfsdf'] == bigram:[] == trigram:[]
2019-06-14 16:05:32	DEBUG	Punctuation handler ==>> text to process:fgdfgdfg
2019-06-14 16:05:32	DEBUG	Tokenization handler ==>> takens:['fgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:05:32	DEBUG	Stemmer handler ==>> stem_tokens:['fgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:05:32	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:05:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:05:32	DEBUG	Ngram handler ==>> unigram:['fgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:05:32	DEBUG	Punctuation handler ==>> text to process:dfgdfgdffgdfgdfg
2019-06-14 16:05:32	DEBUG	Tokenization handler ==>> takens:['dfgdfgdffgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:05:32	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfgdffgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:05:32	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:05:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:05:32	DEBUG	Ngram handler ==>> unigram:['dfgdfgdffgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:08:16	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 16:08:16	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:08:16	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 16:08:16	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-14 16:08:16	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:08:16	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-14 16:08:16	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-14 16:08:16	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:08:16	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-14 16:08:16	DEBUG	Punctuation handler ==>> text to process:dfsdfsdfsdfdsfsdf
2019-06-14 16:08:16	DEBUG	Tokenization handler ==>> takens:['dfsdfsdfsdfdsfsdf'] and tokenize_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	Stemmer handler ==>> stem_tokens:['dfsdfsdfsdfdsfsdf'] and stem_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:08:16	DEBUG	Ngram handler ==>> unigram:['dfsdfsdfsdfdsfsdf'] == bigram:[] == trigram:[]
2019-06-14 16:08:16	DEBUG	Punctuation handler ==>> text to process:fgdfgdfg
2019-06-14 16:08:16	DEBUG	Tokenization handler ==>> takens:['fgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	Stemmer handler ==>> stem_tokens:['fgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:08:16	DEBUG	Ngram handler ==>> unigram:['fgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:08:16	DEBUG	Punctuation handler ==>> text to process:dfgdfgdffgdfgdfg
2019-06-14 16:08:16	DEBUG	Tokenization handler ==>> takens:['dfgdfgdffgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfgdffgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:08:16	DEBUG	Ngram handler ==>> unigram:['dfgdfgdffgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:08:16	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 16:08:16	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:08:16	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 16:08:16	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-14 16:08:16	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:08:16	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-14 16:08:16	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-14 16:08:16	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:08:16	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-14 16:08:16	DEBUG	Punctuation handler ==>> text to process:dfsdfsdfsdfdsfsdf
2019-06-14 16:08:16	DEBUG	Tokenization handler ==>> takens:['dfsdfsdfsdfdsfsdf'] and tokenize_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	Stemmer handler ==>> stem_tokens:['dfsdfsdfsdfdsfsdf'] and stem_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:08:16	DEBUG	Ngram handler ==>> unigram:['dfsdfsdfsdfdsfsdf'] == bigram:[] == trigram:[]
2019-06-14 16:08:16	DEBUG	Punctuation handler ==>> text to process:fgdfgdfg
2019-06-14 16:08:16	DEBUG	Tokenization handler ==>> takens:['fgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	Stemmer handler ==>> stem_tokens:['fgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:08:16	DEBUG	Ngram handler ==>> unigram:['fgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:08:16	DEBUG	Punctuation handler ==>> text to process:dfgdfgdffgdfgdfg
2019-06-14 16:08:16	DEBUG	Tokenization handler ==>> takens:['dfgdfgdffgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfgdffgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:08:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:08:16	DEBUG	Ngram handler ==>> unigram:['dfgdfgdffgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:08:37	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 16:08:37	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:08:37	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 16:08:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:08:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:08:37	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 16:08:37	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-14 16:08:37	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-14 16:08:37	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-14 16:08:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:08:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:08:37	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-14 16:08:37	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-14 16:08:37	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:08:37	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-14 16:08:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:08:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:08:37	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-14 16:08:37	DEBUG	Punctuation handler ==>> text to process:dfsdfsdfsdfdsfsdf
2019-06-14 16:08:37	DEBUG	Tokenization handler ==>> takens:['dfsdfsdfsdfdsfsdf'] and tokenize_without_stop_words:[]
2019-06-14 16:08:37	DEBUG	Stemmer handler ==>> stem_tokens:['dfsdfsdfsdfdsfsdf'] and stem_without_stop_words:[]
2019-06-14 16:08:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:08:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:08:37	DEBUG	Ngram handler ==>> unigram:['dfsdfsdfsdfdsfsdf'] == bigram:[] == trigram:[]
2019-06-14 16:08:37	DEBUG	Punctuation handler ==>> text to process:fgdfgdfg
2019-06-14 16:08:37	DEBUG	Tokenization handler ==>> takens:['fgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:08:37	DEBUG	Stemmer handler ==>> stem_tokens:['fgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:08:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:08:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:08:37	DEBUG	Ngram handler ==>> unigram:['fgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:08:37	DEBUG	Punctuation handler ==>> text to process:dfgdfgdffgdfgdfg
2019-06-14 16:08:37	DEBUG	Tokenization handler ==>> takens:['dfgdfgdffgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:08:37	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfgdffgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:08:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:08:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:08:37	DEBUG	Ngram handler ==>> unigram:['dfgdfgdffgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:08:59	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 16:08:59	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:08:59	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 16:08:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:08:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:08:59	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 16:08:59	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-14 16:08:59	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-14 16:08:59	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-14 16:08:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:08:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:08:59	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-14 16:08:59	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-14 16:08:59	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:08:59	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-14 16:08:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:08:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:08:59	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-14 16:08:59	DEBUG	Punctuation handler ==>> text to process:dfsdfsdfsdfdsfsdf
2019-06-14 16:08:59	DEBUG	Tokenization handler ==>> takens:['dfsdfsdfsdfdsfsdf'] and tokenize_without_stop_words:[]
2019-06-14 16:08:59	DEBUG	Stemmer handler ==>> stem_tokens:['dfsdfsdfsdfdsfsdf'] and stem_without_stop_words:[]
2019-06-14 16:08:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:08:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:08:59	DEBUG	Ngram handler ==>> unigram:['dfsdfsdfsdfdsfsdf'] == bigram:[] == trigram:[]
2019-06-14 16:08:59	DEBUG	Punctuation handler ==>> text to process:fgdfgdfg
2019-06-14 16:08:59	DEBUG	Tokenization handler ==>> takens:['fgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:08:59	DEBUG	Stemmer handler ==>> stem_tokens:['fgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:08:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:08:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:08:59	DEBUG	Ngram handler ==>> unigram:['fgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:08:59	DEBUG	Punctuation handler ==>> text to process:dfgdfgdffgdfgdfg
2019-06-14 16:08:59	DEBUG	Tokenization handler ==>> takens:['dfgdfgdffgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:08:59	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfgdffgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:08:59	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:08:59	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:08:59	DEBUG	Ngram handler ==>> unigram:['dfgdfgdffgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:09:01	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 16:09:01	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:09:01	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 16:09:01	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:09:01	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:09:01	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 16:09:01	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-14 16:09:02	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-14 16:09:02	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-14 16:09:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:09:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:09:02	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-14 16:09:02	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-14 16:09:02	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:09:02	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-14 16:09:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:09:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:09:02	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-14 16:09:02	DEBUG	Punctuation handler ==>> text to process:dfsdfsdfsdfdsfsdf
2019-06-14 16:09:02	DEBUG	Tokenization handler ==>> takens:['dfsdfsdfsdfdsfsdf'] and tokenize_without_stop_words:[]
2019-06-14 16:09:02	DEBUG	Stemmer handler ==>> stem_tokens:['dfsdfsdfsdfdsfsdf'] and stem_without_stop_words:[]
2019-06-14 16:09:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:09:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:09:02	DEBUG	Ngram handler ==>> unigram:['dfsdfsdfsdfdsfsdf'] == bigram:[] == trigram:[]
2019-06-14 16:09:02	DEBUG	Punctuation handler ==>> text to process:fgdfgdfg
2019-06-14 16:09:02	DEBUG	Tokenization handler ==>> takens:['fgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:09:02	DEBUG	Stemmer handler ==>> stem_tokens:['fgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:09:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:09:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:09:02	DEBUG	Ngram handler ==>> unigram:['fgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:09:02	DEBUG	Punctuation handler ==>> text to process:dfgdfgdffgdfgdfg
2019-06-14 16:09:02	DEBUG	Tokenization handler ==>> takens:['dfgdfgdffgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:09:02	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfgdffgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:09:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:09:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:09:02	DEBUG	Ngram handler ==>> unigram:['dfgdfgdffgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:09:03	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 16:09:03	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:09:03	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 16:09:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:09:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:09:03	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 16:09:03	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-14 16:09:03	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-14 16:09:03	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-14 16:09:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:09:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:09:03	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-14 16:09:03	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-14 16:09:03	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:09:03	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-14 16:09:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:09:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:09:03	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-14 16:09:03	DEBUG	Punctuation handler ==>> text to process:dfsdfsdfsdfdsfsdf
2019-06-14 16:09:03	DEBUG	Tokenization handler ==>> takens:['dfsdfsdfsdfdsfsdf'] and tokenize_without_stop_words:[]
2019-06-14 16:09:03	DEBUG	Stemmer handler ==>> stem_tokens:['dfsdfsdfsdfdsfsdf'] and stem_without_stop_words:[]
2019-06-14 16:09:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:09:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:09:03	DEBUG	Ngram handler ==>> unigram:['dfsdfsdfsdfdsfsdf'] == bigram:[] == trigram:[]
2019-06-14 16:09:03	DEBUG	Punctuation handler ==>> text to process:fgdfgdfg
2019-06-14 16:09:03	DEBUG	Tokenization handler ==>> takens:['fgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:09:03	DEBUG	Stemmer handler ==>> stem_tokens:['fgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:09:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:09:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:09:03	DEBUG	Ngram handler ==>> unigram:['fgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:09:03	DEBUG	Punctuation handler ==>> text to process:dfgdfgdffgdfgdfg
2019-06-14 16:09:03	DEBUG	Tokenization handler ==>> takens:['dfgdfgdffgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:09:03	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfgdffgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:09:03	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:09:03	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:09:03	DEBUG	Ngram handler ==>> unigram:['dfgdfgdffgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:10:27	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 16:10:27	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:10:27	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 16:10:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:10:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:10:27	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 16:10:27	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-14 16:10:27	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-14 16:10:27	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-14 16:10:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:10:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:10:27	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-14 16:10:27	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-14 16:10:27	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:10:27	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-14 16:10:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:10:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:10:27	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-14 16:10:27	DEBUG	Punctuation handler ==>> text to process:dfsdfsdfsdfdsfsdf
2019-06-14 16:10:27	DEBUG	Tokenization handler ==>> takens:['dfsdfsdfsdfdsfsdf'] and tokenize_without_stop_words:[]
2019-06-14 16:10:27	DEBUG	Stemmer handler ==>> stem_tokens:['dfsdfsdfsdfdsfsdf'] and stem_without_stop_words:[]
2019-06-14 16:10:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:10:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:10:27	DEBUG	Ngram handler ==>> unigram:['dfsdfsdfsdfdsfsdf'] == bigram:[] == trigram:[]
2019-06-14 16:10:27	DEBUG	Punctuation handler ==>> text to process:fgdfgdfg
2019-06-14 16:10:27	DEBUG	Tokenization handler ==>> takens:['fgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:10:27	DEBUG	Stemmer handler ==>> stem_tokens:['fgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:10:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:10:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:10:27	DEBUG	Ngram handler ==>> unigram:['fgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:10:27	DEBUG	Punctuation handler ==>> text to process:dfgdfgdffgdfgdfg
2019-06-14 16:10:27	DEBUG	Tokenization handler ==>> takens:['dfgdfgdffgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:10:27	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfgdffgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:10:27	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:10:27	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:10:27	DEBUG	Ngram handler ==>> unigram:['dfgdfgdffgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:10:32	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 16:10:32	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:10:32	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 16:10:32	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:10:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:10:32	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 16:10:32	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-14 16:10:32	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-14 16:10:32	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-14 16:10:32	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:10:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:10:32	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-14 16:10:32	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-14 16:10:32	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:10:32	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-14 16:10:32	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:10:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:10:32	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-14 16:10:32	DEBUG	Punctuation handler ==>> text to process:dfsdfsdfsdfdsfsdf
2019-06-14 16:10:32	DEBUG	Tokenization handler ==>> takens:['dfsdfsdfsdfdsfsdf'] and tokenize_without_stop_words:[]
2019-06-14 16:10:32	DEBUG	Stemmer handler ==>> stem_tokens:['dfsdfsdfsdfdsfsdf'] and stem_without_stop_words:[]
2019-06-14 16:10:32	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:10:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:10:32	DEBUG	Ngram handler ==>> unigram:['dfsdfsdfsdfdsfsdf'] == bigram:[] == trigram:[]
2019-06-14 16:10:32	DEBUG	Punctuation handler ==>> text to process:fgdfgdfg
2019-06-14 16:10:32	DEBUG	Tokenization handler ==>> takens:['fgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:10:32	DEBUG	Stemmer handler ==>> stem_tokens:['fgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:10:32	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:10:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:10:32	DEBUG	Ngram handler ==>> unigram:['fgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:10:32	DEBUG	Punctuation handler ==>> text to process:dfgdfgdffgdfgdfg
2019-06-14 16:10:32	DEBUG	Tokenization handler ==>> takens:['dfgdfgdffgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:10:32	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfgdffgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:10:32	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:10:32	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:10:32	DEBUG	Ngram handler ==>> unigram:['dfgdfgdffgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:15:45	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 16:15:46	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:15:46	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 16:15:46	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:15:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:15:46	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 16:15:46	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-14 16:15:46	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-14 16:15:46	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-14 16:15:46	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:15:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:15:46	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-14 16:15:46	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-14 16:15:46	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:15:46	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-14 16:15:46	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:15:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:15:46	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-14 16:15:46	DEBUG	Punctuation handler ==>> text to process:dfsdfsdfsdfdsfsdf
2019-06-14 16:15:46	DEBUG	Tokenization handler ==>> takens:['dfsdfsdfsdfdsfsdf'] and tokenize_without_stop_words:[]
2019-06-14 16:15:46	DEBUG	Stemmer handler ==>> stem_tokens:['dfsdfsdfsdfdsfsdf'] and stem_without_stop_words:[]
2019-06-14 16:15:46	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:15:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:15:46	DEBUG	Ngram handler ==>> unigram:['dfsdfsdfsdfdsfsdf'] == bigram:[] == trigram:[]
2019-06-14 16:15:46	DEBUG	Punctuation handler ==>> text to process:fgdfgdfg
2019-06-14 16:15:46	DEBUG	Tokenization handler ==>> takens:['fgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:15:46	DEBUG	Stemmer handler ==>> stem_tokens:['fgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:15:46	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:15:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:15:46	DEBUG	Ngram handler ==>> unigram:['fgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:15:46	DEBUG	Punctuation handler ==>> text to process:dfgdfgdffgdfgdfg
2019-06-14 16:15:46	DEBUG	Tokenization handler ==>> takens:['dfgdfgdffgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:15:46	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfgdffgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:15:46	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:15:46	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:15:46	DEBUG	Ngram handler ==>> unigram:['dfgdfgdffgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:15:52	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 16:15:52	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:15:52	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 16:15:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:15:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:15:52	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 16:15:52	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-14 16:15:52	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-14 16:15:52	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-14 16:15:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:15:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:15:52	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-14 16:15:52	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-14 16:15:52	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:15:52	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-14 16:15:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:15:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:15:52	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-14 16:15:52	DEBUG	Punctuation handler ==>> text to process:dfsdfsdfsdfdsfsdf
2019-06-14 16:15:52	DEBUG	Tokenization handler ==>> takens:['dfsdfsdfsdfdsfsdf'] and tokenize_without_stop_words:[]
2019-06-14 16:15:52	DEBUG	Stemmer handler ==>> stem_tokens:['dfsdfsdfsdfdsfsdf'] and stem_without_stop_words:[]
2019-06-14 16:15:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:15:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:15:52	DEBUG	Ngram handler ==>> unigram:['dfsdfsdfsdfdsfsdf'] == bigram:[] == trigram:[]
2019-06-14 16:15:52	DEBUG	Punctuation handler ==>> text to process:fgdfgdfg
2019-06-14 16:15:52	DEBUG	Tokenization handler ==>> takens:['fgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:15:52	DEBUG	Stemmer handler ==>> stem_tokens:['fgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:15:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:15:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:15:52	DEBUG	Ngram handler ==>> unigram:['fgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:15:52	DEBUG	Punctuation handler ==>> text to process:dfgdfgdffgdfgdfg
2019-06-14 16:15:52	DEBUG	Tokenization handler ==>> takens:['dfgdfgdffgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:15:52	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfgdffgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:15:52	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:15:52	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:15:52	DEBUG	Ngram handler ==>> unigram:['dfgdfgdffgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:25:51	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 16:25:51	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:25:51	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 16:25:51	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:25:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:25:51	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 16:25:51	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-14 16:25:51	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-14 16:25:51	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-14 16:25:51	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:25:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:25:51	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-14 16:25:51	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-14 16:25:51	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:25:51	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-14 16:25:51	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:25:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:25:51	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-14 16:25:51	DEBUG	Punctuation handler ==>> text to process:dfsdfsdfsdfdsfsdf
2019-06-14 16:25:51	DEBUG	Tokenization handler ==>> takens:['dfsdfsdfsdfdsfsdf'] and tokenize_without_stop_words:[]
2019-06-14 16:25:51	DEBUG	Stemmer handler ==>> stem_tokens:['dfsdfsdfsdfdsfsdf'] and stem_without_stop_words:[]
2019-06-14 16:25:51	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:25:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:25:51	DEBUG	Ngram handler ==>> unigram:['dfsdfsdfsdfdsfsdf'] == bigram:[] == trigram:[]
2019-06-14 16:25:51	DEBUG	Punctuation handler ==>> text to process:fgdfgdfg
2019-06-14 16:25:51	DEBUG	Tokenization handler ==>> takens:['fgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:25:51	DEBUG	Stemmer handler ==>> stem_tokens:['fgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:25:51	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:25:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:25:51	DEBUG	Ngram handler ==>> unigram:['fgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:25:51	DEBUG	Punctuation handler ==>> text to process:dfgdfgdffgdfgdfg
2019-06-14 16:25:51	DEBUG	Tokenization handler ==>> takens:['dfgdfgdffgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:25:51	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfgdffgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:25:51	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:25:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:25:51	DEBUG	Ngram handler ==>> unigram:['dfgdfgdffgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:25:56	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 16:25:56	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:25:56	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 16:25:56	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:25:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:25:56	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 16:25:56	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-14 16:25:56	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-14 16:25:56	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-14 16:25:56	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:25:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:25:56	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-14 16:25:56	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-14 16:25:56	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:25:56	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-14 16:25:56	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:25:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:25:56	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-14 16:25:56	DEBUG	Punctuation handler ==>> text to process:dfsdfsdfsdfdsfsdf
2019-06-14 16:25:56	DEBUG	Tokenization handler ==>> takens:['dfsdfsdfsdfdsfsdf'] and tokenize_without_stop_words:[]
2019-06-14 16:25:56	DEBUG	Stemmer handler ==>> stem_tokens:['dfsdfsdfsdfdsfsdf'] and stem_without_stop_words:[]
2019-06-14 16:25:56	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:25:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:25:56	DEBUG	Ngram handler ==>> unigram:['dfsdfsdfsdfdsfsdf'] == bigram:[] == trigram:[]
2019-06-14 16:25:56	DEBUG	Punctuation handler ==>> text to process:fgdfgdfg
2019-06-14 16:25:56	DEBUG	Tokenization handler ==>> takens:['fgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:25:56	DEBUG	Stemmer handler ==>> stem_tokens:['fgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:25:56	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:25:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:25:56	DEBUG	Ngram handler ==>> unigram:['fgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:25:56	DEBUG	Punctuation handler ==>> text to process:dfgdfgdffgdfgdfg
2019-06-14 16:25:56	DEBUG	Tokenization handler ==>> takens:['dfgdfgdffgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:25:56	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfgdffgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:25:56	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:25:56	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:25:56	DEBUG	Ngram handler ==>> unigram:['dfgdfgdffgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:27:14	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 16:27:14	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:27:14	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 16:27:14	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:27:14	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:27:14	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 16:27:14	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-14 16:27:14	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-14 16:27:14	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-14 16:27:14	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:27:14	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:27:14	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-14 16:27:14	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-14 16:27:14	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:27:14	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-14 16:27:14	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:27:14	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:27:14	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-14 16:27:14	DEBUG	Punctuation handler ==>> text to process:dfsdfsdfsdfdsfsdf
2019-06-14 16:27:14	DEBUG	Tokenization handler ==>> takens:['dfsdfsdfsdfdsfsdf'] and tokenize_without_stop_words:[]
2019-06-14 16:27:14	DEBUG	Stemmer handler ==>> stem_tokens:['dfsdfsdfsdfdsfsdf'] and stem_without_stop_words:[]
2019-06-14 16:27:14	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:27:14	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:27:14	DEBUG	Ngram handler ==>> unigram:['dfsdfsdfsdfdsfsdf'] == bigram:[] == trigram:[]
2019-06-14 16:27:14	DEBUG	Punctuation handler ==>> text to process:fgdfgdfg
2019-06-14 16:27:14	DEBUG	Tokenization handler ==>> takens:['fgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:27:14	DEBUG	Stemmer handler ==>> stem_tokens:['fgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:27:14	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:27:14	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:27:14	DEBUG	Ngram handler ==>> unigram:['fgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:27:14	DEBUG	Punctuation handler ==>> text to process:dfgdfgdffgdfgdfg
2019-06-14 16:27:14	DEBUG	Tokenization handler ==>> takens:['dfgdfgdffgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:27:14	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfgdffgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:27:14	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:27:14	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:27:14	DEBUG	Ngram handler ==>> unigram:['dfgdfgdffgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:28:47	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 16:28:47	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:28:47	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 16:28:47	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:28:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:28:47	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 16:28:47	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-14 16:28:47	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-14 16:28:47	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-14 16:28:47	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:28:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:28:47	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-14 16:28:47	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-14 16:28:47	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:28:47	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-14 16:28:47	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:28:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:28:47	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-14 16:28:47	DEBUG	Punctuation handler ==>> text to process:dfsdfsdfsdfdsfsdf
2019-06-14 16:28:47	DEBUG	Tokenization handler ==>> takens:['dfsdfsdfsdfdsfsdf'] and tokenize_without_stop_words:[]
2019-06-14 16:28:47	DEBUG	Stemmer handler ==>> stem_tokens:['dfsdfsdfsdfdsfsdf'] and stem_without_stop_words:[]
2019-06-14 16:28:47	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:28:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:28:47	DEBUG	Ngram handler ==>> unigram:['dfsdfsdfsdfdsfsdf'] == bigram:[] == trigram:[]
2019-06-14 16:28:47	DEBUG	Punctuation handler ==>> text to process:fgdfgdfg
2019-06-14 16:28:47	DEBUG	Tokenization handler ==>> takens:['fgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:28:47	DEBUG	Stemmer handler ==>> stem_tokens:['fgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:28:47	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:28:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:28:47	DEBUG	Ngram handler ==>> unigram:['fgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:28:47	DEBUG	Punctuation handler ==>> text to process:dfgdfgdffgdfgdfg
2019-06-14 16:28:47	DEBUG	Tokenization handler ==>> takens:['dfgdfgdffgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:28:47	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfgdffgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:28:47	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:28:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:28:47	DEBUG	Ngram handler ==>> unigram:['dfgdfgdffgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:29:47	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 16:29:47	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:29:47	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 16:29:47	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:29:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:29:47	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 16:29:47	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-14 16:29:47	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-14 16:29:47	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-14 16:29:47	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:29:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:29:47	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-14 16:29:47	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-14 16:29:47	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:29:47	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-14 16:29:47	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:29:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:29:47	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-14 16:29:47	DEBUG	Punctuation handler ==>> text to process:dfsdfsdfsdfdsfsdf
2019-06-14 16:29:47	DEBUG	Tokenization handler ==>> takens:['dfsdfsdfsdfdsfsdf'] and tokenize_without_stop_words:[]
2019-06-14 16:29:47	DEBUG	Stemmer handler ==>> stem_tokens:['dfsdfsdfsdfdsfsdf'] and stem_without_stop_words:[]
2019-06-14 16:29:47	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:29:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:29:47	DEBUG	Ngram handler ==>> unigram:['dfsdfsdfsdfdsfsdf'] == bigram:[] == trigram:[]
2019-06-14 16:29:47	DEBUG	Punctuation handler ==>> text to process:fgdfgdfg
2019-06-14 16:29:47	DEBUG	Tokenization handler ==>> takens:['fgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:29:47	DEBUG	Stemmer handler ==>> stem_tokens:['fgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:29:47	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:29:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:29:47	DEBUG	Ngram handler ==>> unigram:['fgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:29:47	DEBUG	Punctuation handler ==>> text to process:dfgdfgdffgdfgdfg
2019-06-14 16:29:47	DEBUG	Tokenization handler ==>> takens:['dfgdfgdffgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:29:47	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfgdffgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:29:47	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:29:47	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:29:47	DEBUG	Ngram handler ==>> unigram:['dfgdfgdffgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:30:12	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 16:30:12	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:30:12	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 16:30:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:30:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:30:12	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 16:30:12	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-14 16:30:12	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-14 16:30:12	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-14 16:30:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:30:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:30:12	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-14 16:30:12	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-14 16:30:12	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:30:12	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-14 16:30:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:30:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:30:12	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-14 16:30:12	DEBUG	Punctuation handler ==>> text to process:dfsdfsdfsdfdsfsdf
2019-06-14 16:30:12	DEBUG	Tokenization handler ==>> takens:['dfsdfsdfsdfdsfsdf'] and tokenize_without_stop_words:[]
2019-06-14 16:30:12	DEBUG	Stemmer handler ==>> stem_tokens:['dfsdfsdfsdfdsfsdf'] and stem_without_stop_words:[]
2019-06-14 16:30:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:30:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:30:12	DEBUG	Ngram handler ==>> unigram:['dfsdfsdfsdfdsfsdf'] == bigram:[] == trigram:[]
2019-06-14 16:30:12	DEBUG	Punctuation handler ==>> text to process:fgdfgdfg
2019-06-14 16:30:12	DEBUG	Tokenization handler ==>> takens:['fgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:30:12	DEBUG	Stemmer handler ==>> stem_tokens:['fgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:30:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:30:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:30:12	DEBUG	Ngram handler ==>> unigram:['fgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:30:12	DEBUG	Punctuation handler ==>> text to process:dfgdfgdffgdfgdfg
2019-06-14 16:30:12	DEBUG	Tokenization handler ==>> takens:['dfgdfgdffgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:30:12	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfgdffgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:30:12	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:30:12	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:30:12	DEBUG	Ngram handler ==>> unigram:['dfgdfgdffgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:30:28	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 16:30:28	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:30:28	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 16:30:28	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:30:28	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:30:28	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 16:30:28	DEBUG	Punctuation handler ==>> text to process:dummy
2019-06-14 16:30:28	DEBUG	Tokenization handler ==>> takens:['dummy'] and tokenize_without_stop_words:[]
2019-06-14 16:30:28	DEBUG	Stemmer handler ==>> stem_tokens:['dummi'] and stem_without_stop_words:[]
2019-06-14 16:30:28	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:30:28	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:30:28	DEBUG	Ngram handler ==>> unigram:['dummi'] == bigram:[] == trigram:[]
2019-06-14 16:30:28	DEBUG	Punctuation handler ==>> text to process:mcq phrase
2019-06-14 16:30:28	DEBUG	Tokenization handler ==>> takens:['mcq', 'phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:30:28	DEBUG	Stemmer handler ==>> stem_tokens:['mcq', 'phrase'] and stem_without_stop_words:[]
2019-06-14 16:30:28	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:30:28	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:30:28	DEBUG	Ngram handler ==>> unigram:['mcq', 'phrase'] == bigram:['mcq phrase'] == trigram:[]
2019-06-14 16:30:28	DEBUG	Punctuation handler ==>> text to process:dfsdfsdfsdfdsfsdf
2019-06-14 16:30:28	DEBUG	Tokenization handler ==>> takens:['dfsdfsdfsdfdsfsdf'] and tokenize_without_stop_words:[]
2019-06-14 16:30:28	DEBUG	Stemmer handler ==>> stem_tokens:['dfsdfsdfsdfdsfsdf'] and stem_without_stop_words:[]
2019-06-14 16:30:28	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:30:28	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:30:28	DEBUG	Ngram handler ==>> unigram:['dfsdfsdfsdfdsfsdf'] == bigram:[] == trigram:[]
2019-06-14 16:30:28	DEBUG	Punctuation handler ==>> text to process:fgdfgdfg
2019-06-14 16:30:28	DEBUG	Tokenization handler ==>> takens:['fgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:30:28	DEBUG	Stemmer handler ==>> stem_tokens:['fgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:30:28	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:30:28	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:30:28	DEBUG	Ngram handler ==>> unigram:['fgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:30:28	DEBUG	Punctuation handler ==>> text to process:dfgdfgdffgdfgdfg
2019-06-14 16:30:28	DEBUG	Tokenization handler ==>> takens:['dfgdfgdffgdfgdfg'] and tokenize_without_stop_words:[]
2019-06-14 16:30:28	DEBUG	Stemmer handler ==>> stem_tokens:['dfgdfgdffgdfgdfg'] and stem_without_stop_words:[]
2019-06-14 16:30:28	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:30:28	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:30:28	DEBUG	Ngram handler ==>> unigram:['dfgdfgdffgdfgdfg'] == bigram:[] == trigram:[]
2019-06-14 16:37:45	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 16:37:45	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 16:37:45	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 16:37:45	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 16:37:45	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 16:37:45	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 17:48:50	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 17:48:50	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 17:48:50	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 17:48:50	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 17:48:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 17:48:50	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 22:29:40	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 22:29:40	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 22:29:40	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 22:29:40	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:29:40	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:29:40	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 22:41:29	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 22:41:29	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 22:41:29	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 22:41:29	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:41:29	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:41:29	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 22:42:21	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 22:42:21	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 22:42:21	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 22:42:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:42:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:42:21	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 22:42:21	DEBUG	Punctuation handler ==>> text to process:test
2019-06-14 22:42:21	DEBUG	Tokenization handler ==>> takens:['test'] and tokenize_without_stop_words:[]
2019-06-14 22:42:21	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 22:42:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:42:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:42:21	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 22:42:21	DEBUG	Punctuation handler ==>> text to process:testing
2019-06-14 22:42:21	DEBUG	Tokenization handler ==>> takens:['testing'] and tokenize_without_stop_words:[]
2019-06-14 22:42:21	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 22:42:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:42:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:42:21	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 22:42:21	DEBUG	Punctuation handler ==>> text to process:payment
2019-06-14 22:42:21	DEBUG	Tokenization handler ==>> takens:['payment'] and tokenize_without_stop_words:[]
2019-06-14 22:42:21	DEBUG	Stemmer handler ==>> stem_tokens:['payment'] and stem_without_stop_words:[]
2019-06-14 22:42:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:42:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:42:21	DEBUG	Ngram handler ==>> unigram:['payment'] == bigram:[] == trigram:[]
2019-06-14 22:42:21	DEBUG	Punctuation handler ==>> text to process:paymentdata
2019-06-14 22:42:21	DEBUG	Tokenization handler ==>> takens:['paymentdata'] and tokenize_without_stop_words:[]
2019-06-14 22:42:21	DEBUG	Stemmer handler ==>> stem_tokens:['paymentdata'] and stem_without_stop_words:[]
2019-06-14 22:42:21	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:42:21	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:42:21	DEBUG	Ngram handler ==>> unigram:['paymentdata'] == bigram:[] == trigram:[]
2019-06-14 22:43:02	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 22:43:02	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 22:43:02	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 22:43:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:43:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:43:02	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 22:43:02	DEBUG	Punctuation handler ==>> text to process:test
2019-06-14 22:43:02	DEBUG	Tokenization handler ==>> takens:['test'] and tokenize_without_stop_words:[]
2019-06-14 22:43:02	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 22:43:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:43:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:43:02	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 22:43:02	DEBUG	Punctuation handler ==>> text to process:testing
2019-06-14 22:43:02	DEBUG	Tokenization handler ==>> takens:['testing'] and tokenize_without_stop_words:[]
2019-06-14 22:43:02	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 22:43:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:43:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:43:02	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 22:43:02	DEBUG	Punctuation handler ==>> text to process:payment
2019-06-14 22:43:02	DEBUG	Tokenization handler ==>> takens:['payment'] and tokenize_without_stop_words:[]
2019-06-14 22:43:02	DEBUG	Stemmer handler ==>> stem_tokens:['payment'] and stem_without_stop_words:[]
2019-06-14 22:43:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:43:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:43:02	DEBUG	Ngram handler ==>> unigram:['payment'] == bigram:[] == trigram:[]
2019-06-14 22:43:02	DEBUG	Punctuation handler ==>> text to process:paymentdata
2019-06-14 22:43:02	DEBUG	Tokenization handler ==>> takens:['paymentdata'] and tokenize_without_stop_words:[]
2019-06-14 22:43:02	DEBUG	Stemmer handler ==>> stem_tokens:['paymentdata'] and stem_without_stop_words:[]
2019-06-14 22:43:02	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:43:02	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:43:02	DEBUG	Ngram handler ==>> unigram:['paymentdata'] == bigram:[] == trigram:[]
2019-06-14 22:44:09	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 22:44:09	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 22:44:09	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 22:44:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:44:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:44:09	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 22:44:09	DEBUG	Punctuation handler ==>> text to process:test
2019-06-14 22:44:09	DEBUG	Tokenization handler ==>> takens:['test'] and tokenize_without_stop_words:[]
2019-06-14 22:44:09	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 22:44:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:44:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:44:09	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 22:44:09	DEBUG	Punctuation handler ==>> text to process:testing
2019-06-14 22:44:09	DEBUG	Tokenization handler ==>> takens:['testing'] and tokenize_without_stop_words:[]
2019-06-14 22:44:09	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 22:44:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:44:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:44:09	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 22:44:09	DEBUG	Punctuation handler ==>> text to process:payment
2019-06-14 22:44:09	DEBUG	Tokenization handler ==>> takens:['payment'] and tokenize_without_stop_words:[]
2019-06-14 22:44:09	DEBUG	Stemmer handler ==>> stem_tokens:['payment'] and stem_without_stop_words:[]
2019-06-14 22:44:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:44:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:44:09	DEBUG	Ngram handler ==>> unigram:['payment'] == bigram:[] == trigram:[]
2019-06-14 22:44:09	DEBUG	Punctuation handler ==>> text to process:paymentdata
2019-06-14 22:44:09	DEBUG	Tokenization handler ==>> takens:['paymentdata'] and tokenize_without_stop_words:[]
2019-06-14 22:44:09	DEBUG	Stemmer handler ==>> stem_tokens:['paymentdata'] and stem_without_stop_words:[]
2019-06-14 22:44:09	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:44:09	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:44:09	DEBUG	Ngram handler ==>> unigram:['paymentdata'] == bigram:[] == trigram:[]
2019-06-14 22:44:16	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 22:44:16	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 22:44:16	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 22:44:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:44:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:44:16	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 22:44:16	DEBUG	Punctuation handler ==>> text to process:test
2019-06-14 22:44:16	DEBUG	Tokenization handler ==>> takens:['test'] and tokenize_without_stop_words:[]
2019-06-14 22:44:16	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 22:44:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:44:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:44:16	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 22:44:16	DEBUG	Punctuation handler ==>> text to process:testing
2019-06-14 22:44:16	DEBUG	Tokenization handler ==>> takens:['testing'] and tokenize_without_stop_words:[]
2019-06-14 22:44:16	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 22:44:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:44:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:44:16	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 22:44:16	DEBUG	Punctuation handler ==>> text to process:payment
2019-06-14 22:44:16	DEBUG	Tokenization handler ==>> takens:['payment'] and tokenize_without_stop_words:[]
2019-06-14 22:44:16	DEBUG	Stemmer handler ==>> stem_tokens:['payment'] and stem_without_stop_words:[]
2019-06-14 22:44:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:44:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:44:16	DEBUG	Ngram handler ==>> unigram:['payment'] == bigram:[] == trigram:[]
2019-06-14 22:44:16	DEBUG	Punctuation handler ==>> text to process:paymentdata
2019-06-14 22:44:16	DEBUG	Tokenization handler ==>> takens:['paymentdata'] and tokenize_without_stop_words:[]
2019-06-14 22:44:16	DEBUG	Stemmer handler ==>> stem_tokens:['paymentdata'] and stem_without_stop_words:[]
2019-06-14 22:44:16	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:44:16	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:44:16	DEBUG	Ngram handler ==>> unigram:['paymentdata'] == bigram:[] == trigram:[]
2019-06-14 22:54:37	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 22:54:37	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 22:54:37	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 22:54:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:54:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:54:37	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 22:54:37	DEBUG	Punctuation handler ==>> text to process:test
2019-06-14 22:54:37	DEBUG	Tokenization handler ==>> takens:['test'] and tokenize_without_stop_words:[]
2019-06-14 22:54:37	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 22:54:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:54:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:54:37	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 22:54:37	DEBUG	Punctuation handler ==>> text to process:testing
2019-06-14 22:54:37	DEBUG	Tokenization handler ==>> takens:['testing'] and tokenize_without_stop_words:[]
2019-06-14 22:54:37	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 22:54:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:54:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:54:37	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 22:54:37	DEBUG	Punctuation handler ==>> text to process:payment
2019-06-14 22:54:37	DEBUG	Tokenization handler ==>> takens:['payment'] and tokenize_without_stop_words:[]
2019-06-14 22:54:37	DEBUG	Stemmer handler ==>> stem_tokens:['payment'] and stem_without_stop_words:[]
2019-06-14 22:54:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:54:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:54:37	DEBUG	Ngram handler ==>> unigram:['payment'] == bigram:[] == trigram:[]
2019-06-14 22:54:37	DEBUG	Punctuation handler ==>> text to process:paymentdata
2019-06-14 22:54:37	DEBUG	Tokenization handler ==>> takens:['paymentdata'] and tokenize_without_stop_words:[]
2019-06-14 22:54:37	DEBUG	Stemmer handler ==>> stem_tokens:['paymentdata'] and stem_without_stop_words:[]
2019-06-14 22:54:37	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:54:37	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:54:37	DEBUG	Ngram handler ==>> unigram:['paymentdata'] == bigram:[] == trigram:[]
2019-06-14 22:54:49	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 22:54:49	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 22:54:49	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 22:54:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:54:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:54:49	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 22:54:49	DEBUG	Punctuation handler ==>> text to process:test
2019-06-14 22:54:49	DEBUG	Tokenization handler ==>> takens:['test'] and tokenize_without_stop_words:[]
2019-06-14 22:54:49	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 22:54:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:54:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:54:49	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 22:54:49	DEBUG	Punctuation handler ==>> text to process:testing
2019-06-14 22:54:49	DEBUG	Tokenization handler ==>> takens:['testing'] and tokenize_without_stop_words:[]
2019-06-14 22:54:49	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 22:54:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:54:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:54:49	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 22:54:49	DEBUG	Punctuation handler ==>> text to process:payment
2019-06-14 22:54:49	DEBUG	Tokenization handler ==>> takens:['payment'] and tokenize_without_stop_words:[]
2019-06-14 22:54:49	DEBUG	Stemmer handler ==>> stem_tokens:['payment'] and stem_without_stop_words:[]
2019-06-14 22:54:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:54:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:54:49	DEBUG	Ngram handler ==>> unigram:['payment'] == bigram:[] == trigram:[]
2019-06-14 22:54:49	DEBUG	Punctuation handler ==>> text to process:paymentdata
2019-06-14 22:54:49	DEBUG	Tokenization handler ==>> takens:['paymentdata'] and tokenize_without_stop_words:[]
2019-06-14 22:54:49	DEBUG	Stemmer handler ==>> stem_tokens:['paymentdata'] and stem_without_stop_words:[]
2019-06-14 22:54:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:54:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:54:49	DEBUG	Ngram handler ==>> unigram:['paymentdata'] == bigram:[] == trigram:[]
2019-06-14 22:55:26	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 22:55:26	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 22:55:26	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 22:55:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:55:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:55:26	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 22:55:26	DEBUG	Punctuation handler ==>> text to process:test
2019-06-14 22:55:26	DEBUG	Tokenization handler ==>> takens:['test'] and tokenize_without_stop_words:[]
2019-06-14 22:55:26	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 22:55:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:55:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:55:26	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 22:55:26	DEBUG	Punctuation handler ==>> text to process:testing
2019-06-14 22:55:26	DEBUG	Tokenization handler ==>> takens:['testing'] and tokenize_without_stop_words:[]
2019-06-14 22:55:26	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 22:55:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:55:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:55:26	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 22:55:26	DEBUG	Punctuation handler ==>> text to process:payment
2019-06-14 22:55:26	DEBUG	Tokenization handler ==>> takens:['payment'] and tokenize_without_stop_words:[]
2019-06-14 22:55:26	DEBUG	Stemmer handler ==>> stem_tokens:['payment'] and stem_without_stop_words:[]
2019-06-14 22:55:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:55:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:55:26	DEBUG	Ngram handler ==>> unigram:['payment'] == bigram:[] == trigram:[]
2019-06-14 22:55:26	DEBUG	Punctuation handler ==>> text to process:paymentdata
2019-06-14 22:55:26	DEBUG	Tokenization handler ==>> takens:['paymentdata'] and tokenize_without_stop_words:[]
2019-06-14 22:55:26	DEBUG	Stemmer handler ==>> stem_tokens:['paymentdata'] and stem_without_stop_words:[]
2019-06-14 22:55:26	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:55:26	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:55:26	DEBUG	Ngram handler ==>> unigram:['paymentdata'] == bigram:[] == trigram:[]
2019-06-14 22:56:31	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 22:56:31	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 22:56:31	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 22:56:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:56:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:56:31	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 22:56:31	DEBUG	Punctuation handler ==>> text to process:test
2019-06-14 22:56:31	DEBUG	Tokenization handler ==>> takens:['test'] and tokenize_without_stop_words:[]
2019-06-14 22:56:31	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 22:56:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:56:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:56:31	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 22:56:31	DEBUG	Punctuation handler ==>> text to process:testing
2019-06-14 22:56:31	DEBUG	Tokenization handler ==>> takens:['testing'] and tokenize_without_stop_words:[]
2019-06-14 22:56:31	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 22:56:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:56:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:56:31	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 22:56:31	DEBUG	Punctuation handler ==>> text to process:payment
2019-06-14 22:56:31	DEBUG	Tokenization handler ==>> takens:['payment'] and tokenize_without_stop_words:[]
2019-06-14 22:56:31	DEBUG	Stemmer handler ==>> stem_tokens:['payment'] and stem_without_stop_words:[]
2019-06-14 22:56:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:56:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:56:31	DEBUG	Ngram handler ==>> unigram:['payment'] == bigram:[] == trigram:[]
2019-06-14 22:56:31	DEBUG	Punctuation handler ==>> text to process:paymentdata
2019-06-14 22:56:31	DEBUG	Tokenization handler ==>> takens:['paymentdata'] and tokenize_without_stop_words:[]
2019-06-14 22:56:31	DEBUG	Stemmer handler ==>> stem_tokens:['paymentdata'] and stem_without_stop_words:[]
2019-06-14 22:56:31	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:56:31	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:56:31	DEBUG	Ngram handler ==>> unigram:['paymentdata'] == bigram:[] == trigram:[]
2019-06-14 22:56:51	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 22:56:51	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 22:56:51	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 22:56:51	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:56:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:56:51	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 22:56:51	DEBUG	Punctuation handler ==>> text to process:test
2019-06-14 22:56:51	DEBUG	Tokenization handler ==>> takens:['test'] and tokenize_without_stop_words:[]
2019-06-14 22:56:51	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 22:56:51	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:56:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:56:51	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 22:56:51	DEBUG	Punctuation handler ==>> text to process:testing
2019-06-14 22:56:51	DEBUG	Tokenization handler ==>> takens:['testing'] and tokenize_without_stop_words:[]
2019-06-14 22:56:51	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 22:56:51	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:56:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:56:51	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 22:56:51	DEBUG	Punctuation handler ==>> text to process:payment
2019-06-14 22:56:51	DEBUG	Tokenization handler ==>> takens:['payment'] and tokenize_without_stop_words:[]
2019-06-14 22:56:51	DEBUG	Stemmer handler ==>> stem_tokens:['payment'] and stem_without_stop_words:[]
2019-06-14 22:56:51	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:56:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:56:51	DEBUG	Ngram handler ==>> unigram:['payment'] == bigram:[] == trigram:[]
2019-06-14 22:56:51	DEBUG	Punctuation handler ==>> text to process:paymentdata
2019-06-14 22:56:51	DEBUG	Tokenization handler ==>> takens:['paymentdata'] and tokenize_without_stop_words:[]
2019-06-14 22:56:51	DEBUG	Stemmer handler ==>> stem_tokens:['paymentdata'] and stem_without_stop_words:[]
2019-06-14 22:56:51	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:56:51	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:56:51	DEBUG	Ngram handler ==>> unigram:['paymentdata'] == bigram:[] == trigram:[]
2019-06-14 22:57:18	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 22:57:18	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 22:57:18	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 22:57:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:57:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:57:18	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 22:57:18	DEBUG	Punctuation handler ==>> text to process:test
2019-06-14 22:57:18	DEBUG	Tokenization handler ==>> takens:['test'] and tokenize_without_stop_words:[]
2019-06-14 22:57:18	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 22:57:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:57:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:57:18	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 22:57:18	DEBUG	Punctuation handler ==>> text to process:testing
2019-06-14 22:57:18	DEBUG	Tokenization handler ==>> takens:['testing'] and tokenize_without_stop_words:[]
2019-06-14 22:57:18	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 22:57:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:57:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:57:18	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 22:57:18	DEBUG	Punctuation handler ==>> text to process:payment
2019-06-14 22:57:18	DEBUG	Tokenization handler ==>> takens:['payment'] and tokenize_without_stop_words:[]
2019-06-14 22:57:18	DEBUG	Stemmer handler ==>> stem_tokens:['payment'] and stem_without_stop_words:[]
2019-06-14 22:57:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:57:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:57:18	DEBUG	Ngram handler ==>> unigram:['payment'] == bigram:[] == trigram:[]
2019-06-14 22:57:18	DEBUG	Punctuation handler ==>> text to process:paymentdata
2019-06-14 22:57:18	DEBUG	Tokenization handler ==>> takens:['paymentdata'] and tokenize_without_stop_words:[]
2019-06-14 22:57:18	DEBUG	Stemmer handler ==>> stem_tokens:['paymentdata'] and stem_without_stop_words:[]
2019-06-14 22:57:18	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:57:18	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:57:18	DEBUG	Ngram handler ==>> unigram:['paymentdata'] == bigram:[] == trigram:[]
2019-06-14 22:58:50	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 22:58:50	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 22:58:50	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 22:58:50	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:58:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:58:50	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 22:58:50	DEBUG	Punctuation handler ==>> text to process:test
2019-06-14 22:58:50	DEBUG	Tokenization handler ==>> takens:['test'] and tokenize_without_stop_words:[]
2019-06-14 22:58:50	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 22:58:50	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:58:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:58:50	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 22:58:50	DEBUG	Punctuation handler ==>> text to process:testing
2019-06-14 22:58:50	DEBUG	Tokenization handler ==>> takens:['testing'] and tokenize_without_stop_words:[]
2019-06-14 22:58:50	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 22:58:50	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:58:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:58:50	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 22:58:50	DEBUG	Punctuation handler ==>> text to process:payment
2019-06-14 22:58:50	DEBUG	Tokenization handler ==>> takens:['payment'] and tokenize_without_stop_words:[]
2019-06-14 22:58:50	DEBUG	Stemmer handler ==>> stem_tokens:['payment'] and stem_without_stop_words:[]
2019-06-14 22:58:50	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:58:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:58:50	DEBUG	Ngram handler ==>> unigram:['payment'] == bigram:[] == trigram:[]
2019-06-14 22:58:50	DEBUG	Punctuation handler ==>> text to process:paymentdata
2019-06-14 22:58:50	DEBUG	Tokenization handler ==>> takens:['paymentdata'] and tokenize_without_stop_words:[]
2019-06-14 22:58:50	DEBUG	Stemmer handler ==>> stem_tokens:['paymentdata'] and stem_without_stop_words:[]
2019-06-14 22:58:50	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:58:50	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:58:50	DEBUG	Ngram handler ==>> unigram:['paymentdata'] == bigram:[] == trigram:[]
2019-06-14 22:59:08	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 22:59:08	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 22:59:08	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 22:59:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:59:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:59:08	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 22:59:08	DEBUG	Punctuation handler ==>> text to process:test
2019-06-14 22:59:08	DEBUG	Tokenization handler ==>> takens:['test'] and tokenize_without_stop_words:[]
2019-06-14 22:59:08	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 22:59:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:59:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:59:08	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 22:59:08	DEBUG	Punctuation handler ==>> text to process:testing
2019-06-14 22:59:08	DEBUG	Tokenization handler ==>> takens:['testing'] and tokenize_without_stop_words:[]
2019-06-14 22:59:08	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 22:59:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:59:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:59:08	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 22:59:08	DEBUG	Punctuation handler ==>> text to process:payment
2019-06-14 22:59:08	DEBUG	Tokenization handler ==>> takens:['payment'] and tokenize_without_stop_words:[]
2019-06-14 22:59:08	DEBUG	Stemmer handler ==>> stem_tokens:['payment'] and stem_without_stop_words:[]
2019-06-14 22:59:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:59:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:59:08	DEBUG	Ngram handler ==>> unigram:['payment'] == bigram:[] == trigram:[]
2019-06-14 22:59:08	DEBUG	Punctuation handler ==>> text to process:paymentdata
2019-06-14 22:59:08	DEBUG	Tokenization handler ==>> takens:['paymentdata'] and tokenize_without_stop_words:[]
2019-06-14 22:59:08	DEBUG	Stemmer handler ==>> stem_tokens:['paymentdata'] and stem_without_stop_words:[]
2019-06-14 22:59:08	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:59:08	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:59:08	DEBUG	Ngram handler ==>> unigram:['paymentdata'] == bigram:[] == trigram:[]
2019-06-14 22:59:49	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 22:59:49	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 22:59:49	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 22:59:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:59:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:59:49	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 22:59:49	DEBUG	Punctuation handler ==>> text to process:test
2019-06-14 22:59:49	DEBUG	Tokenization handler ==>> takens:['test'] and tokenize_without_stop_words:[]
2019-06-14 22:59:49	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 22:59:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:59:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:59:49	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 22:59:49	DEBUG	Punctuation handler ==>> text to process:testing
2019-06-14 22:59:49	DEBUG	Tokenization handler ==>> takens:['testing'] and tokenize_without_stop_words:[]
2019-06-14 22:59:49	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 22:59:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:59:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:59:49	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 22:59:49	DEBUG	Punctuation handler ==>> text to process:payment
2019-06-14 22:59:49	DEBUG	Tokenization handler ==>> takens:['payment'] and tokenize_without_stop_words:[]
2019-06-14 22:59:49	DEBUG	Stemmer handler ==>> stem_tokens:['payment'] and stem_without_stop_words:[]
2019-06-14 22:59:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:59:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:59:49	DEBUG	Ngram handler ==>> unigram:['payment'] == bigram:[] == trigram:[]
2019-06-14 22:59:49	DEBUG	Punctuation handler ==>> text to process:paymentdata
2019-06-14 22:59:49	DEBUG	Tokenization handler ==>> takens:['paymentdata'] and tokenize_without_stop_words:[]
2019-06-14 22:59:49	DEBUG	Stemmer handler ==>> stem_tokens:['paymentdata'] and stem_without_stop_words:[]
2019-06-14 22:59:49	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 22:59:49	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 22:59:49	DEBUG	Ngram handler ==>> unigram:['paymentdata'] == bigram:[] == trigram:[]
2019-06-14 23:00:04	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 23:00:04	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 23:00:04	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 23:00:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 23:00:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 23:00:04	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 23:00:04	DEBUG	Punctuation handler ==>> text to process:test
2019-06-14 23:00:04	DEBUG	Tokenization handler ==>> takens:['test'] and tokenize_without_stop_words:[]
2019-06-14 23:00:04	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 23:00:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 23:00:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 23:00:04	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 23:00:04	DEBUG	Punctuation handler ==>> text to process:testing
2019-06-14 23:00:04	DEBUG	Tokenization handler ==>> takens:['testing'] and tokenize_without_stop_words:[]
2019-06-14 23:00:04	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 23:00:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 23:00:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 23:00:04	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 23:00:04	DEBUG	Punctuation handler ==>> text to process:payment
2019-06-14 23:00:04	DEBUG	Tokenization handler ==>> takens:['payment'] and tokenize_without_stop_words:[]
2019-06-14 23:00:04	DEBUG	Stemmer handler ==>> stem_tokens:['payment'] and stem_without_stop_words:[]
2019-06-14 23:00:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 23:00:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 23:00:04	DEBUG	Ngram handler ==>> unigram:['payment'] == bigram:[] == trigram:[]
2019-06-14 23:00:04	DEBUG	Punctuation handler ==>> text to process:paymentdata
2019-06-14 23:00:04	DEBUG	Tokenization handler ==>> takens:['paymentdata'] and tokenize_without_stop_words:[]
2019-06-14 23:00:04	DEBUG	Stemmer handler ==>> stem_tokens:['paymentdata'] and stem_without_stop_words:[]
2019-06-14 23:00:04	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 23:00:04	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 23:00:04	DEBUG	Ngram handler ==>> unigram:['paymentdata'] == bigram:[] == trigram:[]
2019-06-14 23:00:11	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 23:00:11	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 23:00:11	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 23:00:11	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 23:00:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 23:00:11	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 23:00:11	DEBUG	Punctuation handler ==>> text to process:test
2019-06-14 23:00:11	DEBUG	Tokenization handler ==>> takens:['test'] and tokenize_without_stop_words:[]
2019-06-14 23:00:11	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 23:00:11	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 23:00:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 23:00:11	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 23:00:11	DEBUG	Punctuation handler ==>> text to process:testing
2019-06-14 23:00:11	DEBUG	Tokenization handler ==>> takens:['testing'] and tokenize_without_stop_words:[]
2019-06-14 23:00:11	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 23:00:11	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 23:00:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 23:00:11	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 23:00:11	DEBUG	Punctuation handler ==>> text to process:payment
2019-06-14 23:00:11	DEBUG	Tokenization handler ==>> takens:['payment'] and tokenize_without_stop_words:[]
2019-06-14 23:00:11	DEBUG	Stemmer handler ==>> stem_tokens:['payment'] and stem_without_stop_words:[]
2019-06-14 23:00:11	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 23:00:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 23:00:11	DEBUG	Ngram handler ==>> unigram:['payment'] == bigram:[] == trigram:[]
2019-06-14 23:00:11	DEBUG	Punctuation handler ==>> text to process:paymentdata
2019-06-14 23:00:11	DEBUG	Tokenization handler ==>> takens:['paymentdata'] and tokenize_without_stop_words:[]
2019-06-14 23:00:11	DEBUG	Stemmer handler ==>> stem_tokens:['paymentdata'] and stem_without_stop_words:[]
2019-06-14 23:00:11	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 23:00:11	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 23:00:11	DEBUG	Ngram handler ==>> unigram:['paymentdata'] == bigram:[] == trigram:[]
2019-06-14 23:01:43	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 23:01:43	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 23:01:43	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 23:01:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 23:01:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 23:01:43	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 23:01:43	DEBUG	Punctuation handler ==>> text to process:test
2019-06-14 23:01:43	DEBUG	Tokenization handler ==>> takens:['test'] and tokenize_without_stop_words:[]
2019-06-14 23:01:43	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 23:01:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 23:01:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 23:01:43	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 23:01:43	DEBUG	Punctuation handler ==>> text to process:testing
2019-06-14 23:01:43	DEBUG	Tokenization handler ==>> takens:['testing'] and tokenize_without_stop_words:[]
2019-06-14 23:01:43	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 23:01:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 23:01:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 23:01:43	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 23:01:43	DEBUG	Punctuation handler ==>> text to process:payment
2019-06-14 23:01:43	DEBUG	Tokenization handler ==>> takens:['payment'] and tokenize_without_stop_words:[]
2019-06-14 23:01:43	DEBUG	Stemmer handler ==>> stem_tokens:['payment'] and stem_without_stop_words:[]
2019-06-14 23:01:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 23:01:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 23:01:43	DEBUG	Ngram handler ==>> unigram:['payment'] == bigram:[] == trigram:[]
2019-06-14 23:01:43	DEBUG	Punctuation handler ==>> text to process:paymentdata
2019-06-14 23:01:43	DEBUG	Tokenization handler ==>> takens:['paymentdata'] and tokenize_without_stop_words:[]
2019-06-14 23:01:43	DEBUG	Stemmer handler ==>> stem_tokens:['paymentdata'] and stem_without_stop_words:[]
2019-06-14 23:01:43	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 23:01:43	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 23:01:43	DEBUG	Ngram handler ==>> unigram:['paymentdata'] == bigram:[] == trigram:[]
2019-06-14 23:01:57	DEBUG	Punctuation handler ==>> text to process:phrase
2019-06-14 23:01:57	DEBUG	Tokenization handler ==>> takens:['phrase'] and tokenize_without_stop_words:[]
2019-06-14 23:01:57	DEBUG	Stemmer handler ==>> stem_tokens:['phrase'] and stem_without_stop_words:[]
2019-06-14 23:01:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 23:01:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 23:01:57	DEBUG	Ngram handler ==>> unigram:['phrase'] == bigram:[] == trigram:[]
2019-06-14 23:01:57	DEBUG	Punctuation handler ==>> text to process:test
2019-06-14 23:01:57	DEBUG	Tokenization handler ==>> takens:['test'] and tokenize_without_stop_words:[]
2019-06-14 23:01:57	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 23:01:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 23:01:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 23:01:57	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 23:01:57	DEBUG	Punctuation handler ==>> text to process:testing
2019-06-14 23:01:57	DEBUG	Tokenization handler ==>> takens:['testing'] and tokenize_without_stop_words:[]
2019-06-14 23:01:57	DEBUG	Stemmer handler ==>> stem_tokens:['test'] and stem_without_stop_words:[]
2019-06-14 23:01:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 23:01:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 23:01:57	DEBUG	Ngram handler ==>> unigram:['test'] == bigram:[] == trigram:[]
2019-06-14 23:01:57	DEBUG	Punctuation handler ==>> text to process:payment
2019-06-14 23:01:57	DEBUG	Tokenization handler ==>> takens:['payment'] and tokenize_without_stop_words:[]
2019-06-14 23:01:57	DEBUG	Stemmer handler ==>> stem_tokens:['payment'] and stem_without_stop_words:[]
2019-06-14 23:01:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 23:01:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 23:01:57	DEBUG	Ngram handler ==>> unigram:['payment'] == bigram:[] == trigram:[]
2019-06-14 23:01:57	DEBUG	Punctuation handler ==>> text to process:paymentdata
2019-06-14 23:01:57	DEBUG	Tokenization handler ==>> takens:['paymentdata'] and tokenize_without_stop_words:[]
2019-06-14 23:01:57	DEBUG	Stemmer handler ==>> stem_tokens:['paymentdata'] and stem_without_stop_words:[]
2019-06-14 23:01:57	DEBUG	lemmatization handler ==>> lemma_tokens:[] and lemma_without_stop_words:[]
2019-06-14 23:01:57	DEBUG	POS Lemma handler ==>> pos_lemma_tokens:[] and pos_lemma_tokens_without_stopwords:[]
2019-06-14 23:01:57	DEBUG	Ngram handler ==>> unigram:['paymentdata'] == bigram:[] == trigram:[]
